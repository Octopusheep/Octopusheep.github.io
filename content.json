{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"about","text":"He gives man speech, speech created thought, which is measure of the universe. I remember this phrase from Thinking in Java(4th Edition) So I save what I wanna save in this website including my thought, which is mean of why I build it.","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Android MVP框架学习笔记","text":"本学习笔记总结自文章MVP模式简单易懂的介绍方式 MVP即Model-View-Presenter设计模式，相比于MVC设计模式，将MVC中View层的业务逻辑抽离至Presenter层中，使整个框架的耦合度进一步降低。 MVC与MVPMVC即模型-视图-控制器设计模式 View层：应用程序的UI界面，负责向用户展示数据和接受用户的输入 Model层：JavaBean实体类，负责保存实例数据 Controller层：更新用于用户界面，和数据实例 Android中MVP设计模式的核心思想： MVP把Activity中的UI逻辑抽象成View接口，把业务逻辑抽象成Presenter接口，Model类还是原来的Model。 这样做简化了Activity的工作，只用来响应生命周期，其他工作都丢到Presenter层中去完成。为了充分体现MVP的思想，View层不能直接对Model层进行操作，这是MVP与MVC最大的不同。 MVP模式具体的应用 使用MVP至少要做如下步骤： 创建IPresenter接口，把所有业务逻辑的接口放在这里，并创建他们的实现类PresenterCompl，在PresenterCompl类中写具体的业务逻辑 创建IView接口，把所有视图逻辑的接口放在这里，其实现类是Activity或Fragment Model不一定要存在，但是一定会有View和Presenter 根据我的理解，View层和Presenter层相互持有彼此的引用，因此View层中的逻辑操作可以通过操纵Presenter层的引用完成，而Presenter层可以通过操纵View层的引用更新UI界面，View层无法直接接触Model层，必须通过Presnter层中持有的View层引用，来更新UI界面，这样三层之间实现充分解耦。","link":"/2018/10/08/Android MVP框架学习笔记1/"},{"title":"Android MVP框架学习笔记（进阶）","text":"本学习笔记总结自文章Android MVP架构搭建 引言在学习Android MVP的过程中，我发现第一篇文章中的MVP结构存在诸多问题，一是对每一个Activity都需要写一套MVP结构，异常麻烦；二是Model层中只包含JavaBean，未包含数据请求部分，导致presenter层中需要加上数据请求。 学习了这篇文章后我觉得主要掌握的几点有： 为MVP各层级添加base基类和范型大大增加复用性 对view层为null的情况做兼容处理 对model层请求数据采用callback的方式通知presenter层实现view层界面的刷新 而我对MVP更深一步的理解是： presenter层是单纯的Java类，只负责处理逻辑业务 model层包括JavaBean和数据请求 所有的Android API应该在view层的Activity或Fragment中实现 架构组成进阶版的MVP架构有几个方面组成： MVP结构的base基类：BaseActivity，BaseView，BasePresenter,Callback 实现基类的MVP结构类：Model，MvpView，MvpPresenter，MvpActivity 具体实现大概就在这8个类里。 实现步骤 BaseView 123456789101112131415161718192021222324public interface BaseView { /** * 显示正在加载view */ void showLoading(); /** * 关闭正在加载view */ void hideLoading(); /** * 显示提示 * @param msg */ void showToast(String msg); /** * 显示请求错误提示 */ void showErr(); /** * 获取上下文 * @return 上下文 */ Context getContext();} BaseActivity 1234567891011121314151617181920212223242526272829303132public abstract class BaseActivity extends Activity implements IBaseView { private ProgressDialog mProgressDialog; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); mProgressDialog = new ProgressDialog(this); mProgressDialog.setCancelable(false); } @Override public void showLoading() { if (!mProgressDialog.isShowing()) { mProgressDialog.show(); } } @Override public void hideLoading() { if (mProgressDialog.isShowing()) { mProgressDialog.dismiss(); } } @Override public void showToast(String msg) { Toast.makeText(this, msg, Toast.LENGTH_SHORT).show(); } @Override public void showErr() { showToast(getResources().getString(R.string.api_error_msg)); } @Override public Context getContext() { return BaseActivity.this; } Callback 12345678910111213141516171819202122public interface Callback&lt;T&gt; { /** * 数据请求成功 * @param data 请求到的数据 */ void onSuccess(T data); /** * 使用网络API接口请求方式时，虽然已经请求成功但是由 * 于{@code msg}的原因无法正常返回数据。 */ void onFailure(String msg); /** * 请求数据失败，指在请求网络API接口请求方式时，出现无法联网、 * 缺少权限，内存泄露等原因导致无法连接到请求数据源。 */ void onError(); /** * 当请求数据结束时，无论请求结果是成功，失败或是抛出异常都会执行此方法给用户做处理，通常做网络 * 请求时可以在此处隐藏“正在加载”的等待控件 */ void onComplete();} BasePresenter 1234567891011121314151617181920212223242526272829303132public class BasePresenter&lt;V extends IBaseView&gt; { /** * 绑定的view */ private V mvpView; /** * 绑定view，一般在初始化中调用该方法 */ @Override public void attachView(V mvpView) { this.mvpView = mvpView; } /** * 断开view，一般在onDestroy中调用 */ @Override public void detachView() { this.mvpView = null; } /** * 是否与View建立连接 * 每次调用业务请求的时候都要出先调用方法检查是否与View建立连接 */ public boolean isViewAttached(){ return mvpView != null; } /** * 获取连接的view */ public V getView(){ return mvpView; } Model 需要注意model层中数据请求的方法都是静态方法，故参数前面需要final修饰 123456789101112131415161718192021222324252627public class MvpModel { /** * 获取网络接口数据 * @param param 请求参数 * @param callback 数据回调接口 */ public static void getNetData(final String param, final MvpCallback&lt;String&gt; callback){ // 利用postDelayed方法模拟网络请求数据的耗时操作 new Handler().postDelayed(new Runnable() { @Override public void run() { switch (param){ case \"normal\": callback.onSuccess(\"根据参数\"+param+\"的请求网络数据成功\"); break; case \"failure\": callback.onFailure(\"请求失败：参数有误\"); break; case \"error\": callback.onError(); break; } callback.onComplete(); } },2000); }} 实现基类的View层 基类中已经存在的方法就不用写进子类了，增加了复用性 1234567public interface MvpView extends BaseView{ /** * 当数据请求成功后，调用此接口显示数据 * @param data 数据源 */ void showData(String data);} 实现了基类的presenter层 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class MvpPresenter extends BasePresenter&lt;MvpView &gt; { /** * 获取网络数据 * @param params 参数 */ public void getData(String params){ if (!isViewAttached()){ //如果没有View引用就不加载数据 return; } //显示正在加载进度条 getView().showLoading(); // 调用Model请求数据 MvpModel.getNetData(params, new MvpCallback()&lt;String&gt; { @Override public void onSuccess(String data) { //调用view接口显示数据 if(isViewAttached()){ getView().showData(data); } } @Override public void onFailure(String msg) { //调用view接口提示失败信息 if(isViewAttached()){ getView().showToast(msg); } } @Override public void onError() { //调用view接口提示请求异常 if(isViewAttached()){ getView().showErr(); } } @Override public void onComplete() { // 隐藏正在加载进度条 if(isViewAttached()){ getView().hideLoading(); } } }); }} 实现了基类的Activity 1234567891011121314151617181920212223242526272829303132333435public class MainActivity extends BaseActivity implements MvpView { TextView text; MvpPresenter presenter; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); text = (TextView)findViewById(R.id.text); //初始化Presenter presenter = new MvpPresenter(); presenter.attachView(this); } @Override protected void onDestroy() { super.onDestroy(); //断开View引用 presenter.detachView(); } @Override public void showData(String data) { text.setText(data); } // button 点击事件调用方法 public void getData(View view){ presenter.getData(\"normal\"); } // button 点击事件调用方法 public void getDataForFailure(View view){ presenter.getData(\"failure\"); } // button 点击事件调用方法 public void getDataForError(View view){ presenter.getData(\"error\"); } } fragment实现MVP的方法同BaseActivity一样，需要构造一个BaseFragment基类。 需要注意的是： 需要在onCreateView()生命周期方法中通过getActivity()方法拿到上下文参数，在实现BaseView接口的方法时，调用其容器Activity的上下文来实现父容器的界面刷新。 在调用父容器界面方法之前，需要用getActivity()是否null来检查与Activity的连接情况。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public abstract class BaseFragment extends Fragment implements BaseView { public abstract int getContentViewId(); protected abstract void initAllMembersView(Bundle savedInstanceState); protected Context mContext; protected View mRootView; @Nullable @Override public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) { mRootView = inflater.inflate(getContentViewId(), container, false); this.mContext = getActivity(); initAllMembersView(savedInstanceState); return mRootView; } @Override public void showLoading() { checkActivityAttached(); ((BaseFragmentActivity) mContext).showLoading(); } @Override public void showLoading(String msg) { checkActivityAttached(); ((BaseFragmentActivity) mContext).showLoading(msg); } @Override public void hideLoading() { checkActivityAttached(); ((BaseFragmentActivity) mContext).hideLoading(); } @Override public void showToast(String msg) { checkActivityAttached(); ((BaseFragmentActivity) mContext).showToast(msg); } @Override public void showErr() { checkActivityAttached(); ((BaseFragmentActivity) mContext).showErr(); } protected boolean isAttachedContext(){ return getActivity() != null; } /** * 检查activity连接情况 */ public void checkActivityAttached() { if (getActivity() == null) { throw new ActivityNotAttachedException(); } } public static class ActivityNotAttachedException extends RuntimeException { public ActivityNotAttachedException() { super(\"Fragment has disconnected from Activity ! - -.\"); } }}","link":"/2018/12/04/Android MVP框架学习笔记2/"},{"title":"AndroidStudio常用快捷键指南","text":"常用命令 alt+up/down 在类和方法间移动光标 ctrl+f12 弹出文件中类和方法的结构图，按esc取消 ctrl+alr+h 展示一个方法调用路径层级图 ctrl+shift+i 弹出展示代码具体实现的小框 ctrl+shift+a 查找Android Studio中的动作或命令（Analyze Data Flow to Here） ctrl+y 删除整行 ctrl+shift+delete 移除外层包围的代码 ctrl+j 弹出动态模板代码提示框 alt+MouseDrag 拉长光标 ctrl+o 快速复写方法","link":"/2018/08/24/AndroidStudio常用快捷键指南/"},{"title":"Android原生TTS逻辑分析","text":"本文依据API 28的安卓源码文件UtteranceProgressListener.java分析整理得出 What is UtteranceProgressListenerUtteranceProgressListener实际上是一个抽象类，它是一个监听器，监听与发声的过程相关的事件，这个事件是通过很多步骤来处理的。每一个TTS发声事件都与函数调用相关联，分别是TextToSpeech#speak和TextToSpeech#synthesizeToFile.并且有唯一的发声ID(utterance identifier)来标识自己。这个ID就是TextToSpeech.Engine#KEY_PARAM_UTTERANCE_ID TTS回调类型 onStart(String utteranceId)该回调会在TTS发声之前被调用，TTS发声是由于TextToSpeech#speak或TextToSpeech#synthesizeToFile的调用引起的，参数为该发声事件的发声ID(utteranceId) onDone(String utteranceId)当TTS发声过程成功完成后（要说的话从头到尾一字不落全说完），调用该回调。可以保证onDone回调一定是在对应的onStart回调之后调用的,参数为该发声事件的发声ID(utteranceId) onError(String utteranceId)当TTS发声过程中出现一个错误时调用该回调，在TTS语音合成过程的任意时间点都可以调用该回调，一个onStart只对应一个onDone或onError回调,参数为该发声事件的发声ID(utteranceId) onError(String utteranceId, int errorCode)当TTS发声过程中出现一个错误时调用该回调，在TTS语音合成过程的任意时间点都可以调用该回调，一个onStart只对应一个onDone或onError回调，比单参数错误回调多返回一个来自TextToSpeech的错误代码(ERROR_* codes from TextToSpeech) onStop(String utteranceId, boolean interrupted)当TTS播放过程中停止播放或合成队列刷新过程时调用该回调，这个回调可以发生在调用TextToSpeech#stop()方法或者使用TextToSpeech#QUEUE_FLUSH作为参数调用TextToSpeech#speak和TextToSpeech#synthesizeToFile方法时.参数为该发声事件的发声ID(utteranceId)和布尔型参数interrupted.interrupted为true时，TTS发声过程将在正在语音合成的过程中被打断，且输出是不完整的;为flase时，TTS发声事件将在语音合成开始之前被刷新 - 文件源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182// Copyright 2011 Google Inc. All Rights Reserved.package android.speech.tts;import android.media.AudioFormat;/** * Listener for events relating to the progress of an utterance through * the synthesis queue. Each utterance is associated with a call to * {@link TextToSpeech#speak} or {@link TextToSpeech#synthesizeToFile} with an * associated utterance identifier, as per {@link TextToSpeech.Engine#KEY_PARAM_UTTERANCE_ID}. * * The callbacks specified in this method can be called from multiple threads. */public abstract class UtteranceProgressListener { /** * Called when an utterance \"starts\" as perceived by the caller. This will * be soon before audio is played back in the case of a {@link TextToSpeech#speak} * or before the first bytes of a file are written to the file system in the case * of {@link TextToSpeech#synthesizeToFile}. * * @param utteranceId The utterance ID of the utterance. */ public abstract void onStart(String utteranceId); /** * Called when an utterance has successfully completed processing. * All audio will have been played back by this point for audible output, and all * output will have been written to disk for file synthesis requests. * * This request is guaranteed to be called after {@link #onStart(String)}. * * @param utteranceId The utterance ID of the utterance. */ public abstract void onDone(String utteranceId); /** * Called when an error has occurred during processing. This can be called * at any point in the synthesis process. Note that there might be calls * to {@link #onStart(String)} for specified utteranceId but there will never * be a call to both {@link #onDone(String)} and {@link #onError(String)} for * the same utterance. * * @param utteranceId The utterance ID of the utterance. * @deprecated Use {@link #onError(String,int)} instead */ @Deprecated public abstract void onError(String utteranceId); /** * Called when an error has occurred during processing. This can be called * at any point in the synthesis process. Note that there might be calls * to {@link #onStart(String)} for specified utteranceId but there will never * be a call to both {@link #onDone(String)} and {@link #onError(String,int)} for * the same utterance. The default implementation calls {@link #onError(String)}. * * @param utteranceId The utterance ID of the utterance. * @param errorCode one of the ERROR_* codes from {@link TextToSpeech} */ public void onError(String utteranceId, int errorCode) { onError(utteranceId); } /** * Called when an utterance has been stopped while in progress or flushed from the * synthesis queue. This can happen if a client calls {@link TextToSpeech#stop()} * or uses {@link TextToSpeech#QUEUE_FLUSH} as an argument with the * {@link TextToSpeech#speak} or {@link TextToSpeech#synthesizeToFile} methods. * * @param utteranceId The utterance ID of the utterance. * @param interrupted If true, then the utterance was interrupted while being synthesized * and its output is incomplete. If false, then the utterance was flushed * before the synthesis started. */ public void onStop(String utteranceId, boolean interrupted) { } /** * Called when the TTS engine begins to synthesize the audio for a request. * * &lt;p&gt; * It provides information about the format of the byte array for subsequent * {@link #onAudioAvailable} calls. * &lt;/p&gt; * * &lt;p&gt; * This is called when the TTS engine starts synthesizing audio for the request. If an * application wishes to know when the audio is about to start playing, {#onStart(String)} * should be used instead. * &lt;/p&gt; * * @param utteranceId The utterance ID of the utterance. * @param sampleRateInHz Sample rate in hertz of the generated audio. * @param audioFormat Audio format of the generated audio. Should be one of * {@link AudioFormat#ENCODING_PCM_8BIT}, {@link AudioFormat#ENCODING_PCM_16BIT} or * {@link AudioFormat#ENCODING_PCM_FLOAT}. * @param channelCount The number of channels. */ public void onBeginSynthesis(String utteranceId, int sampleRateInHz, int audioFormat, int channelCount) { } /** * This is called when a chunk of audio is ready for consumption. * * &lt;p&gt; * The audio parameter is a copy of what will be synthesized to the speakers (when synthesis was * initiated with a {@link TextToSpeech#speak} call) or written to the file system (for * {@link TextToSpeech#synthesizeToFile}). The audio bytes are delivered in one or more chunks; * if {@link #onDone} or {@link #onError} is called all chunks have been received. * &lt;/p&gt; * * &lt;p&gt; * The audio received here may not be played for some time depending on buffer sizes and the * amount of items on the synthesis queue. * &lt;/p&gt; * * @param utteranceId The utterance ID of the utterance. * @param audio A chunk of audio; the format can be known by listening to * {@link #onBeginSynthesis(String, int, int, int)}. */ public void onAudioAvailable(String utteranceId, byte[] audio) { } /** * This is called when the TTS service is about to speak the specified range of the utterance * with the given utteranceId. * * &lt;p&gt;This method is called when the audio is expected to start playing on the speaker. Note * that this is different from {@link #onAudioAvailable} which is called as soon as the audio is * generated. * &lt;p&gt;This information can be used, for example, to highlight ranges of the text while it is * spoken. * * &lt;p&gt;Only called if the engine supplies timing information by calling {@link * SynthesisCallback#rangeStart(int, int, int)}. * * @param utteranceId Unique id identifying the synthesis request. * @param start The start index of the range in the utterance text. * @param end The end index of the range (exclusive) in the utterance text. * @param frame The position in frames in the audio of the request where this range is spoken. */ public void onRangeStart(String utteranceId, int start, int end, int frame) { onUtteranceRangeStart(utteranceId, start, end); } /** @removed */ @Deprecated public void onUtteranceRangeStart(String utteranceId, int start, int end) { } /** * Wraps an old deprecated OnUtteranceCompletedListener with a shiny new progress listener. * * @hide */ static UtteranceProgressListener from( final TextToSpeech.OnUtteranceCompletedListener listener) { return new UtteranceProgressListener() { @Override public synchronized void onDone(String utteranceId) { listener.onUtteranceCompleted(utteranceId); } @Override public void onError(String utteranceId) { listener.onUtteranceCompleted(utteranceId); } @Override public void onStart(String utteranceId) { // Left unimplemented, has no equivalent in the old // API. } @Override public void onStop(String utteranceId, boolean interrupted) { listener.onUtteranceCompleted(utteranceId); } }; }}","link":"/2019/04/12/Android原生TTS逻辑分析/"},{"title":"Android开发环境配置(Ubuntu环境)","text":"安装Java development kit (JDK) 从oracle官网下载jdk，选择Linux x64版本,下载完成后，复制到桌面 在/usr/local目录下创建java文件夹 进入终端，输入 sudo mkdir /usr/local/java进入终端，输入 sudo cp -r jdk-8u171-linux-x64.tar.gz /usr/local/java进入终端，输入 sudo tar -xzvf sudo mkdir /usr/local/java 使用文本编辑器修改/home//.bashrc文件,末尾追加 export JAVA_HOME=/usr/local/java/jdk1.8.0_171export JRE_HOME=${JAVA_HOME}/jreexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/libexport PATH=${JAVA_HOME}/bin:$PATH 重启系统后，jdk即安装成功 安装Android studio(Linux) 下载Linux版本的Android studio安装包 进入./bin文件夹中右键打开终端 输入sudo sh studio.sh 依次执行即可完成安装 配置android studi启动图标 在桌面进入终端，输入指令 gedit android_studio.desktop 在文本编辑器中添加下列信息 [Desktop Entry]Name = Android StudioComment= android studioExec=/opt/android-studio/bin/studio.shIcon=/opt/android-studio/bin/studio.pngTerminal=falseType=Application 安装shadowsocks-qt5 命令行安装ShadowSocks sudo add-apt-repository ppa:hzwhuang/ss-qt5sudo apt-get updatesudo apt-get install shadowsocks-qt5 使用Ubnutu18.04安装Shadowsocks-Qt5时,同样使用sudo add-apt-repository ppa:hzwhuang/ss-qt5添加源，但是ppa:hzwhuang/ss-qt5并没有18.04版本的源，所以再执行update时会出现如下错误: 仓库 “http://ppa.launchpad.net/hzwhuang/ss-qt5/ubuntu bionic Release” 没有 Release 文件 这时，只要编辑/etc/apt/sources.list.d/hzwhuang-ubuntu-ss-qt5-bionic.list文件，将bionic (18.04版本代号)改成xenial（16.04版本代号）.然后再执行sudo apt-get update. 成功之后就是sudo apt-get install shadowsocks-qt5 安装Chrome浏览器 在Firefox浏览器设置中编辑SOCKS主机和端口号分别为127.0.0.1和1080 在Ubuntu系统网络设置中按如下配置网络代理 成功翻墙后安装Chrome浏览器","link":"/2018/08/24/Android开发环境配置(Ubuntu环境)/"},{"title":"Docker客制化镜像指南","text":"本教程以ubuntu:latest镜像作为基础镜像，创建一个启动后自动打印日志的docker镜像 下载基础镜像下载ubuntu镜像作为基础镜像： 1docker pull ubuntu 启动ubuntu镜像容器：1docker run -it ubuntu 更新软件源(容器内)1root@03da790f4a63:/# apt-get update 下载所需软件(容器内)1root@03da790f4a63:/# apt-get install vim 编写自动打印日志的shell脚本并保存(容器内)在./根路径使用vim命令创建shell脚本文件： 12345root@03da790f4a63:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@03da790f4a63:/# pwd/root@03da790f4a63:/# vim script.sh 输入如下脚本内容： 12345678i=0;while truedoecho current index: $i;echo current index in log/log1: $i &gt;&gt; /log/log1;i=`expr $i + 1`;sleep 1;done 这个脚本做了4件事情： 1. 定义了变量i 2. 创建了一个while无限循环 3. 每次循环会用echo命令向终端输出current index: i的日志信息，并向./log/log1文件中写入相同日志信息 4. 每次循环最后会将变量i的值加1 保存并退出脚本和当前容器3da790f4a63 创建log文件夹(容器内)在容器内尝试执行script.sh: 1root@03da790f4a63:/# sh script.sh 你会发现命令行内会输出如下内容： 12345678910current index: 0script.sh: 5: script.sh: cannot create /log/log1: Directory nonexistentcurrent index: 1script.sh: 5: script.sh: cannot create /log/log1: Directory nonexistent^[current index: 2script.sh: 5: script.sh: cannot create /log/log1: Directory nonexistentLcurrent index: 3script.sh: 5: script.sh: cannot create /log/log1: Directory nonexistentcurrent index: 4script.sh: 5: script.sh: cannot create /log/log1: Directory nonexistent 👀眼睛一眯就发现原来是echo命令没有创建文件夹的权限，Bravo！ 因此我摸了摸我杂乱的小胡子，创建了一个文件夹，解决这个问题： 1root@03da790f4a63:/# mkdir log 至此，我们已经创建了一个具有以下特性的容器： 1. 基于ubuntu容器 2. 安装有vim文字编辑器 3. 保存了循环打印日志的shell脚本 查看容器ID1docker ps -a 出现如下docker进程： 1234CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES03da790f4a63 ubuntu &quot;/bin/bash&quot; 25 minutes ago Up 25 minutes priceless_edisonb5b1243d00d7 tangjiawei/banana:v0.0.1 &quot;/bin/sh -c &apos;sh ./ap…&quot; 39 minutes ago Up 39 minutes priceless_golicka9905e4f5cff af2b1144440a &quot;/bin/sh -c &apos;/bash/s…&quot; 40 minutes ago Exited (127) 40 minutes ago jovial_germain 找到上一步我们客制化的容器ID为03da790f4a63 创建客制化镜像1docker commit 03da790f4a63 octopusheep/apple:v0.0.1 至此，我们客制化了一个具有一个具有以下特性的镜像： 1. 基于ubuntu容器 2. 安装有vim文字编辑器 3. 保存了循环打印日志的shell脚本 However，这个镜像产生的容器并不能运行后自动运行我们编写的shell脚本，因此需要使用Dockerfile生成可以自动启动脚本的镜像 创建Dockerfile文件在你的电脑内新建一个空文件夹，新建一个Dockerfile文件 我放在了/Documents/Dockerfile资料/essential路径下，大家可以随意 1~/Documents/Dockerfile资料/essential » vi Dockerfile 在Dockerfile文件中输入一下内容： 1234FROM octopusheep/apple:v0.0.1MAINTAINER octopusheep &quot;octopusheep@gmail.com&quot;CMD sh ./script.sh 保存并退出Dockerfile 使用Dockerfile创建客制化镜像在Dockerfile所在的文件夹下使用docker build命令，创建镜像： 1~/Documents/Dockerfile资料/essential » docker build -t octopusheep/banana:v0.0.1 . 出现如下信息即表示镜像构建成功： 12345678910111213Sending build context to Docker daemon 9.216kBStep 1/3 : FROM octopusheep/apple:v0.0.1 ---&gt; 8b1a82856dc9Step 2/3 : MAINTAINER octopusheep &quot;octopusheep@gmail.com&quot; ---&gt; Running in c80e6b9b5a30Removing intermediate container c80e6b9b5a30 ---&gt; 25fa612ede72Step 3/3 : CMD sh ./script.sh ---&gt; Running in 5e5f3e80566aRemoving intermediate container 5e5f3e80566a ---&gt; ad98405d0524Successfully built ad98405d0524Successfully tagged octopusheep/banana:v0.0.1 至此，至此，我们客制化了一个具有一个具有以下特性的镜像： 1. 基于ubuntu容器 2. 安装有vim文字编辑器 3. 保存了循环打印日志的shell脚本 4. 容器一运行就会自动执行shell脚本 Bingo！","link":"/2019/11/26/Docker客制化镜像指南/"},{"title":"Elasticsearch学习笔记","text":"本文翻译总结自Elasticsearch官方文档，都是我自己翻译的yo！ You know, for search(and analysis) Elasticsearch简介elasticsearch是一个分布式的搜索和分析引擎，它基于elasticstack的核心功能。 logstash和beats用于促成收集、整合、丰富你的数据，并将数据存储在elasticsearch中。 kibana能让你交互式的探索、使数据图形化、分享你的关于数据的看法、管理和监控stack。 elasticsearch是让索引、搜索、分析三大魔法发生的地方。 elasticsearch为所有类型的数据提供实时搜索和分析，无论你的数据是有结构还是无结构的文本、数值型数据、地理空间数据，es都能够有效的存储它们并建立索引，且索引的方式支持快速搜索。你可以做出远远超出例如（简单的数据取回、聚合数据以发现你的数据的模式和趋势）这些事。随着你的数据和访问量的增加，es的分布式特性可以让你的部署无缝的与其协作。 然而并不是所有的问题都是搜索型问题，es也提供速度和灵活性在许多不同的处理数据的案例中： 为app或网站增加一个搜索盒(search box) 存储和分析日志、指标，保护事件数据的安全 使用机器学习来自动建模你的实时数据的行为 使用es作为存储引擎的自动化商业工作流程 通过es来管理、聚合、分析地理空间信息，作为地理信息系统(GIS) 通过es来存储和处理基因数据，作为生物信息的搜索工具 我们不断的被人们使用搜索的新奇方式感到惊叹，但无论你是否符合以上的案例，抑或是使用es来解决新问题，用es操作你的数据、文档、指标的方式是相同的 开始使用Elasticsearch准备使用es做一个测试抑或是看看你自己怎样用REST APIs来保存、搜索、分析数据吗？ 初学教程的步骤： 启动并运行es实例 index一些样本文档 使用es查询语言来搜索文档 使用bucket和指标聚合来分析结果 查看Elasticsearcb Introduction来学习lingo和理解es是怎么运行的基本概念。如果你对es已经熟悉并想知道es如何与栈的其余部分一起工作，可以跳转至Elastic Stack Tutorial来学习怎样设置系统监控解决方案，配套使用es、kibana、beats和logstash 设置Elasticsearch这个部分包含如何设置es、让es运行的相关信息，包括： 下载 安装 运行 配置 支持的平台官方支持的操作平台和JVMs的模版可以在Support Matrix获得，es可以在上述平台上被测试，但es也可能在其他平台上可以工作。 Java（JVM）版本es使用java构建的，包含了一系列来自Jdk maintainer（GPLv2+CE）各分支的OpenJDK版本，The bundle JVM是推荐的JVM，并且存在于es文件目录中的jdk目录中 如果使用自己版本的java，请配置JAVA_HOME环境变量，如果你使用了一个与the bundle JVM版本不同的java版本，我们推荐使用支持LTS的java版本。如果使用了错误版本的java，es将会拒绝启动，当使用您自己的JVM时，es中的the bundle JVM目录可能将被移除。 安装Elasticsearch下载esmac或linux环境下es的下载地址：Install Elasticsearch from archive on Linux or MacOS 一些配置管理工具我们也提供了一些相关的配置管理工具来帮助您大范围的部署： Puppet puppet-elasticsearch Chef cookbook-elasticsearch Ansible ansible-elasticsearch 安装es兄弟，把安装包找个合适的地方解压了。 需要注意elasticsearch-version的pwd路径就是$ES_HOME变量的值，记得哟 运行escd elasticsearch-[version]进入es目录下 ./bin/elasticsearch运行es 检查es是否运行curl localhost:9200测试es是否运行成功（9200端口能否返回数据） 正常应收到如下回应： 1234567891011121314151617{ \"name\" : \"Mac.local\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"X4xKA73_SD2WU3saru4sBg\", \"version\" : { \"number\" : \"7.2.0\", \"build_flavor\" : \"default\", \"build_type\" : \"tar\", \"build_hash\" : \"508c38a\", \"build_date\" : \"2019-06-20T15:54:18.811730Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.0.0\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\"} 作为daemon（后台守护进程）运行./bin/elasticsearch -d -p pid -d指定daemon，-p在文件中记录process ID log信息将保存在$ES_HOME/logs/目录中 为了终止es，要杀掉保存在pid文件中的process ID记录pkill -F pid 在命令行中配置Elasticsearches从$ES_HOME/config/elasticsearch.yml中加载默认配置，配置文件的格式在Configuring Elasticsearch中解释 在config文件中被指定的设置也可以通过命令行来实现，使用-E的语法./bin/elasticsearch -d -Ecluster.name=my_cluster -Enode.name=node_1 通常集群等级的设置（如cluster_name）应该在elasticsearch.yml配置文件中进行配置，而节点特性设置（如node_name）应该咋i 命令行中指定 archives归档文件的目录结构归档的分布完全是独立的哟(self-contained)！所有的文件和目录都默认包含在$ES_HOME中，即解压归档文件时所创建的目录 真的很方便哟！为什么嫩，因为你不需要再创建其他的目录再来使用es，删除es也很简单，给$ES_HOME整个删了就完事了。然鹅，改变config、data、log三个目录的默认位置，是比较明智的做法，为的是你之后不会删掉重要的数据 目录类型的作用： home es的home目录，就素$ES_HOME bin 二进制执行脚本的目录，包括运行es的elasticsearch和装插件的elasticsearch-plugin config 包含elasticsearch.yml的配置文件目录 data 包含每个index/shard的数据文件（which分配在节点上）的目录 logs 包含日志文件的目录 plugins 你说全世界哪里放插件最合适，答案是放插件的plugins目录 repo 共享文件系统仓库（repository） script 脚本文件放置处 至此已经建立了测试es的环境，在您开始严肃的开发或使用es进入生产环境前，你必须做如下额外设置： 学习怎么配置Elasticsearch 配置重要的Elasticsearch设置 配置重要的系统设置 配置Elasticsearches本身附带了合理的默认配置，您只需要非常少量的配置，绝大部分设置可以通过在运行的集群上通过集群更新设置API来更改 配置文件应该包含节点特性配置（如node_name和paths）、节点加入一个集群的必要条件，如cluster_name和network_host 配置文件的放置位置es有三个配置文件： elasticsearch.yml 用于配置es jvm.option 用来配置es的JVM设置 log4j2.properties 用来配置es的日志（logging） 这些配置文件都放置在config目录中。 配置目录的位置可以被更改通过ES_PATH_CONF环境变量，如下所示： 1ES_PATH_CONF=/path/to/my/config ./bin/elasticsearch 除此之外，你可以export这个ES_PATH_CONF环境变量通过命令行或通过你的shell profile 对于包分发，config目录默认被放置在/etc/elasticsearch 配置文件格式配置文件的格式为yaml，以下是怎样修改data、logs目录的path： 123path: data: /var/lib/elasticsearch logs: /var/log/elasticsearch 相关设置也可以写成： 12path.data: /var/lib/elasticsearchpath.logs: /var/log/elasticsearch 环境变量替代在配置文件中环境变量可以用${...}形式的注解引用，配置文件将注解替换成环境变量的值，如： 12node.name: ${HOSTNAME}network.host: ${ES_NETWORK_HOST} 设置JVM配置你可能几乎不需要更改jvm设置，如果你真的这么做了，最常见的更改是设置堆容量(heap size),这一节的剩余内容主要在细节上解释如何设置JVM选项 首选的设置JVM选项的方法是通过更改jvm.option配置文件来修改 这个文件包含了用线分隔的JVM参数列表，其用一种特殊的语法： 注释行用#开头 空白行直接忽略 -开头的行被当作是应用于独立的JVM版本的JVM选项 -Xmx2g 数字开头应用与对应版本的JVM 8:-Xmx2g 8-开头对应version8以上的JVM版本 8-:-Xmx2g 8-9开头你还不懂啥意思吗？ 8-9:-Xmx2g 您可以添加客制化的JVM flags在这个文件里，在你的版本控制系统中检查该配置 除此之外，还可以通过设置ES_JAVA_OPTS环境变量来修改JVM选项，如： 12export ES_JAVA_OPTS=\"$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir\"./bin/elasticsearch 安全设置一些设置是敏感的，依赖文件系统的权限来保护数值是不足够的，在这个情况下，es提供了密钥库和elasticsearch-keystore工具来管理密钥库中的设置 这些在elasticsearch.yml中的设置，需要在集群的每个节点中指定。当前，集群中每个节点的安全设置值必须相同 创建密钥库(keystore)使用elasticsearch-keystore的create命令 1bin/elasticsearch-keystore create 获得密钥库设置列表1bin/elasticsearch-keystore list 此外还有add、remove的等命令，详细可看官方文档，这块对我没什么用。 关闭Elasticsearch12jps | grep Elasticsearch14542 Elasticsearch 1kill -SIGTERM 15516","link":"/2019/07/04/Elasticsearch学习笔记/"},{"title":"Elasticsearch部署实践相关总结","text":"单节点ES的部署（选做）创建network1docker network create -d bridge elastic 部署Elasticsearch1234567891011publish_host=$(hostname -I | cut -d&apos; &apos; -f1) \\docker run -d \\ --name elasticsearch \\ -e &quot;discovery.type=single-node&quot; \\ -e &quot;network.host=0.0.0.0&quot; \\ -e &quot;network.publish_host=${publish_host}&quot; \\ -p 9200:9200 -p 9300:9300 \\ --memory-reservation 4g --memory 6g \\ --network=elastic \\ --restart on-failure \\ cargo.caicloudprivatetest.com/caicloud/elasticsearch:6.5.4 Gotcha：环境变量network.publish_host声明上述定义是ES服务可能会连接的唯一有效的主机名，举个栗子，如果你在192.168.133.32上发布你的ES服务，但你尝试连接ES通过主机名es.caicloud.io，用户端将不能使用，即使主机名es.caicloud.io已经映射到了192.168.133.32 验证方式：在ES部署的任意集群上执行(假设ES被安装在192.168.133.32) 1curl &apos;http://192.168.133.32:9200/_nodes/http?pretty&apos; 之后应该能看到如下回复： 1234567891011121314151617181920212223242526272829303132333435363738{ &quot;_nodes&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;nodes&quot; : { &quot;pgnaBbRGSOKJeeuq31tLcQ&quot; : { &quot;name&quot; : &quot;pgnaBbR&quot;, &quot;transport_address&quot; : &quot;192.168.133.32:9300&quot;, &quot;host&quot; : &quot;192.168.133.32&quot;, &quot;ip&quot; : &quot;192.168.133.32&quot;, &quot;version&quot; : &quot;6.5.4&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;d2ef93d&quot;, &quot;roles&quot; : [ &quot;master&quot;, &quot;data&quot;, &quot;ingest&quot; ], &quot;attributes&quot; : { &quot;ml.machine_memory&quot; : &quot;6442450944&quot;, &quot;xpack.installed&quot; : &quot;true&quot;, &quot;ml.max_open_jobs&quot; : &quot;20&quot;, &quot;ml.enabled&quot; : &quot;true&quot; }, &quot;http&quot; : { &quot;bound_address&quot; : [ &quot;[::]:9200&quot; ], &quot;publish_address&quot; : &quot;192.168.133.32:9200&quot;, &quot;max_content_length_in_bytes&quot; : 104857600 } } }} 部署kibanakibana不是ES运行的必需组件，但其是非常重要的debug和维护工具，因此高度推荐你在部署ES实例后也部署kibana 1234567docker run -d \\ --name kibana \\ -e &quot;ELASTICSEARCH_URL=http://elasticsearch:9200&quot; \\ -p 5601:5601 \\ --network=elastic \\ --restart on-failure \\ cargo.caicloudprivatetest.com/caicloud/kibana-oss:6.5.4 ES相关命令查询全部日志概况(假设ES被安装在192.168.133.32)1curl http://192.168.133.32:9200/_cat/indices?v 删除ES内全部日志(假设ES被安装在192.168.133.32)1curl -XDELETE http://192.168.133.32:9200/_all","link":"/2019/07/31/Elasticsearch部署实践相关总结/"},{"title":"Filebeat组件对接Logstash操作指南","text":"CPS系统通过filebeat组件输出日志，日志会经过kafka或logstash后，再输出给ES做持久化保存 组件交互Filebeat -&gt; Logsatsh -&gt; Elasticsearch 因此要实现filebeat对接logstash，需要做两步重要操作： 配置filebeat，使其日志输出到logstash 配置logstash，使其日志保存到elasticsearch 配置Filebeat先前filebeat的日志是直接输出到ES中的，所以要修改为将日志输出到logstash中，因此需要修改filebeat的configmap 进入CPS的控制节点后台 ssh root@192.168.130.101 编辑filebeat的configmap kubectl get cm -n kube-system查找名为filebeat-output的cm kubectl edit cm -n kube-system filebeat-output编辑filebeat-output 在filebeat-output中输入以下内容,配置日志输出到logstash配置事件输出到ES配置正在表达式对日志做多行聚合 12345678910111213141516171819apiVersion: v1data: filebeat-output.yml: | type: logstash hosts: - 192.168.130.14:9200 logstashHost: - 192.168.130.14:5044 multilinePattern: &apos;^\\s(at)\\s&apos; fields: type: testkind: ConfigMapmetadata: creationTimestamp: 2019-07-24T01:29:14Z name: filebeat-output namespace: kube-system resourceVersion: &quot;811292&quot; selfLink: /api/v1/namespaces/kube-system/configmaps/filebeat-output uid: 721615c7-adb2-11e9-9c31-5254005708d0 重启所有filebeat kubectl get pods -n kube-system|grep logging-filebeat列举所有filebeat pod kubectl delete pod -n $(上述filebeat pod id)删除所有filebeat，稍后会自行重启 配置logstash在配置logstash前，你需要有一个独立的可用的节点，节点中已安装docker 进入可用节点后台 ssh root@192.168.130.14 创建ES和Kibana 此步操作请参考文档Elasticsearch Deployment Guide 下载logstash的docker image docker pull logstash:7.2.0 创建并配置logstash 运行logstash镜像并进入container后台 docker run -it -p 9600:9600 -p 5044:5044 logstash：7.2.0 bash 手动输入conf配置文件（logstash容器后台中执行） vi configure.conf 123456789101112input { # 输入 beats { # 来源beats port =&gt; &quot;5044&quot; # 端口 }} output { # 输出 elasticsearch { # 选择elasticsearch hosts =&gt; [&quot;172.18.0.2:9200&quot;] #此处一定要修改为ES的IP和端口 } stdout{} } 执行logstash脚本，即可获得filebeat发送过来的日志 /bin/logstash -f configure.conf --config.reload.automatic 启动kibana docker run -it -p 5601:5601 -d -e ELASTICSEARCH_URL=“http://172.18.0.2:9200” --network=elastic -e PATH=“/usr/share/kibana/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin” -e ELASTIC_CONTAINER=“true” cargo.caicloudprivatetest.com/caicloud/kibana-oss:6.5.4 bash","link":"/2019/07/26/Filebeat组件对接Logstash操作指南/"},{"title":"Flutter学习笔记(Tour the framework)","text":"Introduction Flutter widget are built by a modern react-style framework and the widget have their own configuration and state which can support the rebuilt process when those two varieties changes Hello Worldthe simpiest flutter application likes this: 123456789101112import &apos;package:flutter/material.dart&apos;;void main(){ runApp( Center( child: Text( &apos;Hello,world!&apos;, textDirection: TextDirection.lrt, ), ), );} the runApp function take the given Widget and makes it the root of the widget tree. the flutter framework force the root widget to cover the screen. the text direction needs to be specified in this instance. the coder can author new widgets that are subclasses of either statelessWidget or statefulWidget the diffs of two kind of Widget is that whether your widget manages any state. A widget’s main job is to implement a build function, which describes the widget in terms of other, lower-lever widgets the framework builds those wodgets in turn until this process bottoms out in widgets that represent the underlying RenderObject, which computes and describes the geometry og the widget. Basic widget Text Row,Column Stack Container many widgets need to be inside of a MaterialApp to display properly, in order to inherit theme date. the widget can be marked as Expanded, which means it expands to fill any remainong available apce that hasn’t been consumed by the other children. you can have multiple Expanded children and determine the ratio in which they consume th available space using the flex argument to Expanded. Important: Passing widgets as argument to other widgets is a powerful technique that lets you create generic widgets that cann be reused in a wide variety of ways. Using material componentA material app starts with the MaterialApp widget. Navigator widget manages a stasck of widgets identified by strings , also known as route, which lets you transition smoothly between screeens of your application. Handling gesturethe GestureDetector widget doesn’t hava a visual representation but instead detect gestures made by the user, including taps, drags, and scales. Changing widgets in response to inputStatelessWidgets receive argument from their parent widget, which they store on final member variables. StatefulWidgets are special widgets that know how to generate State objects, which are then used to hold state.","link":"/2018/10/02/Flutter学习笔记(Tour the framework)/"},{"title":"Flutter安装指南(Ubuntu环境)","text":"前言根据flutter官网的说法 Flutter是谷歌的移动UI框架，可以快速在iOS和Android上构建高质量的原生用户界面。 其优点总结起来包括： 亚秒级别的热重载 媲美原生应用的性能 丰富的UI 个人认为flutter作为一个跨平台的UI框架，热重载是其最吸引人的功能，笔者目前负责的新闻项目涉及到切换主题后，应用内部的部分组件颜色也要随主题颜色变化，使用flutter框架进行开发，可以直接热重载应用界面而不用重走应用的生命周期，考虑到种种因素，故对flutter做预研。 主要步骤已由Flutter中文网给出，我重新整理了一下。 获取Flutter SDK 在Flutter官网下载Flutter SDK 右键或命令行解压安装包到你想安装的路径 1xz -d flutter_linux_v0.8.2-beta.tar.xz 1tar -xvf flutter_linux_v0.8.2-beta.tar 解压完成后将flutter文件夹拷贝到你想安装的路径 配置环境变量 将以下代码复制到主目录的.bashrc目录中 123export PUB_HOSTED_URL=https://pub.flutter-io.cn //国内用户需要设置export FLUTTER_STORAGE_BASE_URL=https://storage.flutter-io.cn //国内用户需要设置export PATH= PATH_TO_FLUTTER_GIT_DIRECTORY/flutter/bin:$PATH 注意：PATH_TO_FLUTTER_GIT_DIRECTORY为flutter目录的路径，比如笔者将其放在了/home/zhangyuyang/Android中 1export PATH=/home/zhangyuyang/Android/flutter/bin:$PATH 刷新PATH路径 1source $HOME/.bashrc 用echo命令查看flutter目录是否在PATH路径中 1echo $PATH 检查是否需要其他依赖项1flutter doctor 根据提示安装所需的依赖，再次运行flutter doctor命令，若提示如下图所示无任何问题，即完成flutter安装： 安装Flutter和Dart插件需要在Android Studio中安装两个插件: Flutter插件： 支持Flutter开发工作流 (运行、调试、热重载等). Dart插件： 提供代码分析 (输入代码时进行验证、代码补全等). 要安装这些: 启动Android Studio. 打开插件首选项 (File&gt;Settings&gt;Plugins). 选择 Browse repositories…, 选择 Flutter 插件并点击 install. 重启Android Studio后插件生效.","link":"/2018/09/29/Flutter安装指南(Ubuntu环境)/"},{"title":"Git常用命令总结","text":"本地分支命令 创建版本库git init 添加文件至仓库git add 提交文件至仓库git commit -m &quot;本次提交的说明&quot; 查看版本库当前状态git status 查看上次修改内容git diff 显示从最近到最远的提交日志git log 回退到上一个版本git reset --hard HEAD^ 每一个命令的记录git reflog 查看工作区和版本库里最新版本的区别git diff HEAD -- file 丢弃工作区的修改git checkout -- file 切换分支git checkout branch 把暂存区的修改撤销掉，重新放回工作区git reset HEAD &lt;file&gt; 从版本库删除文件，并提交git rm &lt;file&gt;git commit -m &quot;remove &lt;file&gt;&quot; 从版本库恢复删错的文件（等同于丢弃工作区的修改） git checkout -- &lt;file&gt; 分支管理 创建分支git branch &lt;branch&gt; 创建新分支并切换到该分支git checkout -b &lt;branch&gt; 查看当前分支git branch当前分支前会标一个*号 切换分支git checkout &lt;branch&gt; 合并指定分支到当前分支git merge &lt;dev branch&gt; 删除分支git branch -d &lt;branch&gt; 禁用fast forward模式合并分支git merge --no-ff -m &quot;merge with no-ff&quot; dev 藏匿当前工作现场git stash 查看藏匿的工作现场git stash list 恢复藏匿的工作现场git stash apply 删除stash内容git stash drop 恢复工作现场的同时并删除stash内容git stash pop 删除没有被合并过的分支git branch -D &lt;branch&gt; 查看远程仓库信息git remote, 更详细的信息用git remote -v 推送分支git push origin master 创建远程仓库的分支到本地git checkout -b dev origin/dev 抓取远程的新提交git pull 建立本地分支和远程分支的关联git branch --set-upstream dev origin/dev Git Cheat Sheet","link":"/2018/08/20/Git常用命令总结/"},{"title":"Golang安装指南(Ubuntu环境)","text":"Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. all the content in this article can find in Go official document Download the Go distributionwe can download go from Go official website and choice the right distribution of Go,the latest verison is 1.12.5 until I wrote this article: 1go1.12.5.linux-amd64.tar.gz Install the Go tools extract the archive into /usr/local 1tar -C -xzf go1.12.5.linux-amd64.tar.gz add PATH environment variable into /etc/profile 12345#golangexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport GOPATH=$HOME/workspace/goexport PATH=$PATH:$GOROOT/bin restart your computerthe changes will apply until next time your log into your computer Attentionthe install process in Go official guide have some misunderstanding part,such as the effect PATH environment variable is not export PATH=$PATH:/usr/local/go/bin,its not enough for runing go on Ubuntu.","link":"/2019/05/15/Golang安装指南(Ubuntu环境)/"},{"title":"Golang教程学习笔记","text":"本文内容总结自菜鸟教程Go语言教程和Golang官网 Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. 即Go 是一门开源的编程语言，使构建简单，可靠，有效的软件更加简单 go语言结构go语言的基础组成主要包括6个部分： 包声明 引入包 函数 变量 语句&amp;表达式 注释 示例代码： 123456package mainimport \"fmt\"func main(){ fmt.Println(\"hello world!\")} 第一行的package main定义了源文件的包名，我们必须在源文件非注释的第一行指明这个文件属于哪个包. package main表示该源文件为一个可独立执行的程序，每一个go应用程序都包含一个名为main的包 import “fmt”告诉go编译器这个程序需要使用fmt包（中的函数或其他元素），fmt包实现了格式化IO的函数 func main()是程序开始执行的函数，main函数是每一个可执行的程序所必需包含的，一般来说都是程序启动后第一个执行的函数（如果有init()函数则会先执行该函数） go的注释和java一样，分单行注释和多行注释 fmt.Println()可以将变量输出至控制台显示，实现格式化IO，输出函数有三种： Print Println Printf 和java的syso一样分别实现输出，输出换行，格式化输出，如果没有特别指定，print系函数将会以默认的打印格式输出变量 当一个identifier标识符（包括常量，变量，类型，函数名，结构字段等等）以一个大写字母开头，如Identifier1，那么使用这中标识符的对象就可以被外部包的代码所使用，前提是外部包需要先导入这个包；标识符如果已小写字母开头，则对外部包是不可见的，但是他们在整个包的内部是可用并可见的。这个特性像OOP中的public和protected关键字 {符号不能单独放在一行，否则代码在运行时会产生错误 执行go程序有两种方法 go run hello.go直接对源文件执行go run go build hello.go生成源文件的二进制文件，再运行该文件 go语言基本语法","link":"/2019/05/29/Golang教程学习笔记/"},{"title":"Hexo使用指南一(Ubuntu环境)","text":"前言按照Hexo官网的说法 Hexo 是一个快速、简洁且高效的博客框架. Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页. 利用Hexo,我们可以用极低的成本构建属于自己的博客，并且自动为博文分类和归档，这篇教程是我使用Hexo构建个人博客时候做的总结. 这份Hexo使用指南适用于Ubuntu环境，写这份指南时所用的操作系统版本为Ubuntu18.04.通过这份Hexo使用指南一，你可以快速掌握本地部署博客的方法. 完成本教程后，下一教程将会向您展示如何花费人民币1元的代价，购入属于自己的域名并与本教程中本地存在的Hexo博客关联. 安装前期环境在运行Hexo之前，需要安装两个必备的工具Node.js和Git. 在Terminal中执行以下命令： 安装Node.js 1$ sudo apt-get install nodejs 安装Git1$ sudo apt-get install git 安装Hexo安装完Hexo运行所必备的两个组件后，接下来就可以安装Hexo啦 安装Hexo 1$ sudo npm install hexo-cli -g 安装Hexo完成后可以使用 1$ hexo -v 查看Hexo是否正确安装上 初始化Hexo环境 创建您想保存Hexo的文件夹(建议在主目录下新建blog文件夹，便于使用和管理所有blog) 1$ mkdir blog 进入blog文件夹下 1$ cd blog 初始化Hexo环境(此处叫myblog1,可自定义Hexo环境文件夹名，最好与域名相同，便于查找和管理) 1~/blog$ hexo init myblog1 上述命令执行完成后，可发现/blog文件夹中，新出现了一个myblog1文件夹 进入myblog1文件夹发现其文件结构如下： 其中 node_modules : 依赖包 scaffolds : 生成文章的模板 source : 所有博客文章 themes : 主题 _config.yml : 博客的配置文件 db.json : 解析source的到的文件 package.json : Hexo及其依赖包的版本信息 本教程中使用的只有_config.yml文件和source, themes文件夹 清空Hexo环境 1$ hexo clean 生成Hexo静态文件 1$ hexo generate 上传到本地虚拟服务器 1$ hexo server 当命令行出现以下内容，恭喜你，您的博客已成功部署在本地虚拟服务器，点击链接http://localhost:4000/即可在浏览器中查看自己的博客 发布文章 在myblog1目录下使用hexo new post &lt;博文名&gt;来创建新博文,例如：1$ hexo new post myfirstblogarticle hexo new [layout] &lt;title&gt;命令的layout参数有三种,分别为： post : 发布博文 page : 发布新页面 draft : 发布草稿 具体区别和更多关于Hexo博文的知识点可在Hexo官网的 帮助文档中查看 进入source目录中的_posts目录，新创建的myfirstblogarticle.md博文被创建在此，格式为markdown,可在简书的markdown新手指南中了解书写博客的基本格式. 使用主题博客的主题最能体现博主的风格，相信大家都很在意. Hexo初始化环境默认使用的皮肤为landscape,更多皮肤可以在Hexo官网的themes中挑选并拷贝到themes文件夹中，本教程用hipaper主题作介绍 进入themes文件夹,用git将hipaper主题下载至文件夹内1$ git clone git@github.com:iTimeTraveler/hexo-theme-hipaper.git 如果不会使用Git，建议查看廖雪峰的Git教程 为使用主题的搜索功能，需安装hexo-generator-json-content 工具 1$ npm install -S hexo-generator-json-content 为hipaper主题配置tags, categories, about页面 由于hipaper主题默认只开启了archives(归档)功能，所以标签，分类，简介页面需要靠代码开启 123$ hexo new page tags$ hexo new page categories$ hexo new page about 执行完毕进入source文件夹，发现其中多了about, categories, tags三个子文件夹，且都包含一个名为index.md的文件，以/soucce/about/index.md为例，分别将三个不同的index.md文件中加入一行代码 原代码为： 1234---title: aboutdate: xxxx-xx-xx xx:xx:xx--- 增加一行代码，改为： 12345---title: aboutdate: xxxx-xx-xx xx:xx:xxlayout: about--- tags和categoroes文件夹中的index.md文件也作相应更改，layout参数值就是title参数值,至此，hipaper主题配置完成.","link":"/2018/08/14/Hexo使用指南一(Ubuntu环境)/"},{"title":"Hexo使用指南二(Ubuntu环境)","text":"絮叨完成Hexo使用指南一中的步骤仅仅是将Hexo博客布置到本地的服务器中，怎么样让更多的人通过互联网直接访问你的博客呢？需要的仅仅是通过几个简单的步骤将你在指南一中生成的博客部署到github上. 通过github中你的个人域名来访问你的博客，这样所有人都可以在互联网上访问你的博客了. 值得一提的是，github所提供的个人域名的标准格式为username.github.io, 其中username为你注册的github账号用户名. 虽然域名形式上已经很简单了，但更多的人还是喜欢自己个性化定制的域名, 例如理发店的tony老师可能希望自己的博客域名为tony.com而不是相对复杂的tony.github.io, 本套教程就教你如何用一元人民币的代价来部署属于你的博客在你的个人域名上. 因此完成本套教程的前提为： 注册一个github账号 拥有一块钱 新建github个人域名repository 百度百科对github网站的定义为： gitHub是一个面向开源及私有软件项目的托管平台，因为只支持git 作为唯一的版本库格式进行托管，故名gitHub 注册并登陆github 新建reposotory(后均简称repo)repo可理解为保存代码的仓库，点击主页右上角的+符号，新建new repo命名为&lt;你的github账号名&gt;.github.io,如下所示： 复制该repo的SSH链接地址进入上述步骤建立的名为&lt;你的github账号名&gt;.github.io的repo，点击绿色的clone and download按钮选择SSH方式，复制链接如果主机没有为github配置SSH公匙，请百度一下如何为github配置SSH链接 建立本地Hexo博客与github个人域名的连接 打开mybolg1目录下的_config.yml文件，将文件底部的deploy:代码由 12deploy: type: 更改为 1234deploy: type: git repo: git@github.com:&lt;你的github账号名&gt;/&lt;你的github账号名&gt;.github.io.git //此处即填写复制的repo链接 branch: master 保存文件，并在Hexo博客的根目录下，按序执行： 清空Hexo缓存文件 1$ hexo clean 生成新的Hexo缓存文件 1$ hexo generate -部署Hexo至github仓库 1$ hexo deploy 待上述代码执行完毕，在网页中打开链接&lt;你的github账号名&gt;.github.io，如果你看到了你的个人博客，恭喜你，你已经成功在互联网上搭建了属于自己的个人博客了！ 注册个人自定义域名互联网上可以注册域名的网站有很多，例如阿里云, 腾讯云等. 本教程使用腾讯云来注册个人域名，其他网站的注册域名流程均大同小异. 注册一个域名 登陆腾讯云，根据自己的经济实力注册一个自己所需的域名，按步骤操作，最后交钱就行了.我们还以理发店的Tony老师为例，他注册了一个名为BarberTony.com的域名，由于这个域名档次较高，尊贵无比，所以租用该域名一年要价人民币59元，而笔者生活较为贫苦，无法大手笔购入高价域名，所以买了zhangyuyang.club的域名，租用该域名一年只需1元钱，合情合理，很舒服. 绑定Hexo域名与自定义域名 查看github个人域名外网IP在Terminal终端中用ping命令，查看github个人域名外网IP1$ ping &lt;你的github账号名&gt;.github.io 得到如下结果： 其中的185.199.110.153即为你的github个人域名外网IP 为您购买的自定义域名设置DNS解析进入腾讯云后台，点击我的域名，选择您购买的域名，点击域名解析-&gt;新手快速添加点击网站解析后，将主机地址设置为你的github个人域名外网IP 为Hexo本地文件配置自定义域名进入Hexo本地目录(本教程中为myblog1目录)中的source目录1$ cd source 在source目录下新建一个文件，名为CNAME,向其写入你购买的自定义域名 1$ gedit CNAME 保存文件，用hexo clean,hexo generate,hexo deploy命令重新部署Hexo至github. 打开浏览器，输入你的自定义域名，恭喜你，你已经在互联网上拥有属于自己的个性域名的博客了！","link":"/2018/08/15/Hexo使用指南二(Ubuntu环境)/"},{"title":"Insight及LB模块定位问题通用checklist","text":"Insight历史日志最近五分钟查询不到ES日志由于我们的VM配置为单核8G内存，对于收集整个集群的日志而言，VM的配置过低（内存较小）。在单节点ES上该问题暂时无法解决。 部署ES后收集不到日志该问题可能有两个不同的原因导致： ES节点磁盘写满，filebeat不再写入数据ssh登陆Elasticsearch节点后台（假定节点192.168.133.32）： 1ssh root@192.168.133.32 查看文件系统的磁盘空间占用情况： 1df -h 出现如下内容： 12345678910111213Filesystem Size Used Avail Use% Mounted on/dev/vda1 25G 1.6G 24G 7% /devtmpfs 3.9G 0 3.9G 0% /devtmpfs 3.9G 0 3.9G 0% /dev/shmtmpfs 3.9G 17M 3.9G 1% /runtmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup/dev/vdb1 80G 33M 80G 1% /var/lib/kubelet/dev/vdb2 60G 44G 17G 73% /var/lib/docker/dev/vdb3 60G 33M 60G 1% /gluster192.168.133.32:/root/nfs 25G 1.6G 24G 7% /mntoverlay 60G 44G 17G 73% /var/lib/docker/overlay2/d792933239303e66a22bd5f88287dc2ba1c8ecb34a2d50b3e0d931f2613c0c6c/mergedoverlay 60G 44G 17G 73% /var/lib/docker/overlay2/25b9eb7ae4a75734fa41c0aac2eb03fc2dbae176b24f7a5792978e253974a269/mergedtmpfs 783M 0 783M 0% /run/user/0 可以看到运行ES和kibana容器的docker所在的挂载路径/dev/vdb2当前还有17G的存储空间可用，即可排除ES节点磁盘写满的原因导致ES后收集不到日志。 如果/dev/vdb2的存储空间已经耗尽，filebeat监测到ES节点存储空间耗尽后，filebeat会标记自己为不写入状态，因此ES后收集不到日志，此时需要执行两步操作： 删除ES中保存的日志信息1curl -XDELETE http://192.168.133.32:9200/_all Hint: 删除完后查询全部index，以确认是否删除 1curl http://192.168.133.32:9200/_cat/indices?v 重启集群所有filebeat pod1kubectl delete pod filebeat-xxxxxxxx 每个filebeat的pod都要重启 单节点ES部署失败ssh登陆Elasticsearch节点后台（假定节点192.168.133.32）： 1ssh root@192.168.133.32 查询ES部署信息： 1curl &apos;http://192.168.133.32:9200/_nodes/http?pretty&apos; 出现如下信息： 1234567891011121314151617181920212223242526272829303132333435363738{ &quot;_nodes&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;nodes&quot; : { &quot;pgnaBbRGSOKJeeuq31tLcQ&quot; : { &quot;name&quot; : &quot;pgnaBbR&quot;, &quot;transport_address&quot; : &quot;192.168.133.32:9300&quot;, &quot;host&quot; : &quot;192.168.133.32&quot;, &quot;ip&quot; : &quot;192.168.133.32&quot;, &quot;version&quot; : &quot;6.5.4&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;d2ef93d&quot;, &quot;roles&quot; : [ &quot;master&quot;, &quot;data&quot;, &quot;ingest&quot; ], &quot;attributes&quot; : { &quot;ml.machine_memory&quot; : &quot;6442450944&quot;, &quot;xpack.installed&quot; : &quot;true&quot;, &quot;ml.max_open_jobs&quot; : &quot;20&quot;, &quot;ml.enabled&quot; : &quot;true&quot; }, &quot;http&quot; : { &quot;bound_address&quot; : [ &quot;[::]:9200&quot; ], &quot;publish_address&quot; : &quot;192.168.133.32:9200&quot;, &quot;max_content_length_in_bytes&quot; : 104857600 } } }} 如果上述信息中publish_address字段的内容是0.0.0.0:9200，说明ES部署的有问题，没有配host地址，删了重新部署吧 监控图不显示通常是prometheus的pod没有起来，可能是因为资源不够无法调度，进入集群后台查询promethues状态 1kubectl get pod -A | grep prometheus 正常情况应输出如下内容： 1kube-system monitoring-prometheus-prometheus-v1-0-0 3/3 Running 1 2d9h 如果prometheus非running状态，可能是因为节点上资源不够无法调度，杀掉其他的pod，让prometheus运行起来就完事了","link":"/2019/08/29/Insight及LB模块定位问题通用checklist/"},{"title":"Java多线程基础","text":"当我们执行一些耗时操作时，如果不将这类操作放置在子线程中运行，可能导致主线程被堵塞。 多线程的用法1： 继承Thread类新建一个类继承Thread，然后重写父类的run()方法，在里面编写耗时逻辑。 1234567class SubThread extends Thread{ @Override public void run(){ //处理具体的逻辑 }} 启动线程只需要new出SubThread的实例，然后调用它的start()方法。 1new SubThread().start(); 多线程的用法2： 实现Runnable接口新建一个类实现Runnable接口，重写接口的run()方法 123456class SubThread implements Runnable{ @Override public void run(){ //处理具体的逻辑 }} 启动线程的需要new出实现了runnable接口的SubThread实例，将其传入Thread的构造函数中，接着调用Thread的start()方法。 多线程的用法3： Thread构造方法传入Runnable匿名类如果你不想专门定义一个类去实现Runnable接口，可以用匿名类的方式 12345678new Thread(new Runnable(){ @Override public void run(){ //处理具体的逻辑 }}).start();","link":"/2018/10/22/Java多线程基础/"},{"title":"Kafka Dockerimage Instruction","text":"Comprisalkafaka needs Java(JDK 8) and zookeeper as prerequisite so we should prepare a docker container within JDK8 Create docker container with JDK81docker run -d openjdk:8 then u get the docker container within JDK8 that runs in backgroud Hint: docker psfor find this container id,such as 26aa42c88586 Download Kafkaget latest kafaka tar in Kafka Offical website, the kafka version in this doc is kafka_2.12-2.3.0.tgz Copy Kafka into containerin this case, we imagine the container id is 26aa42c88586 1docker exec -it 26aa42c88586 bash create directory called kafka 1root@26aa42c88586:/# mkdir kafka back to outside of cantianer,and transit kafka tar into container 1docker cp Downloads/kafka_2.12-2.3.0.tgz 26aa42c88586:/kafka/kafka_2.12-2.3.0.tgz Decompress Kafkago into directory kafka 1root@26aa42c88586:/# cd kafka/ decompress kafka tar 1tar -xzf kafka_2.12-2.3.0.tgz go into directory kafka_2.12-2.3.0 1root@26aa42c88586:/kafka# cd kafka_2.12-2.3.0 Run zookeeperconfigure config/zookeeper.properties 1234567891011121314151617181920# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the &quot;License&quot;); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# the directory where the snapshot is stored.dataDir=/root/kafka/log-zookeeper# the port at which the clients will connectclientPort=2181# disable the per-ip limit on the number of connections since this is a non-production configmaxClientCnxns=0 then start zookeeper 1root@26aa42c88586:/kafka# bin/zookeeper-server-start.sh config/zookeeper.properties when it finish ,u will see some log like: 12345678910111213[2019-08-05 11:56:32,689] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,689] INFO Server environment:java.compiler=&lt;NA&gt; (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,689] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,689] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,690] INFO Server environment:os.version=4.9.125-linuxkit (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,690] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,691] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,691] INFO Server environment:user.dir=/kafka/kafka_2.12-2.3.0 (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,709] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,709] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,709] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)[2019-08-05 11:56:32,727] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)[2019-08-05 11:56:32,739] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory) DO NOT CLOSE THIS TERMINAL WINDOW, JUST HOLD IT. Run kafka serverGotcha: u should excute this step in another termial window by excuting command +T in ur termials configure config/server.properties 1234567listeners=PLAINTEXT://0.0.0.0:9092advertised.listeners=PLAINTEXT://192.168.133.30:9092 //your real hostnamelog.dirs=/root/kafka/log-kafkazookeeper.connect=localhost:2181 1docker exec -it 26aa42c88586 bash when u go into the container bash, start kafka server 1root@26aa42c88586:/kafka# bin/kafka-server-start.sh config/server.properties then u will see some new log like: 12345678910[2019-08-05 11:57:12,846] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)[2019-08-05 11:57:12,894] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)[2019-08-05 11:57:12,897] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)[2019-08-05 11:57:12,897] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)[2019-08-05 11:57:12,977] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)[2019-08-05 11:57:13,008] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)[2019-08-05 11:57:13,028] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)[2019-08-05 11:57:13,028] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)[2019-08-05 11:57:13,028] INFO Kafka startTimeMs: 1565006233011 (org.apache.kafka.common.utils.AppInfoParser)[2019-08-05 11:57:13,033] INFO [KafkaServer id=0] started (kafka.server.KafkaServer) Create a topicI just create a topic called octopusheep, u can choose any topic name u like by replacing this field 1root@26aa42c88586:/kafka# bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic octopusheep Gotcha: bin/kafka-topics.sh --list --bootstrap-server localhost:9092 can query all topic u created in this container/host Send some messageRun the producer and then type a few messages into the console to send to the server 1234root@26aa42c88586:/kafka# bin/kafka-console-producer.sh --broker-list localhost:9092 --topic octopusheep&gt; hello world!&gt; he gives man speech, and speech created thoughts, which is the measure of the universe. start a consumerKafka also has a co∑mmand line consumer that will dump out messages to standard output. 1234root@26aa42c88586:/kafka/kafka_2.12-2.3.0# bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic octopusheep --from-beginninghello world!he gives man speech, and speech created thoughts, which is the measure of the universe. now u can see the message sent by producer can be received to consumer.","link":"/2019/08/08/Kafka Dockerimage Instruction/"},{"title":"Kubernetes负载均衡学习笔记","text":"该内容总结自19/07/10韩欢乐老师所讲解的负载均衡内容 基本知识最早负载均衡器是由硬件F5提供 两种经典的四层lb方式 NAT direct route http与https规则的区别：四层之上多了TLS加密层，再到http lb的实现方式； F5 HAProxy nginx ingress-nginx（包含web和反向代理） ipvs（四层） istio（适合微服务） K8s负载均衡常用命令ssh root@ip 进入负载均衡器后台docker ps|grep proxy|grep nginx 搜索docker中运行lb的容器iddocker container exec -it fc8e583fde24 bash 进入lb容器后台cat nginx.conf |grep proxy_buffer 查看proxy_buffers的配置 kubectl get –all-namespaces loadbalancers 查看CPS当前的lb资源kubectl get –all-namespaces configmap -owide 查看CPS当前的configmap资源kubectl describe -n kube-system loadbalancer apiserver 查看lb配置 kubectl get ingress 查看http规则kubectl get cm -n kube-system lb-2011287880-proxy-nginx-tcp -oyaml 查看tcp/udp规则 kubectl describe ingress domain-ingress 负载均衡规则详情kubectl get -n p1 ingress rule1 -oyaml","link":"/2019/07/11/Kubernetes负载均衡学习笔记/"},{"title":"LDAP Studying Note","text":"LDAP（Light Directory Access Portocol），它是基于X.500标准的轻量级目录访问协议。 What is LDAPLDAP是指轻量级目录访问协议，LDAP目录服务由目录数据库和一套访问协议组成 目录目录是一个为查询、浏览和搜索而优化的数据库，它成树状结构组织数据，类似文件目录一样 目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。 LDAP的基本模型概念目录树在一个目录服务系统中，整个目录信息集可以表示为一个目录信息树，树中的每个节点是一个条目。 条目每个条目就是一条记录，每个条目有自己的唯一可区别的名称（DN）。 对象类与某个实体类型对应的一组属性，对象类是可以继承的，这样父类的必须属性也会被继承下来 属性描述条目的某个方面的信息，一个属性由一个属性类型和一个或多个属性值组成，属性有必须属性和非必须属性 AcronymDC domain component域名的部分，其格式是将完整的域名分成几部分，如域名为example.com变成dc=example,dc=com（一条记录的所属位置） UID user id用户ID yuyang.zhang（一条记录的ID） OU organization unit组织单位，组织单位可以包含其他各种对象（包括其他组织单元），如“QA组”（一条记录的所属组织） CN common name公共名称，如“Joey Young”（一条记录的名称） SN surname姓，如“章” DN distinguished name“uid=yuyang.zhang,ou=QA组,dc=example,dc=com”，一条记录的位置（唯一） RDN relative distinguished name相对辨别名，类似于文件系统中的相对路径，它是与目录树结构无关的部分，如“uid=yuyang.zhang”或“cn=Joey Young” 基本模型信息模型在LDAP中信息以树状方式组织，在树状信息中基本数据单元是条目，每个条目由属性组成，属性中存储有属性值 命名模型LDAP的命名模型是条目定位方式，在LDAP中每个条目都有自己的DN，DN是该条目在整个树中的唯一名称标识，如同文件系统中，带路径的文件名就是DN 功能模型在LDAP中共有四类10种操作： 查询类操作 搜索、比较 更新类操作 添加条目、删除条目、修改条目、修改条目名 认证类操作 绑定、解绑 其他操作 放弃、扩展操作 安全模型LDAP的安全模型主要通过身份认证、安全通道和访问控制来实现 LDAP的使用统一身份认证主要是改变原有的认证策略，使需要认证的软件都通过LDAP进行认证，在统一身份认证之后，用户的所有信息都存储在AD Server中。终端用户在需要使用公司内部服务的时候，都需要通过AD服务器的认证。 以PHP脚本作为例子： 12345$ldapconn = ldap_connect(“10.1.8.78&quot;)$ldapbind = ldap_bind($ldapconn, &apos;username&apos;, $ldappass);$searchRows= ldap_search($ldapconn, $basedn, &quot;(cn=*)&quot;);$searchResult = ldap_get_entries($ldapconn, $searchRows);ldap_close($ldapconn); 连接LDAP服务器 绑定到LDAP服务器 在LDAP服务器上执行所需的任何操作 释放LDAP服务器的连接 LDAP Filter Note运算符 等于(EQUAL TO)： = 大于等于(Greater than)： &gt;= 小于等于(Less than)： &lt;= 通配符(wildcard)： * 逻辑运算符 逻辑与(logical AND)： &amp; 逻辑或(logical OR)： | 逻辑非(logical NOT)： ! 举例操作以用户信息存储来举例，假设，用户目录树ou=user,dc=domain，结构如下： 123456dc=domain |-ou=user |-cn=zhangsan |-cn=lisi |-cn=wangwu |-cn=zhaoliu 用户信息属性如下： 123456789cn=zhangsanobjectClass=topobjectClass=personname=张三sex=男age=28pwd=123456email=zhangsan@163.comdesc=描述 查询所有name为张三，sex为男的用户 (&amp;(name=张三)(sex=男)) 查询所有age不为28的用户 (!(age=28)) 查询所有age为28，并且name不为张三的用户 (&amp;(age=28)(!(name=张三))) 查询所有age为28，或者name为张三的用户 (|(age=28)(name=张三)) 查询所有name的姓为张，或者desc包含描述的用户 (|(name=张*)(desc=*描述*)) 查询所有有email为空的用户 (email=) 查询所有没有desc属性的用户 (!(desc=*)) 查询所有有desc属性的用户 (desc=*)","link":"/2019/11/20/LDAP Studying Note/"},{"title":"LDAP服务部署实践","text":"LDAP服务由ladpadmin和ldapserver两个无状态服务组成 新建应用分区创建LDAP服务专用的应用分区 ladpadmin服务容器配置 镜像名称：osixia/phpldapadmin:latest CPU请求：0.5Core CPU上限：1Core 内存请求：1GiB 内存上限：2GiB PHPLDAPADMIN_LDAP_HOSTS:ldapserver PHPLDAPADMIN_HTTPS:false 访问配置ldapadmin 访问类型：集群内访问 访问端口：HTTP协议/80容器端口 ldapadminnodeport32000 访问类型：集群外访问 访问端口：HTTP协议/80容器端口/32000节点端口 ldapserver服务容器配置 镜像名称：osixia/openldap CPU请求：0.5Core CPU上限：1Core 内存请求：1GiB 内存上限：2GiB 访问配置ldapserver 访问类型：集群内访问 访问端口1：TCP协议/389容器端口 访问端口2：UDP协议/389容器端口 ldap服务器设置 服务器地址：ldapserver.ldap 端口：389 账号：cn=admin,dc=example,dc=org 密码：admin BaseDN：dc=example,dc=org 账号字段：cn 姓名字段：sn 邮箱字段：mail 另一种部署方式：docker run123docker run -p 389:389 --name myopenldap --network bridge --hostname openldap-host --env LDAP_ORGANISATION=&quot;mylitboy&quot; --env LDAP_DOMAIN=&quot;mylitboy.com&quot; --env LDAP_ADMIN_PASSWORD=&quot;ldap123&quot; --detach osixia/openldapdocker run -d --privileged -p 10004:80 --name myphpldapadmin --env PHPLDAPADMIN_HTTPS=false --env PHPLDAPADMIN_LDAP_HOSTS=10.1.1.12 --detach osixia/phpldapadmin","link":"/2019/11/26/LDAP服务部署实践/"},{"title":"Linux缺少libpng12-0依赖的解决方法","text":"在安装SP_Flash_Tool时命令行出现如下提示，导致程序无法正常使用 12/SP_Flash_Tool/flash_tool: error while loading shared libraries: libpng12.so.0: cannot open shared object file: No such file or directory 解决步骤经查stackoverflow,原因是因为 It says there is not libpng on your system. I’m not familiar with Kali, but if this thread is correct, you’ll have to compile from source 即系统里没有libpng这个依赖 具体解决步骤如下： 从debian下载libpng 命令行执行安装 1dpkg -i libpng12-0_1.2.50-2+deb8u2_amd64.deb 1apt-get install -f 运行SP_Flash_Tool 1sudo /SP_Flash_Tool/flash_tool","link":"/2018/09/21/Linux缺少libpng12-0依赖的解决方法/"},{"title":"Python Studying Note","text":"update at 7:10pm sep8 2019 Install Pythonin macos we need to install python3 edition instead og python2 download py3 in offical website and run python3 in teminals First python programremember the difference between command mode and python interactive mode commadn mode: 1Mac:~ zhangyuyang$ python interactive mode: 12345Mac:~ zhangyuyang$ python3Python 3.7.4 (v3.7.4:e09359112e, Jul 8 2019, 14:54:52)[Clang 6.0 (clang-600.0.57)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; typeexit()in python interactive mode,which can bakc to commadn mode first py program: 12345678910Mac:~ zhangyuyang$ python3Python 3.7.4 (v3.7.4:e09359112e, Jul 8 2019, 14:54:52)[Clang 6.0 (clang-600.0.57)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 100+200300&gt;&gt;&gt; print(&quot;happy boy and smart girl who wanna laugh&quot;)happy boy and smart girl who wanna laugh&gt;&gt;&gt; exit()Mac:~ zhangyuyang$ under command mode,we can type python3 to enter python interactive mode or typepython3 demo.py to run a .py document Running .py directlyadd special annotation in first line of .py 123#!/usr/bin/env python3print(&apos;Hello World!&apos;) usingchmod a+x demo.py to change auth of .py print()print()can accept lots of string as parameter and using ,to partitionand , in print() will output a blankspace in terminal input()python provide input() to save a type-in string into a variety 123456789Mac:~ zhangyuyang$ pPython 3.7.4 (v3.7.4:e09359112e, Jul 8 2019, 14:54:52)[Clang 6.0 (clang-600.0.57)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; name=input()octopusheep&gt;&gt;&gt; name&apos;octopusheep&apos;&gt;&gt;&gt; input()can receive string parameter as reminder text when user input something 123Mac:Public zhangyuyang$ p demo_helloname.pyplease enter your name:zhangyuyanghello, zhangyuyang Basic syntaxthe sentence begin with # is annotation when sentence ends with :,means the sentence after it was a code block we common use 4 blank space as abbr python is sensetive for upcase and downcase data type int 1,100,-8080,0,0xff00,0xa9023fe hex must use 0-9 and a-f float 1.23，3.14，-9.01,12e-9,1.2e-8 string 'abc'，&quot;xyz&quot;,&quot;I'm OK&quot; trans sign\\: \\n,\\t,\\\\ python allow using r'',r''' ''' to manifest there is no any alpha needs to be transfer multi-line string using ''' boolean boolean value is equal with boolean algebra,it only can be present by True or false, please pay attention to its upcase first alpha boolean can calculate with and,or,not None value just None variety variety can be any data type and be declare by name rule: number upC or downC alpha and _, the first location can not be a number if variety’s type can be changed, those language be called dynamic language, in the verse, which one be called static language constant using all upcase alpha to declare a constant like PI String and coding8 bit = 1 byte ASCII using 1 byte to save a alpha Unicode using 2 byte to save a alpha UTF-8 using 1 byte to save a English alpha and using more than 3 byte to save a Chinese alpha if the data have a lot of enlish alpha, using UTF-8 can save space the another advantage of UTF-8 is that ASCII can be a part of UTF-8, which means lots of historical software using ASCII can working in UTF-8 env there only use Unicode in Memory string in python3in python3, string be code by Unicode, which means python support multi-language 12&gt;&gt;&gt; print(&apos;你好呀xixixi&apos;)你好呀xixixi ord() change single string as coding number 12&gt;&gt;&gt; ord(&apos;你&apos;)20320 chr() change coding number as single string 123456&gt;&gt;&gt; chr(88)&apos;X&apos;&gt;&gt;&gt; chr(66)&apos;B&apos;&gt;&gt;&gt; chr(25991)&apos;文&apos; b'content' means bytes type data encode() Unicode str can be encode specific bytes 12345678&gt;&gt;&gt; &apos;aBc&apos;.encode(&apos;ascii&apos;)b&apos;aBc&apos;&gt;&gt;&gt; &apos;阳仔007真的很牛匹&apos;.encode(&apos;utf-8&apos;)b&apos;\\xe9\\x98\\xb3\\xe4\\xbb\\x94007\\xe7\\x9c\\x9f\\xe7\\x9a\\x84\\xe5\\xbe\\x88\\xe7\\x89\\x9b\\xe5\\x8c\\xb9&apos;&gt;&gt;&gt; &apos;阳仔007真的很牛匹&apos;.encode(&apos;ascii&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;UnicodeEncodeError: &apos;ascii&apos; codec can&apos;t encode characters in position 0-1: ordinal not in range(128) decode() bytes can be decode as a Unicode str 123456789101112131415&gt;&gt;&gt; b&apos;AbF&apos;.decode(&apos;utf-8&apos;)&apos;AbF&apos;&gt;&gt;&gt; b&apos;AbF&apos;.decode(&apos;ascii&apos;)&apos;AbF&apos;&gt;&gt;&gt; b&apos;\\xe4\\xb8&apos;.decode(&apos;ascii&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;UnicodeDecodeError: &apos;ascii&apos; codec can&apos;t decode byte 0xe4 in position 0: ordinal not in range(128)&gt;&gt;&gt; b&apos;\\xe4\\xb8&apos;.decode(&apos;utf-8&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;UnicodeDecodeError: &apos;utf-8&apos; codec can&apos;t decode bytes in position 0-1: unexpected end of data&gt;&gt;&gt; b&apos;\\xe4\\xb8\\xad&apos;.decode(&apos;utf-8&apos;)&apos;中&apos;&gt;&gt;&gt; if bytes contains some invalid byte, decode() will get error 1234&gt;&gt;&gt; b&apos;\\xe4\\xb8\\xad\\xff&apos;.decode(&apos;utf-8&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;UnicodeDecodeError: &apos;utf-8&apos; codec can&apos;t decode byte 0xff in position 3: invalid start byte but if bytes just contains a part of invalid byte, ad parameter errors into decode() 12&gt;&gt;&gt; b&apos;\\xe4\\xb8\\xad\\xff&apos;.decode(&apos;utf-8&apos;,errors=&apos;ignore&apos;)&apos;中&apos; len() len() can show how many single string contained in Unicode str or show how many byte contained in specific bytes 1234&gt;&gt;&gt; len(&apos;octopusheep&apos;)11&gt;&gt;&gt; len(&apos;阳仔007&apos;)5 1234&gt;&gt;&gt; len(b&apos;octopusheep&apos;)11&gt;&gt;&gt; len(b&apos;\\xe7\\xab\\xa0\\xe5\\xae\\x87\\xe9\\x98\\xb3&apos;)9 Gotcha: if py code contains chinese alpha, we need add following annotations at the head of py code 12#!/usr/bin/env python3# -*- coding: utf-8 -*- make sure your text editor save code encoded in UTF-8 without BOM format stringusing % to format string 12&gt;&gt;&gt; &apos;Hi, %s, you have $%d in our bank.&apos;%(&apos;octopusheep&apos;,23333)&apos;Hi, octopusheep, you have $23333 in our bank.&apos; %d format int %s format string %f format float %x format hex int %% can transfer % as a common alpha format()format() can format string by call method 12&gt;&gt;&gt; &apos;Hi!{0},your investment incresing rate is {1:.3f}% now&apos;.format(&apos;octopusheep&apos;,2.33333333333333)&apos;Hi!octopusheep,your investment incresing rate is 2.333% now&apos; list and tuplelist is a kind of python data type list is a ordered element lollection and can insert/delete element at any time 123&gt;&gt;&gt; octopusheep=[&apos;handsome&apos;,&apos;happy&apos;,&apos;ensusiastic&apos;]&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;ensusiastic&apos;] len() can get list element count 12&gt;&gt;&gt; len(octopusheep)3 using index to get certain element in list 12345678910111213141516171819202122&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;ensusiastic&apos;]&gt;&gt;&gt; octopusheep[0]&apos;handsome&apos;&gt;&gt;&gt; octopusheep[1]&apos;happy&apos;&gt;&gt;&gt; octopusheep[2]&apos;ensusiastic&apos;&gt;&gt;&gt; octopusheep[3]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range&gt;&gt;&gt; octopusheep[-1]&apos;ensusiastic&apos;&gt;&gt;&gt; octopusheep[-2]&apos;happy&apos;&gt;&gt;&gt; octopusheep[-3]&apos;handsome&apos;&gt;&gt;&gt; octopusheep[-4]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range using negative index can get last element by order append()insert element into list at last index 123&gt;&gt;&gt; octopusheep.append(666)&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;ensusiastic&apos;, 666] insert()insert element into list at specific index 12345&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;ensusiastic&apos;, 666]&gt;&gt;&gt; octopusheep.insert(2,&apos;tough&apos;)&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;tough&apos;, &apos;ensusiastic&apos;, 666] pop()pop()can delete last element in list 123456&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;tough&apos;, &apos;ensusiastic&apos;, 666]&gt;&gt;&gt; octopusheep.pop()666&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;tough&apos;, &apos;ensusiastic&apos;] pop()also can delete element in list by specific index 123456&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;tough&apos;, &apos;ensusiastic&apos;]&gt;&gt;&gt; octopusheep.pop(2)&apos;tough&apos;&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;ensusiastic&apos;] change element value in listgiven value directly 12345&gt;&gt;&gt; octopusheep[&apos;handsome&apos;, &apos;happy&apos;, &apos;ensusiastic&apos;]&gt;&gt;&gt; octopusheep[0]=&apos;very handsome&apos;&gt;&gt;&gt; octopusheep[&apos;very handsome&apos;, &apos;happy&apos;, &apos;ensusiastic&apos;] list element can be list 123&gt;&gt;&gt; octopusheep.append([&apos;flamboyant&apos;,&apos;invincible&apos;])&gt;&gt;&gt; octopusheep[&apos;very handsome&apos;, &apos;happy&apos;, &apos;ensusiastic&apos;, [&apos;flamboyant&apos;, &apos;invincible&apos;]] if a list do not have any element,its length is zero 123&gt;&gt;&gt; L=[]&gt;&gt;&gt; len(L)0 – tuple is another kind of list, but element of tuple is fixed 123&gt;&gt;&gt; zhangyuyang=(1,2,&apos;hard&apos;,True)&gt;&gt;&gt; zhangyuyang(1, 2, &apos;hard&apos;, True) define a empty tuple 123&gt;&gt;&gt; emptytuple=()&gt;&gt;&gt; emptytuple() define a tuple that have only one element needs add , in parameter list 123&gt;&gt;&gt; tuple_only_one_element=(233,)&gt;&gt;&gt; tuple_only_one_element(233,) when python show tuplethat have only one element, it will add , automaticlly if element of tuple is a list,the element value of this list can be changed, because tuple just storage the ref of element 123456&gt;&gt;&gt; tuple_have_element_is_list=(1,2,[3,4])&gt;&gt;&gt; tuple_have_element_is_list(1, 2, [3, 4])&gt;&gt;&gt; tuple_have_element_is_list[2][0]=9999&gt;&gt;&gt; tuple_have_element_is_list(1, 2, [9999, 4]) conditional judgein python, using if syntax to complete conditional judge 12345678910age = 3if age &gt;18: print(&apos;your age is&apos;,age) print(&apos;adult&apos;)elif age &gt;6: print(&apos;your age is&apos;,age) print(&apos;teenager&apos;)else: print(&apos;your age is&apos;,age) print(&apos;kid&apos;) if judgement condition can be simplify, if variety is non-zero number or non-null string or list, the judgement result is True 12345x=input(&apos;input something here:&apos;)if x: print(&apos;True&apos;)else: print(&apos;False&apos;) int()when we use input() to get what user type into PC, we just get string type data, we should use int() to transfer its type in this case, i don’t transfer str to int 12345birthday=input(&apos;please type your birth year here:&apos;)if birthday&gt;2000: print(&apos;after 2000&apos;)else: print(&apos;before 2000&apos;) then show this error: 123456~/Public » p demo_transferint.py zhangyuyang@Macplease type your birth year here:1984Traceback (most recent call last): File &quot;demo_transferint.py&quot;, line 2, in &lt;module&gt; if birthday&gt;2000:TypeError: &apos;&gt;&apos; not supported between instances of &apos;str&apos; and &apos;int&apos; so we must transfer type to correct 123456birthday=input(&apos;please type your birth year here:&apos;)birthday=int(birthday)if birthday&gt;2000: print(&apos;after 2000&apos;)else: print(&apos;before 2000&apos;) then we can fix this type-relative issue the py program to calculate bmi123456789101112height=float(input(&apos;plz input your height:&apos;))weight=float(input(&apos;plz input your weight:&apos;))bmi = weight/(height*height)print(&apos;your bmi is&apos;,bmi)if bmi&lt;18.5: print(&apos;too light&apos;)elif bmi &gt;=18.5 and bmi&lt;25: print(&apos;normal&apos;)elif bmi &gt;=25 and bmi&lt;28: print(&apos;fat&apos;)elif bmi &gt;=28 and bmi&lt;32: print(&apos;seriously fat&apos;) circleforin circlefor in circle can show every element in list or tuple by order 123names=[&apos;zyy&apos;,&apos;yyy&apos;,&apos;ayy&apos;]for name in names: print(name) range() and list()range() can create an int array, then using list() to make it to a list 12&gt;&gt;&gt; list(range(100))[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] while circle1234567sum=0index=99while index&gt;0: sum =sum +index print(&apos;index:&apos;,index,&apos;sum:&apos;,sum) index=index-2 breakbreak can stop and jump out whole circle syntax 1234567index=0while index&lt;100: if index&gt;10: break print(index) index=index+1print(&apos;END&apos;) continuecontinue can jump current circle count 1234567index=0while index&lt;10: index=index+1 if index%2==0: continue print(index) Hint: break and continue often be used with if using dict and setdictpython put dictionary inside called dict in other programming language it also called map which be storaged by kty-value couple and have extremely fast query speed 123&gt;&gt;&gt; dict={&apos;octopusheep&apos;:23,&apos;jacky chan&apos;:50,&apos;gustav&apos;:78}&gt;&gt;&gt; dict{&apos;octopusheep&apos;: 23, &apos;jacky chan&apos;: 50, &apos;gustav&apos;: 78} the way to put element into dict is that putting it when initialing and by seting key 12345&gt;&gt;&gt; dict{&apos;octopusheep&apos;: 23, &apos;jacky chan&apos;: 50, &apos;gustav&apos;: 78}&gt;&gt;&gt; dict[&apos;donkey&apos;]=666&gt;&gt;&gt; dict{&apos;octopusheep&apos;: 23, &apos;jacky chan&apos;: 50, &apos;gustav&apos;: 78, &apos;donkey&apos;: 666} using same way to change value but u should a key just have only one value if key is not existed, you will get an error: 123456&gt;&gt;&gt; dict{&apos;octopusheep&apos;: 23, &apos;jacky chan&apos;: 50, &apos;gustav&apos;: 78, &apos;donkey&apos;: 666}&gt;&gt;&gt; dict[&apos;lightening&apos;]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;KeyError: &apos;lightening&apos; two way to get value from dict: str in dict 1234&gt;&gt;&gt; &apos;octopusheep&apos;in dictTrue&gt;&gt;&gt; &apos;jack&apos;in dictFalse dict.get(str) 1234&gt;&gt;&gt; dict.get(&apos;octopusheep&apos;)23&gt;&gt;&gt; dict.get(&apos;octopusheep1&apos;)&gt;&gt;&gt; you can set default value of this method: 12&gt;&gt;&gt; dict.get(&apos;octopusheep1&apos;,&apos;i beg you a padon&apos;)&apos;i beg you a padon&apos; pop()can delete a key and his value from dict 123456&gt;&gt;&gt; dict{&apos;octopusheep&apos;: 23, &apos;jacky chan&apos;: 50, &apos;gustav&apos;: 78, &apos;donkey&apos;: 666}&gt;&gt;&gt; dict.pop(&apos;jacky chan&apos;)50&gt;&gt;&gt; dict{&apos;octopusheep&apos;: 23, &apos;gustav&apos;: 78, &apos;donkey&apos;: 666} using key to calculate the loaction of value be called hash algorithm to be sure the correction of hash, the key cannot be changed, so str and int,etc can be key, on the contrary, list is changable so it cannot be key in dict 12345&gt;&gt;&gt; k=[1,2,3]&gt;&gt;&gt; dict[k]=&quot;happy mother&apos;s day&quot;Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: unhashable type: &apos;list&apos; setset is a collection of some key, but its key does not have value using a list as the parameter of set(), which to get a set 123&gt;&gt;&gt; s =set([1,2,23,3,43,34,4,4])&gt;&gt;&gt; s{1, 2, 3, 34, 4, 43, 23} same element will be filtered in set add() can add element in set 12345&gt;&gt;&gt; s{1, 2, 3, 34, 4, 43, 23}&gt;&gt;&gt; s.add(99)&gt;&gt;&gt; s{1, 2, 3, 34, 4, 99, 43, 23} remove() can delete element in set 12345&gt;&gt;&gt; s{1, 2, 3, 34, 4, 99, 43, 23}&gt;&gt;&gt; s.remove(1)&gt;&gt;&gt; s{2, 3, 34, 4, 99, 43, 23} set can be think as a element collection without order and same element in math, so it can do some specific math manipulation like &amp; and |: 123456&gt;&gt;&gt; s1=set([1,2,3])&gt;&gt;&gt; s2=set([3,4,5])&gt;&gt;&gt; s1&amp;s2{3}&gt;&gt;&gt; s1|s2{1, 2, 3, 4, 5} you cannot put list as key into set,becasuse list is unhashable 1234&gt;&gt;&gt; s3=set([1,2,3,[1,2,3]])Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: unhashable type: &apos;list&apos; discuss “unchangable” againunderstand the ref and the object that ref point to","link":"/2019/09/06/Python Studying Note/"},{"title":"RxJava2 Official Document Note1","text":"针对ReactiveX官网给出的官方文档我做了翻译和总结性笔记 Observable被观察者在ReactiveX中,Observable称为被观察者,Observer称为观察者,subscribe称为订阅,emit称为发射,item成为项目,object称为对象,operator成为操作符。 观察者可以订阅被观察者。在观察者订阅了被观察者后,观察者可以对被观察者发射出来的任意项目和项目序列作出反应。这个模式促进了并发操作,因为整个过程（which）可以不被等待观察者发射对象的过程阻塞。这个模式是通过创建一个观察者形式的哨兵,他随时准备对被观察者未来可能作出的任何操作作出合适的反映。 这个页面解释了什么是反应模式（reactive pattern）,什么是观察者和被观察者,观察者怎样订阅被观察者,其他页面展示了你怎样使用各种被观察者操作符来将被观察者连接在一起并改变它们的行为。 这个文档结合大理石图（marble diagrams）和文字来作出解释,以下大理石图展示了被观察者和被观察者的转换过程： 这是被观察者的事件线,时间从左到右流动 这些是被观察者发射出来的项目 这个垂直的竖线表明被观察者已经成功发射完全部项目 这些带点的虚线和中间的方块盒子表明转换过程正在被应用于被观察者（发射的项目）身上。盒子内部中间的文字表明了转变的自然过程 这个被观察者就是转换的结果（即转换结果可以还是被观察者） 如果因为一些原因被观察者被异常终止,垂直的竖线将被一个X代替表示终止 你也可以看看:Single-一个特殊版本的观察者,它只发射一个项目Rx Workshop: IntroductionIntroduction to Rx: IObservableMastering observables (from the Couchbase Server documentation)2 minute introduction to Rx by Andre Staltz (“将被观察者看做一个异步的一成不变的序列。”)Introducing the Observable by Jafar Husain (JavaScript Video Tutorial)Observable object (RxJS) by Dennis StoyanovTurning a callback into an Rx Observable by @afterecho Backgroud后台在一些软件编程任务中,你或多或少的希望你写的说明将被一点点地,逐次递增地被执行和完善,并且按照你写的顺序那么去做。但是在ReactiveX中,一些说明可能是平行执行的,它们的结果随后会被观察者以随意的顺序捕获。比起调用一个方法,你用被观察者形式定义了一种检索和转变数据的机制,然后给它订阅一个观察者,在先前定义的机制,它会响应观察者哨兵的捕获并对被观察者无论何时发出的发射项目作出反应。 这种方式的一个优点是当你有一堆不相互依赖的任务时,你可以同时开始这些任务,而不是在开始下一个任务前要等待上一个任务完成。用这种方式,你这一捆任务的完成时间和这捆任务中耗时最长的任务完成时间相同。 这里有一些术语用来描述异步编程和设计的模型,这个文档将使用下列术语：一个订阅了被观察者的观察者,一个被观察者发射了一个项目或发送了一个通知给它们的观察者通过调用观察者的方法。 在其他的文档和内容中,我们称Observer为观察者,有时也叫它Subscriber订阅者,watcher监视者,reactor反应者,这个模型通常被称为reactor pattern反映者模式。 Establishing Observers创建观察者这页使用了类goorvy的伪代码来展示例子,但这些ReactiveX实现也在其他一些语言中。 在一个普通的方法调用中（也就是说并不像ReactiveX中那样异步并行的调用类型）,它的流是这样的： 调用一个方法 存储来自这个方法的返回值于一个变量中 使用这个变量和它的新值来作些有用的事情 在异步模型中方法流是这样的： 定义一个能用来自于异步调用的返回值做一些有用的事的方法,这个方法是观察者的一部分 定义一个异步调用它自己的实体叫被观察者 连接这个观察者和被观察者通过订阅它（这也叫做初始化被观察者的行为） 继续你的业务；无论什么时候异步调用有了返回值=结果,观察者的方法将开始针对返回值进行操作,这些项目就是由被观察着发射的 onNext,onCompleted,and onError处理每个异步返回值的方法,完成处理后调用的方法,出错时调用的方法订阅subscribe方法是你连接一个观察者和被观察者的方式。你的观察者实现了下列方法的子集： onNext处理每个异步返回值的方法一个被观察者调用这个方法在这个被观察者无论何时发射出一个项目的时候,这个方法将被观察者发出的项目作为参数 onCompleted完成处理后调用的方法被观察者调用这个方法当他调用了最后一次onNext方法,在被观察者整个过程没有遭遇到任何错误的情况下。 onError出错时调用的方法一个被观察者调用这个方法来表明它没能产生期望的数据或遭遇了其他一些错误,它将不能后续调用onNext和onCompleted方法onError方法用导致错误发生的原因作为它的参数 在对the Observable contract即一种对被观察者标准定义的尝试的术语定义中,它可能调用onNext零次和数次,然后可能调用onCompleted或onError中的一种作为被观察者调用的最后一次的方法,并不是两者都调用。按照惯例,在这个文档中,对onNext的调用通常为叫做项目的发射,而调用onCompleted和onError被叫做通知 也可以看看Introduction to Rx: IObserver Unsubscribing退订在一些ReactiveX实现中,有一种特殊的观察者接口,被称为subscriber订阅者,它实现了一个解除订阅的方法unsubscribe。你可以调用这个方法来表明这个订阅者不在对它当前订阅过的任何被观察者感兴趣。这些被观察者随后（如果它们没有其他感兴趣的观察者的话）会选择停止产生新项目去发射。 解除订阅的结果可能会层级反馈给反映者链,这些反映者是应用于那些已经实现了订阅关系的被观察者,然后这将导致链上的每一个连接停止发射项目。这并不能保证一切是立即发生的,然而,一个被观察者在即使没有观察者保留观察它们的发射项目的情况下依然产生和尝试发射项目一段时间是可能的。 Some Notes on Naming Conventions一些命名约定的备注每一种ReactiveX在特定语言上的实现都有自己的命名怪僻,这里没有典范的命名标准,尽管这里有一些实现上的共性。 此外,这些名称在其他情形中具有不同的含义,或者在特定实现语言的习语中看起来很尴尬。 例如onEvent这种命名模式（还有onNext,onCompleted,onError）。在一些情形下,这些名称指明方法通过事件处理者被注册的意义。在ReactiveX中,然而,他们表示事件处理者自己本身。 “HOt” and “Cold” Observable 热和冷被观察者什么时候被观察者开始发射项目的序列呢？这决定于被观察者。热观察者可能开始发射项目从它一被创建就开始,因此一些后来订阅了这个被观察者的观察者可能开始观察这个序列从中间的某个时候。冷被观察者,从另一方面说,在它开始发射项目之前它将一直等待直到一个观察者订阅了它。如此这样一个观察者被认为看到了整个序列从开始的过程。 在ReactiveX的一些实现中,有些概念被称为Connectable Obsevable可连接的被观察者。这种被观察者不会从一开始就发射项目直到它的connect连接方法被调用,无论它又没有被任何观察者订阅。 Composition via Observable Operators通过被观察者操作符进行组合被观察者和观察者只是ReactiveX的开始,她们自己本身不过是标准观察者模式的轻微扩展,为了更好的处理事件的序列而不是单个的回调。 真正的能力来自于反应性扩展（即ReactiveX）-操作符,它允许你转变,结合,操作,处理被观察者发射的项目序列。 这些Rx操作符允许你以声明的方式将异步序列组合在一起,拥有回调的所有效率优点,但没有嵌套回调处理者通常都与异步系统相关联的缺点。 这个文档组信息包括各种操作符和它们使用的的例子： 创造被观察者 create,defer,empty/never/throw,from,interval,just,range,repeat,start,timer 转变被观察者项目 buffer,flatmap,groupby,map,scan,window 过滤被观察者 debounce,distinct,elementat,filter,first,ignoreelements,last,sample,skip,skiplast,take,takelast 结合被观察者 and/then/when,combinelatest,join,merge,startwith,switch,zip 错误处理操作符 catch,retry 工具操作符 delay,do,materialize/dematerialize, observeon, serialize, subscribe, subscribeon, timeinterval, timeout, timestamp,using 条件判断布朗操作符 all,amb,contains,defaultifempty,sequenceequal,skipuntil,skipwhile,takeuntil,takewhile 数学与集合预算符 average,concat,count,max,min,reduce,sum 转换操作符 to 可连接的被观察者操作符 connect,publish,refcount,replay 背压操作符 各种操作符执行特定的流控制策略 这些页展示的关于一些操作符的信息不是ReactiveX核心的一部分,但是这些被实现在一种或多种特定语言的实现上或可选模块中。 Chaining Operators连接操作符大多数操作符操作于被观察者,并返回一个被观察者,这允许了你能够在调用链中一个接一个地应用这些操作符。每一个操作符都修改了传递到来自上一个操作符的操作过的被观察者。 这里还有其他一些模式,如建造者模式,一个特定类中的各种方法操作在同一个类的项目上,通过这些方法的操作可以些该这些对象。这种模式允许你连是串联起这些方法以同样的方式。但在建造者模式中,方法在链中出现的顺序不是很重要,但是被观察者操作符的顺序很重要。 被观察者操作符的链不能生效在一个原始的创造了这个链的被观察者上,它们是反过来操作的。在被观察者身上的每一个操作都产生于链上上一个操作符的操作结果。","link":"/2019/03/21/RxJava2 Official Document Note/"},{"title":"RxJava2学习笔记","text":"草率地看了些许RxJava的文章，自己的理解是，RxJava结合观察者模式实现异步操作，在观察者(Observable)流中处理一些事务，当流中一个事物完成后，会通知被观察者(Observer)，使其对结果再进行处理。 工程引用在app的build.gradle中添加依赖: 1234//添加RxJava2依赖implementation 'io.reactivex.rxjava2:rxjava:2.2.3'//添加RxAndroid依赖implementation 'io.reactivex.rxjava2:rxandroid:2.1.0' 核心概念与RxJava1相同，RxJava2的核心概念依旧是 Observable Observer Subscribe Affair 并多了两个新的概念 Subscriber(一种新的观察者：订阅者) Flowable（一种新的被观察者） 使用方式 Observable的创建 RxJava的多样性体现在被观察者的创建方式上。 create()方法 创建方式： 123456789Observable&lt;String&gt; observable = Observable.create(new ObservableOnSubscribe&lt;String&gt;() { @Override public void subscribe(ObservableEmitter&lt;String&gt; emitter) throws Exception { //执行一些其他操作 //............. //执行完毕，触发回调，通知观察者 emitter.onNext(\"我来发射数据\"); } }); just()方法 创建方式： 1Observable&lt;String&gt; observable = Observable.just(\"data\"); fromIterable()方法 创建方式： 12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(); for(int i =0;i&lt;10;i++){ list.add(\"Hello\"+i); }Observable&lt;String&gt; observable = Observable.fromIterable((Iterable&lt;String&gt;) list); 注意：Collection接口是Iterable接口的子接口，所以所有Collection接口的实现类都可以作为Iterable对象直接传入fromIterable()方法。 defer()方式 创建方式： 123456Observable&lt;String&gt; observable = Observable.defer(new Callable&lt;ObservableSource&lt;? extends String&gt;&gt;() { @Override public ObservableSource&lt;? extends String&gt; call() throws Exception { return Observable.just(\"hello\"); } }); interval()方式 创建方式： 1Observable&lt;String&gt; observable = Observable.interval(2, TimeUnit.SECONDS); range( )方式 创建方式： 1Observable&lt;Integer&gt; observable = Observable.range(1,20); timer( )方式 创建方式： 1Observable&lt;Integer&gt; observable = Observable.timer(2, TimeUnit.SECONDS); repeat( )方式 创建方式： 1Observable&lt;Integer&gt; observable = Observable.just(123).repeat(); Observer的创建 创建方式: 12345678910111213141516171819202122Observer&lt;String&gt; observer = new Observer&lt;String&gt;() { @Override public void onSubscribe(Disposable d) { } @Override //观察者接收到通知,进行相关操作 public void onNext(String data) { System.out.println(\"data is: \"+data); } @Override public void onError(Throwable e) { } @Override public void onComplete() { } }; 实现订阅 创建方式： 1observable.subscribe(observer); 操作符 map() 将原来的Observable对象转换成另一个Observable对象 123456Observable.range(0, 100).map(new Function&lt;Integer, String&gt;() { @Override public String apply(Integer integer) throws Exception { return \"num \"+integer; } }); flatMap() flatMap()可以将集合等数据转换成Obseravable对象，并把数据转换成Observer想要的数据形式。 1234567891011121314151617181920//生成一个listList&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 100; i++) { list.add(\"number \" + i); }//用flatMap()将list转化为一个Observable对象Observable.just(list) .flatMap(new Function&lt;List&lt;String&gt;, ObservableSource&lt;?&gt;&gt;() { @Override public ObservableSource&lt;?&gt; apply(List&lt;String&gt; strings) throws Exception { return Observable.fromIterable(strings); } }) .subscribe(new Consumer&lt;Object&gt;() { @Override public void accept(Object o) throws Exception { Log.d(TAG, (String) o); } }); filter() 根据自己增加的过滤条件，过滤出自己需要的数据加入到新的Observable对象中。 1234567891011121314151617181920Observable.just(list).flatMap(new Function&lt;List&lt;String&gt;, ObservableSource&lt;?&gt;&gt;() { @Override public ObservableSource&lt;?&gt; apply(List&lt;String&gt; strings) throws Exception { return Observable.fromIterable(strings); } }).filter(new Predicate&lt;Object&gt;() { @Override public boolean test(Object s) throws Exception { String newStr = (String) s; if (newStr.charAt(5) - '0' &gt; 5) { return true; } return false; } }).subscribe(new Consumer&lt;Object&gt;() { @Override public void accept(Object o) throws Exception { System.out.println((String)o); } }); take() 输出最多指定数量的结果 doOnNext() 允许我们在每次输出一个元素之前做一些额外的事情。 12345678910111213141516Observable.just(list).flatMap(new Function&lt;List&lt;String&gt;, ObservableSource&lt;?&gt;&gt;() { @Override public ObservableSource&lt;?&gt; apply(List&lt;String&gt; strings) throws Exception { return Observable.fromIterable(strings); } }).take(5).doOnNext(new Consumer&lt;Object&gt;() { @Override public void accept(Object o) throws Exception { System.out.println(\"准备工作\"); } }).subscribe(new Consumer&lt;Object&gt;() { @Override public void accept(Object s) throws Exception { System.out.println((String)s); } });","link":"/2018/11/21/RxJava2学习笔记/"},{"title":"RxJava学习笔记","text":"本文内容学习总结来自扔物线所写的给 Android 开发者的 RxJava 详解 什么是RxJava a library for composing asynchronous and event-based programs using observable sequences for the Java VM 即一个在Java虚拟机上使用了可观测序列的组合了异步和事件驱动的程序的库，RxJava的本质是一个实现异步操作的库, 优点是把复杂的业务逻辑变得简介，可读性强。 API介绍和原理简析RxJava 的异步实现，是通过一种扩展的观察者模式来实现的。 扩展的观察者模式在RxJava中，Observable被Observer所观察，通过subscribe()方法实现订阅。 RxJava 有四个基本概念：Observable (可观察者，即被观察者)、 Observer (观察者)、 subscribe (订阅)、事件 RxJava 的事件回调方法除了普通事件 onNext() 之外，还定义了两个特殊的事件：onCompleted() 和 onError()。 被观察者通过订阅被观察者监视，当触发订阅事件时，会回调onNext()等事件 基本实现RxJava 的基本实现主要有三点： 创建Observer观察者决定事件触发时将有怎样的行为。RxJava 中的 Observer 接口的实现方式： 12345678910111213141516Observer&lt;String&gt; observer = new Observer&lt;String&gt;() { @Override public void onNext(String s) { Log.d(tag, \"Item: \" + s); } @Override public void onCompleted() { Log.d(tag, \"Completed!\"); } @Override public void onError(Throwable e) { Log.d(tag, \"Error!\"); }}; RxJava 还内置了一个实现了 Observer 的抽象类：Subscriber。 Subscriber 对 Observer 接口进行了一些扩展，但他们的基本使用方式是完全一样的： 12345678910111213141516Subscriber&lt;String&gt; subscriber = new Subscriber&lt;String&gt;() { @Override public void onNext(String s) { Log.d(tag, \"Item: \" + s); } @Override public void onCompleted() { Log.d(tag, \"Completed!\"); } @Override public void onError(Throwable e) { Log.d(tag, \"Error!\"); }}; Observer 和 Subscriber的区别主要有两点： onStart() 这是 Subscriber 增加的方法。它会在 subscribe 刚开始，而事件还未发送之前被调用，可以用于做一些准备工作，例如数据的清零或重置。这是一个可选方法，默认情况下它的实现为空。需要注意的是，如果对准备工作的线程有要求（例如弹出一个显示进度的对话框，这必须在主线程执行）， onStart() 就不适用了，因为它总是在 subscribe 所发生的线程被调用，而不能指定线程。要在指定的线程来做准备工作，可以使用 doOnSubscribe() 方法，具体可以在后面的文中看到。 unsubscribe() 这是 Subscriber 所实现的另一个接口 Subscription 的方法，用于取消订阅。在这个方法被调用后，Subscriber 将不再接收事件。一般在这个方法调用前，可以使用 isUnsubscribed() 先判断一下状态。 unsubscribe() 这个方法很重要，因为在 subscribe() 之后， Observable 会持有 Subscriber 的引用，这个引用如果不能及时被释放，将有内存泄露的风险。所以最好保持一个原则：要在不再使用的时候尽快在合适的地方（例如 onPause() onStop() 等方法中）调用 unsubscribe() 来解除引用关系，以避免内存泄露的发生。 创建Observable被观察者决定什么时候触发事件和触发怎样的事件，RxJava 使用 create() 方法来创建一个 Observable ，并为它定义事件触发规则： 123456789Observable observable = Observable.create(new Observable.OnSubscribe&lt;String&gt;() { @Override public void call(Subscriber&lt;? super String&gt; subscriber) { subscriber.onNext(\"Hello\"); subscriber.onNext(\"Hi\"); subscriber.onNext(\"Aloha\"); subscriber.onCompleted(); }}); Subscribe(订阅)创建了 Observable 和 Observer 之后，再用 subscribe() 方法将它们联结起来。 123observable.subscribe(observer);// 或者：observable.subscribe(subscriber); 除了 subscribe(Observer) 和 subscribe(Subscriber) ，subscribe() 还支持不完整定义的回调，RxJava 会自动根据定义创建出 Subscriber 。 线程控制在不指定线程的情况下， RxJava 遵循的是线程不变的原则，即：在哪个线程调用 subscribe()，就在哪个线程生产事件；在哪个线程生产事件，就在哪个线程消费事件。如果需要切换线程，就需要用到 Scheduler （调度器）。 Schedulers.immediate(): 直接在当前线程运行，相当于不指定线程。这是默认的 Scheduler。 Schedulers.newThread(): 总是启用新线程，并在新线程执行操作。 Schedulers.io(): I/O 操作（读写文件、读写数据库、网络信息交互等）所使用的 Scheduler。行为模式和 newThread() 差不多，区别在于 io() 的内部实现是是用一个无数量上限的线程池，可以重用空闲的线程，因此多数情况下 io() 比 newThread() 更有效率。不要把计算工作放在 io() 中，可以避免创建不必要的线程。 Schedulers.computation(): 计算所使用的 Scheduler。这个计算指的是 CPU 密集型计算，即不会被 I/O 等操作限制性能的操作，例如图形的计算。这个 Scheduler 使用的固定的线程池，大小为 CPU 核数。不要把 I/O 操作放在 computation() 中，否则 I/O 操作的等待时间会浪费 CPU。 另外， Android 还有一个专用的 AndroidSchedulers.mainThread()，它指定的操作将在 Android 主线程运行。 123456789Observable.just(1, 2, 3, 4) .subscribeOn(Schedulers.io()) // 指定 subscribe() 发生在 IO 线程 .observeOn(AndroidSchedulers.mainThread()) // 指定 Subscriber 的回调发生在主线程 .subscribe(new Action1&lt;Integer&gt;() { @Override public void call(Integer number) { Log.d(tag, \"number:\" + number); } }); 这种在 subscribe() 之前写上两句 subscribeOn(Scheduler.io()) 和 observeOn(AndroidSchedulers.mainThread()) 的使用方式非常常见，它适用于多数的 『后台线程取数据，主线程显示』的程序策略。 例如在IO线程读取图片，在安卓主线程设置照片，即使加载图片耗费了几十甚至几百毫秒的时间，也不会造成丝毫界面的卡顿。 123456789101112131415161718192021222324252627int drawableRes = ...;ImageView imageView = ...;Observable.create(new OnSubscribe&lt;Drawable&gt;() { @Override public void call(Subscriber&lt;? super Drawable&gt; subscriber) { Drawable drawable = getTheme().getDrawable(drawableRes)); subscriber.onNext(drawable); subscriber.onCompleted(); }}).subscribeOn(Schedulers.io()) // 指定 subscribe() 发生在 IO 线程.observeOn(AndroidSchedulers.mainThread()) // 指定 Subscriber 的回调发生在主线程.subscribe(new Observer&lt;Drawable&gt;() { @Override public void onNext(Drawable drawable) { imageView.setImageDrawable(drawable); } @Override public void onCompleted() { } @Override public void onError(Throwable e) { Toast.makeText(activity, \"Error!\", Toast.LENGTH_SHORT).show(); }}); 变换所谓变换，就是将事件序列中的对象或整个序列进行加工处理，转换成不同的事件或事件序列. 例如将String类型的事件对象map为Bitmap类型： 12345678910111213Observable.just(\"images/logo.png\") // 输入类型 String .map(new Func1&lt;String, Bitmap&gt;() { @Override public Bitmap call(String filePath) { // 参数类型 String return getBitmapFromPath(filePath); // 返回类型 Bitmap } }) .subscribe(new Action1&lt;Bitmap&gt;() { @Override public void call(Bitmap bitmap) { // 参数类型 Bitmap showBitmap(bitmap); } }); rx.Observable的map方法参数为Func1，与Action1类似，也是RxJava的一个接口，用于包装一个含有参数的方法。 Func1 和 Action 的区别在于， Func1 包装的是有返回值的方法。和 ActionX 一样， FuncX 也有多个，用于不同参数个数的方法。FuncX 和 ActionX 的区别在 FuncX 包装的是有返回值的方法。 常用变换： map(): 事件对象的直接变换 flatMap(): 将事件对象的多个成员变量发送给subscriber的回调方法 flatMap() 中返回的是个 Observable 对象，并且这个 Observable 对象并不是被直接发送到了 Subscriber 的回调方法中。 flatMap() 的原理是这样的：1. 使用传入的事件对象创建一个 Observable 对象；2. 并不发送这个 Observable, 而是将它激活，于是它开始发送事件；3. 每一个创建出来的 Observable 发送的事件，都被汇入同一个 Observable ，而这个 Observable 负责将这些事件统一交给 Subscriber 的回调方法。这三个步骤，把事件拆成了两级，通过一组新创建的 Observable 将初始的对象『铺平』之后通过统一路径分发了下去。而这个『铺平』就是 flatMap() 所谓的 flat。 变换的原理这些变换虽然功能各有不同，但实质上都是针对事件序列的处理和再发送。而在 RxJava 的内部，它们是基于同一个基础的变换方法： lift(Operator)。首先看一下 lift() 的内部实现（仅核心代码）： 123456789101112// 注意：这不是 lift() 的源码，而是将源码中与性能、兼容性、扩展性有关的代码剔除后的核心代码。// 如果需要看源码，可以去 RxJava 的 GitHub 仓库下载。public &lt;R&gt; Observable&lt;R&gt; lift(Operator&lt;? extends R, ? super T&gt; operator) { return Observable.create(new OnSubscribe&lt;R&gt;() { @Override public void call(Subscriber subscriber) { Subscriber newSubscriber = operator.call(subscriber); newSubscriber.onStart(); onSubscribe.call(newSubscriber); } });} 这段代码很有意思：它生成了一个新的 Observable 并返回，而且创建新 Observable 所用的参数 OnSubscribe 的回调方法 call() 中的实现竟然看起来和前面讲过的 Observable.subscribe() 一样！然而它们并不一样哟~不一样的地方关键就在于第二行 onSubscribe.call(subscriber) 中的 onSubscribe 所指代的对象不同（高能预警：接下来的几句话可能会导致身体的严重不适）—— subscribe() 中这句话的 onSubscribe 指的是 Observable 中的 onSubscribe 对象，这个没有问题，但是 lift() 之后的情况就复杂了点。 当含有 lift() 时： lift() 创建了一个 Observable 后，加上之前的原始 Observable，已经有两个 Observable 了； 而同样地，新 Observable 里的新 OnSubscribe 加上之前的原始 Observable 中的原始 OnSubscribe，也就有了两个 OnSubscribe； 当用户调用经过 lift() 后的 Observable 的 subscribe() 的时候，使用的是 lift() 所返回的新的 Observable ，于是它所触发的 onSubscribe.call(subscriber)，也是用的新 Observable 中的新 OnSubscribe，即在 lift() 中生成的那个 OnSubscribe； 而这个新 OnSubscribe 的 call() 方法中的 onSubscribe ，就是指的原始 Observable 中的原始 OnSubscribe ，在这个 call() 方法里，新 OnSubscribe 利用 operator.call(subscriber) 生成了一个新的 Subscriber（Operator 就是在这里，通过自己的 call() 方法将新 Subscriber 和原始 Subscriber 进行关联，并插入自己的『变换』代码以实现变换），然后利用这个新 Subscriber 向原始 Observable 进行订阅。 这样就实现了 lift() 过程，有点像一种代理机制，通过事件拦截和处理实现事件序列的变换。 compose: 对Observable整体的转换12345678910111213141516public class LiftAllTransformer implements Observable.Transformer&lt;Integer, String&gt; { @Override public Observable&lt;String&gt; call(Observable&lt;Integer&gt; observable) { return observable .lift1() .lift2() .lift3() .lift4(); }}...Transformer liftAll = new LiftAllTransformer();observable1.compose(liftAll).subscribe(subscriber1);observable2.compose(liftAll).subscribe(subscriber2);observable3.compose(liftAll).subscribe(subscriber3);observable4.compose(liftAll).subscribe(subscriber4); 使用 compose() 方法，Observable 可以利用传入的 Transformer 对象的 call 方法直接对自身进行处理，也就不必被包在方法的里面了。 线程控制： Schedule12345678Observable.just(1, 2, 3, 4) // IO 线程，由 subscribeOn() 指定 .subscribeOn(Schedulers.io()) .observeOn(Schedulers.newThread()) .map(mapOperator) // 新线程，由 observeOn() 指定 .observeOn(Schedulers.io()) .map(mapOperator2) // IO 线程，由 observeOn() 指定 .observeOn(AndroidSchedulers.mainThread) .subscribe(subscriber); // Android 主线程，由 observeOn() 指定 延伸：doOnSubscribe()而与 Subscriber.onStart() 相对应的，有一个方法 Observable.doOnSubscribe() 。它和 Subscriber.onStart() 同样是在 subscribe() 调用后而且在事件发送前执行，但区别在于它可以指定线程。默认情况下， doOnSubscribe() 执行在 subscribe() 发生的线程；而如果在 doOnSubscribe() 之后有 subscribeOn() 的话，它将执行在离它最近的 subscribeOn() 所指定的线程。 例如： 1234567891011Observable.create(onSubscribe) .subscribeOn(Schedulers.io()) .doOnSubscribe(new Action0() { @Override public void call() { progressBar.setVisibility(View.VISIBLE); // 需要在主线程执行 } }) .subscribeOn(AndroidSchedulers.mainThread()) // 指定主线程 .observeOn(AndroidSchedulers.mainThread()) .subscribe(subscriber); 如上，在 doOnSubscribe()的后面跟一个 subscribeOn() ，就能指定准备工作的线程了。 RxJava 的适用场景和使用方式与Retrofit结合 Retrofit 是 Square 的一个著名的网络请求库。 使用 RxJava 形式的 API，定义同样的请求是这样的： 12@GET(\"/user\")public Observable&lt;User&gt; getUser(@Query(\"userId\") String userId); 使用的时候是这样的： 123456789101112131415161718getUser(userId) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Observer&lt;User&gt;() { @Override public void onNext(User user) { userView.setUser(user); } @Override public void onCompleted() { } @Override public void onError(Throwable error) { // Error handling ... } });","link":"/2018/10/06/RxJava学习笔记/"},{"title":"Sublime License Verify","text":"经整理可用于sublime build3211版本license认证的步骤 Modify host1sudo vi /etc/hosts add following text into hosts: 12345678127.0.0.1 sublimetext.com127.0.0.1 sublimehq.com127.0.0.1 license.sublimehq.com127.0.0.1 45.55.255.55127.0.0.1 45.55.41.2230.0.0.0 license.sublimehq.com0.0.0.0 45.55.255.550.0.0.0 45.55.41.223 then save docunment Input license key in sublime12345678910111213----- BEGIN LICENSE -----Member J2TeaMSingle User LicenseEA7E-1011316D7DA350E 1B8B0760 972F8B60 F3E64036B9B4E234 F356F38F 0AD1E3B7 0E9C5FADFA0A2ABE 25F65BD8 D51458E5 3923CE8087428428 79079A01 AA69F319 A1AF29A4A684C2DC 0B1583D4 19CBD290 217618CD5653E0A0 BACE3948 BB2EE45E 422D2C87DD9AF44B 99C49590 D2DBDEE1 75860FD28C8BB2AD B2ECE5A4 EFC08AF2 25A9B864------ END LICENSE ------​ that‘s all process to get authority of sublime","link":"/2020/10/19/Sublime License Verify/"},{"title":"Thinking in Hanoi Tower","text":"Rulesas we all know, there are three sticks in space and one spectical stick have 64 round plates, which all plates follow the rules that bigger one in the bottom. the destination of this game is move all plate to another stick Note by myselfassuming that there just have 3 plates in Hanoi environment, three sticks be called A,B,C one by one and all 3 plates be stack in A stick. so the move order like: A-&gt;B A-&gt;C B-&gt;C A-&gt;B C-&gt;A C-&gt;B A-&gt;B finding the trace about this order,i find that no matter how many plate sticked in A stick,what we should do is to move 1th and 2nd plate to B and C stick, Then we get into the dilemma that every stick has plate on. Correct answerconsidering top n-1 counts plate as an unit called Y, then move this unit Y from A to B, then move biggest plate from A to C, then considering Y as a new plate group which base in B, just move it from B to C by A, just like initial time. so the code like: 1234567def hanoi(n,a,b,c): if n==1: print(a,&apos;--&gt;&apos;,c) else: hanoi(n-1,a,c,b) print(a,&apos;--&gt;&apos;,c) hanoi(n-1,b,a,c) here is the output: 123456789101112131415161718192021222324&gt;&gt;&gt; hanoi(3,&apos;A&apos;,&apos;B&apos;,&apos;C&apos;)A --&gt; CA --&gt; BC --&gt; BA --&gt; CB --&gt; AB --&gt; CA --&gt; C&gt;&gt;&gt; hanoi(4,&apos;A&apos;,&apos;B&apos;,&apos;C&apos;)A --&gt; BA --&gt; CB --&gt; CA --&gt; BC --&gt; AC --&gt; BA --&gt; BA --&gt; CB --&gt; CB --&gt; AC --&gt; AB --&gt; CA --&gt; BA --&gt; CB --&gt; C such a funny question.","link":"/2019/10/22/Thinking in Hanoi Tower/"},{"title":"Ubuntu系统下adb检测不到设备的处理方案","text":"Ubuntu18.04环境下adb经常连接不上安卓设备，或者连接上后很快断开。 ![此时usb接口已经连接了安卓设备,adb却检测不到](/images/35.png) 原因分析经查阅文档，该问题的原因为adb的特征识别码中未保存我们车机的相关信息，导致usb口能识别设备，但adb无法识别改设备。 解决方案须手动保存相应的设备信息 查看usb设备 断开安卓设备与PC的usb连接，使用命令lsusb查看usb设备，如图： 重新将安卓设备与PC的usb接口连接，再次使用lsusb查看usb设备，如图： 可以发现usb接口插入安卓设备后，多出了两个bus： 其中0424:494c和0424:4715就是安卓设备的特征识别码,0424为VendorId,494c和4715为ProductId。 将特征识别码添加至ADB白名单内 在/etc/udev/rules.d/路径下新建70-Android.rules文件 1sudo gedit /etc/udev/rules.d/70-android.rules 在文件中添加安卓设备的特征识别码,如下所示 12SUBSYSTEM==\"usb\", ATTR{idVendor}==\"0424\",ATTRS{idProduct}==\"494c\",MODE=\"0666\"SUBSYSTEM==\"usb\", ATTR{idVendor}==\"0424\",ATTRS{idProduct}==\"4715\",MODE=\"0666\" 保存并退出该文件，如下图所示 给70-Android.rules文件添加权限 1sudo chmod 777 '/etc/udev/rules.d/70-Android.rules' 重启系统的udev服务 1sudo service udev restart 关闭adb服务 1adb kill-server 重新使用adb检测安卓设备 1adb devices 可以看到已经成功检测出安卓设备 如果还是检测不到设备，则执行如下命令,将设备的VendorId写入adb_usb.ini文件中 1echo echo \"0x0424\" &gt;~/.android/adb_usb.ini 再次出现该问题的解决方案只需关闭adb服务后再打开adb检测安卓设备 12adb kill-serveradb devices","link":"/2019/02/13/Ubuntu系统下adb检测不到设备的处理方案/"},{"title":"VI/VIM常用命令","text":"Vim is a highly configurable text editor for efficiently creating and changing any kind of text. vim是一个高度可配置的的文本编辑器，用于有效地创建和修改任何类型的文本，官方中文操作手册可以在SOURCEFORGE下载 基本模式 普通模式 插入模式 命令模式 普通模式命令dd删除一整行 yy复制一整行p粘贴 o在当前行下方插入新行O在当前行上方插入新行 a在当前字符后插入光标A在当前行尾插入光标 i在当前字符前插入光标I在当前行首插入光标 命令模式命令wq保存退出!q不保存退出 set number显示行数标","link":"/2019/11/22/VI:VIM常用命令/"},{"title":"VM Password Free Instruction","text":"The people always say: 两岸🐒声啼不住，密码输到手抽搐 Comprisalif u wanna login VM and free for password, the prerequisite is sshpass and some mistery shell code Install sshpassDownload sshpassu can get sshpass in sourceforge, download it. Hint: the sshpass version is sshpass-1.06.tar.gz in this document. Depressure sshpassdepressures sshpass-1.06.tar.gz to current directory 1tar -zxvf sshpass-1.06.tar.gz check environment1./configure compile source code1make&amp;&amp;make install Hint: excute sshpassand show the message,which means that u installed sshpass successfully. 12345678910111213Mac:~ zhangyuyang$ sshpassUsage: sshpass [-f|-d|-p|-e] [-hV] command parameters -f filename Take password to use from file -d number Use number as file descriptor for getting password -p password Provide password as argument (security unwise) -e Password is passed as env-var &quot;SSHPASS&quot; With no parameters - password will be taken from stdin -P prompt Which string should sshpass search for to detect a password prompt -v Be verbose about what you&apos;re doing -h Show help (this screen) -V Print version informationAt most one of -f, -d, -p or -e should be used Setting password free in shellsaving those shell code as shell in any directory u like: 1234567891011121314151617181920212223242526272829303132333435363738394041424344#passwordfree.shpassword='caicloud2019'network_segment='192.168.133.'log='./log/elasticserch.log'#INFO打印function info_log(){ echo -e \"[INFO]$1\"}#SUCCESS打印function success_log(){ echo -e \"\\033[32m[SUCCESS]\\033[0m$1\"}#ERROR打印function error_log(){ echo -e \"\\033[31m[ERROR]\\033[0m$1\" exit 0}# 分发root密钥function distribution_key(){ ping ${ip} -c1 &gt;&gt; ${log} 2&gt;&amp;1 if [ $? -gt 0 ];then error_log \"${ip} 无法ping通请检查网络\" |tee -a ${log} continue fi sshpass -p ${password} ssh-copy-id -i ~/.ssh/others/id_rsa_zhangyuyang -o StrictHostKeyChecking=no root@${ip} &gt;&gt; ${log} 2&gt;&amp;1 if [ $? -gt 0 ];then error_log \"$ip 密钥分发失败\" |tee -a ${log} continue else success_log \"$ip 密钥分发成功\" |tee -a ${log} fi}# 执行操作for i in {30..31};do ip=${network_segment}${i} distribution_keydone in this code,u need to edit some field: password VM’s password network_segment VM’s IP srgment for i in {30..31}; VM’s IP last index range ~/.ssh/others/id_rsa_zhangyuyang ur RSA public key Excute shell script1bash passwordfree.sh Copy and rename public keyGotcha: this step is crucial for whole process, go into the directory where u store public key 1cd .ssh/others/ then copy the public key file and rename it: 1cp id_rsa_zhangyuyang id_rsa_zhangyuyang.pub Excute shell script again1bash passwordfree.sh then u can passsword freee to login VM.","link":"/2019/08/08/VM Password Free Instruction/"},{"title":"Web Scraping Note","text":"Prerequisite预置条件 Requests BeautifulSoup lxml Detail实现细节Data Module数据保存模块Video Module视频数据模块‘Video’ class contains essential video information: title, link 1234567891011# modelclass Video(object): def __init__(self, title, link): self.title = title self.link = link def information(self): SPLIT_LINE = &apos;----------------------------------&apos; print(&apos;%s\\nvideo title: %s\\nvideo link: %s\\n%s&apos; % (SPLIT_LINE, self.title, self.link, SPLIT_LINE)) Network Model网络请求模块","link":"/2019/10/28/Web Scraping Note/"},{"title":"docker安装指南及基本操作(Mac环境)","text":"Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. for more precisely manifest docker,all the doc i collected is from official website,and this is my original article download dockerwe can download docker desktop for mac on dock hub install dockeras it hint,just drag &amp; drop docker icon into applications download example docker imagechosing suitable positon as you like，for me, the url is /Users/zhangyuyang/Documents/workspace enforce command in terminal 1git clone https://github.com/docker/doodle.git build docker image1cd doodle/cheers2019 &amp;&amp; docker build -t octopusheep/cheers2019 . wait for process completed as below: run the docker container1docker run -it --rm octopusheep/cheers2019 and you will see the demo function of our example docker image as below:","link":"/2019/06/14/docker安装指南及基本操作(Mac环境)/"},{"title":"docker官方文档学习笔记","text":"as some kind of notes for better understanding docker and this is my original article为了更好的理解和学习docker所作的笔记 orientationsome basic concept what difference between container and VM? as the picture below: A container can natively runs on Linux and share the kernel of the host machine with other containers A virtual machine (VM) runs a full-size “guset” operating system with virtual access to host resources through a hypervisor and definitely VMs provide an environment with more resources than most applications need containers and images a container is launched by running an image a container is a runtime instance of an image docker command12345678910111213141516171819## List Docker CLI commandsdockerdocker container --help## Display Docker version and infodocker --versiondocker versiondocker info## Execute Docker imagedocker run hello-world## List Docker imagesdocker image ls## List Docker containers (running, all, all in quiet mode)docker container lsdocker container ls --alldocker container ls -aq containersdockerfileDockerfile defines what goes on in the environment inside your container create a dockerfile Create an empty directory on your local machine. Change directories (cd) into the new directory, create a file called Dockerfile, copy-and-paste the following content into that file, and save it. Take note of the comments that explain each statement in your new Dockerfile. 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appCOPY . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [\"python\", \"app.py\"] create app itself Create two more files, requirements.txt and app.py, and put them in the same folder with the Dockerfile. requirements.txt 12FlaskRedis app.py 123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=\"redis\", db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(\"/\")def hello(): try: visits = redis.incr(\"counter\") except RedisError: visits = \"&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;\" html = \"&lt;h3&gt;Hello {name}!&lt;/h3&gt;\" \\ \"&lt;b&gt;Hostname:&lt;/b&gt; {hostname}&lt;br/&gt;\" \\ \"&lt;b&gt;Visits:&lt;/b&gt; {visits}\" return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname(), visits=visits)if __name__ == \"__main__\": app.run(host='0.0.0.0', port=80) build the app Make sure you are still at the top level of your new directory 1docker build --tag=friendlyhello . when the building process completed,try check it in your machine’s local docker image registry 1docker image ls you will find it in the list run the appRun the app, mapping your machine’s port 4000 to the container’s published port 80 using -p: 1docker run -p 4000:80 friendlyhello open the url http://localhost:4000 in safari or just curl it Now let’s run the app in the background, in detached mode 1docker run -d -p 4000:80 friendlyhello when you type it in ,then a specific hash code will appear on screene253b895743bafbf1ccbece83528ad8c1a966e3c04a44882b0f57951fa9f3b0d You can also see the abbreviated container ID with 1docker container ls use docker container stop to end the process, using the CONTAINER ID 1docker container stop 1fa4ab2cf395 Log in with your Docker ID1docker login Tag the image1docker tag friendlyhello gordon/get-started:part2 push the image1docker push octopusheep/demo:1.0.0 Pull and run the image from the remote repository1docker run -p 4000:80 username/repository:tag If the image isn’t available locally on the machine, Docker pulls it from the repository Here is a list of the basic Docker commands from this page, and some related ones if you’d like to explore a bit before moving on. 12345678910111213141516docker build -t friendlyhello . # Create image using this directory's Dockerfiledocker run -p 4000:80 friendlyhello # Run \"friendlyhello\" mapping port 4000 to 80docker run -d -p 4000:80 friendlyhello # Same thing, but in detached modedocker container ls # List all running containersdocker container ls -a # List all containers, even those not runningdocker container stop &lt;hash&gt; # Gracefully stop the specified containerdocker container kill &lt;hash&gt; # Force shutdown of the specified containerdocker container rm &lt;hash&gt; # Remove specified container from this machinedocker container rm $(docker container ls -a -q) # Remove all containersdocker image ls -a # List all images on this machinedocker image rm &lt;image id&gt; # Remove specified image from this machinedocker image rm $(docker image ls -a -q) # Remove all images from this machinedocker login # Log in this CLI session using your Docker credentialsdocker tag &lt;image&gt; username/repository:tag # Tag &lt;image&gt; for upload to registrydocker push username/repository:tag # Upload tagged image to registrydocker run username/repository:tag # Run image from a registry","link":"/2019/06/15/docker官方文档学习笔记/"},{"title":"iTerm2终端美化教程","text":"从iterm2官网下载软件后安装 切换zsh为默认shell1chsh -s /bin/zsh 安装 oh-my-zsh1curl -L https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh | sh 解决Connection refused问题如果安装过程中提示错误: 1Failed to connect to raw.githubusercontent.com port 443: Connection refused 应进行如下操作： 查询url对应的IP登陆https://site.ip138.com/ ,输入raw.githubusercontent.com 进行查询 将IP加入/etc/hosts1sudo vi /etc/hosts 例如: 123456789# Host Database## localhost is used to configure the loopback interface# when the system is booting. Do not change this entry.127.0.0.1 localhost255.255.255.255 broadcasthost::1 localhost151.101.76.133 raw.githubusercontent.com 保存修改并退出 再次执行安装oh-my-zsh 1curl -L https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh | sh 或切换或内码云平台: 1sh -c &quot;$(curl -fsSL https://gitee.com/pocmon/ohmyzsh/raw/master/tools/install.sh)&quot; 切换af-magic主题1vi .zshrc 修改主题为af-magic 1ZSH_THEME=&quot;af-magic&quot; 保存后刷新配置文件即可 1source .zshrc","link":"/2020/10/19/iTerm2终端美化教程/"},{"title":"Kafka部署实践","text":"进入可以部署Kafka的节点1~ » ssh root@192.168.133.32 下载JAVA(Kafka的节点内)先下载wget 1[root@qa4v133-30 ~]# yum install wget 更新软件源： 1[root@qa4v133-30 ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 再下载JAVA： 1[root@qa4v133-30 ~]# yum install java 本地下载Kafka安装包在Kafka官网下载页下载Kafka安装包 Scp传入可以部署Kafka的节点此处需要输入Kafka节点密码: 1~ » scp /Users/zhangyuyang/Downloads/kafka_2.12-2.3.0.tgz root@192.168.133.30:/root 传送文件结束后，在kafka节点查验是否传送完毕： 12[root@qa4v133-30 ~]# lscommon infra-v2.0.7-rc.1-centos infra-v2.0.7-rc.1-centos.tar.gz kafka_2.12-2.3.0.tgz 可以看到kafka_2.12-2.3.0.tgz已经传入kafka节点 解压kafka文件(Kafka的节点内)1[root@qa4v133-30 ~]# tar -xzvf kafka_2.12-2.3.0.tgz 此时kafka节点内./root路径下就有解压后的kafka_2.12-2.3.0文件夹了 修改zookeeper.properties(Kafka的节点内)1234567891011121314151617181920# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the &quot;License&quot;); you may not use this file except in compliance with# the License. You may obtain a copy of the License at# # http://www.apache.org/licenses/LICENSE-2.0# # Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# the directory where the snapshot is stored.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# disable the per-ip limit on the number of connections since this is a non-production configmaxClientCnxns=0 修改server.properties(Kafka的节点内)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the &quot;License&quot;); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# see kafka.server.KafkaConfig for additional details and defaults############################# Server Basics ############################## The id of the broker. This must be set to a unique integer for each broker.broker.id=0############################# Socket Server Settings ############################## The address the socket server listens on. It will get the value returned from # java.net.InetAddress.getCanonicalHostName() if not configured.# FORMAT:# listeners = listener_name://host_name:port# EXAMPLE:# listeners = PLAINTEXT://your.host.name:9092listeners=PLAINTEXT://0.0.0.0:9092# Hostname and port the broker will advertise to producers and consumers. If not set, # it uses the value for &quot;listeners&quot; if configured. Otherwise, it will use the value# returned from java.net.InetAddress.getCanonicalHostName().advertised.listeners=PLAINTEXT://192.168.133.30:9092# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL# The number of threads that the server uses for receiving requests from the network and sending responses to the networknum.network.threads=3# The number of threads that the server uses for processing requests, which may include disk I/Onum.io.threads=8# The send buffer (SO_SNDBUF) used by the socket serversocket.send.buffer.bytes=102400# The receive buffer (SO_RCVBUF) used by the socket serversocket.receive.buffer.bytes=102400# The maximum size of a request that the socket server will accept (protection against OOM)socket.request.max.bytes=104857600############################# Log Basics ############################## A comma separated list of directories under which to store log fileslog.dirs=/tmp/kafka-logs# The default number of log partitions per topic. More partitions allow greater# parallelism for consumption, but this will also result in more files across# the brokers.num.partitions=1# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.# This value is recommended to be increased for installations with data dirs located in RAID array.num.recovery.threads.per.data.dir=1############################# Internal Topic Settings ############################## The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1############################# Log Flush Policy ############################## Messages are immediately written to the filesystem but by default we only fsync() to sync# the OS cache lazily. The following configurations control the flush of data to disk.# There are a few important trade-offs here:# 1. Durability: Unflushed data may be lost if you are not using replication.# 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.# 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.# The settings below allow one to configure the flush policy to flush data after a period of time or# every N messages (or both). This can be done globally and overridden on a per-topic basis.# The number of messages to accept before forcing a flush of data to disk#log.flush.interval.messages=10000# The maximum amount of time a message can sit in a log before we force a flush#log.flush.interval.ms=1000############################# Log Retention Policy ############################## The following configurations control the disposal of log segments. The policy can# be set to delete segments after a period of time, or after a given size has accumulated.# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens# from the end of the log.# The minimum age of a log file to be eligible for deletion due to agelog.retention.hours=168# A size-based retention policy for logs. Segments are pruned from the log unless the remaining# segments drop below log.retention.bytes. Functions independently of log.retention.hours.#log.retention.bytes=1073741824# The maximum size of a log segment file. When this size is reached a new log segment will be created.log.segment.bytes=1073741824# The interval at which log segments are checked to see if they can be deleted according# to the retention policieslog.retention.check.interval.ms=300000############################# Zookeeper ############################## Zookeeper connection string (see zookeeper docs for details).# This is a comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.# You can also append an optional chroot string to the urls to specify the# root directory for all kafka znodes.zookeeper.connect=localhost:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000############################# Group Coordinator Settings ############################## The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.# The default value for this is 3 seconds.# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.group.initial.rebalance.delay.ms=0 运行zookeeper(Kafka的节点内)另起终端运行： 1[root@qa4v133-30 kafka_2.12-2.3.0]bin/zookeeper-server-start.sh config/zookeeper.properties 运行kafka(Kafka的节点内)另起终端运行： 1[root@qa4v133-30 kafka_2.12-2.3.0]# bin/kafka-server-start.sh config/server.properties 创建topic(Kafka的节点内)另起终端运行： 1[root@qa4v133-30 kafka_2.12-2.3.0]# bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic octopusheep 创建producer(Kafka的节点内)另起终端运行： 1[root@qa4v133-30 kafka_2.12-2.3.0]# bin/kafka-console-producer.sh --broker-list localhost:9092 --topic octopusheep 创建consumer(Kafka的节点内)另起终端运行： 1[root@qa4v133-30 kafka_2.12-2.3.0]# bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic octopusheep --from-beginning","link":"/2019/11/26/kafka部署实践/"},{"title":"《Java编程思想》读书笔记(序章)","text":"绪论 程序设计是对复杂性的管理 待解决问题的复杂性 用来解决该问题的工具的复杂性 在足够多的人的相互联系之上，下一次变革将是一种全球意识的形成 Arts&amp;Crafts运动始于世纪之交，在1900至1920年间达到巅峰，强调简洁设计，回归自然是整个运动的核心，注重手工制造集推崇个性化设计。 上帝赋予人类说话的能力，而语言又创造了思想，思想是人类对宇宙的量度 真实世界在很大程度上是不知不觉的基于群体的语言习惯形成的 你需要在头脑里创建一个模型，以加强你对这种语言的深入理解 Code Standard标识符(方法，变量和类名)排为粗体 大部分的关键字为粗体，但不包括频繁使用的关键字","link":"/2018/09/04/《Java编程思想》读书笔记(序章)/"},{"title":"《Java编程思想》读书笔记(第一章)","text":"对象导论 编程语言始于对机器的模仿，但并非机器那么简单，它是一种不同类型的表达媒体 What is Object-oriented Programming? 人们所能够解决的问题的复杂性直接取决于抽象的类型和质量 解空间：你对问题建模的地方，如机器 问题空间：问题存在的地方 The definition of Object 问题空间的元素及其在解空间的表示 对象具有状态，行为，标识 面向对象的设计方式 万物皆对象 程序是对象的集合 每个对象都有自己的由其他对象所构成的存储 每个对象都拥有其类型 某一特定类型的所有对象都可以接收同样的信息 每个对象在内存中都有一个唯一的地址创建对象的方式 定义这个对象的引用(reference) 调用new方法创建新对象 用统一建模语言表示类 UML即unified modelling language 每个类都用一个方框表示，类名在方框的顶部，你所关心的任何成员变量都描述在方框的中间部分，方法在方框的底部 通常，只有类名和公共方法被示于UML设计图中 如果只对类型感兴趣，那么方框的底部也不需要给出","link":"/2018/09/05/《Java编程思想》读书笔记(第一章)/"},{"title":"《Java编程思想》读书笔记(第七章)","text":"三种代码重用机制：组合，继承，代理 每一个非基本类型的对象都有一个toString()方法，而且当编译器需要一个String而你却只有一个对象时，该方法就会调用 java使用super关键词来表示超类，表达式super.method()将调用基类版本的scrub() java会自动在导出类的构造器中插入对基类构造器的调用 使用代理时可以拥有更多的控制力，我们可以选择提供成员对象中的方法中的子集 12345678910111213141516171819202122232425262728class SpaceShipControl{ void forward(int speed); void backward(int speed); void left(int speed); void right(int speed);}public class SpaceShipDetegent{ private String name; private SpaceShipControl ssp=new SpaceShipControl(); public SpaceShipDetegent(String name){ this.name=name; } public void backward(int velocity){ ssp.backward(velocity); } public void forward(int velocity){ ssp.backward(velocity); } public static void main(String[] args){ SpaceShipDetegent ssd=new SpaceShipDetegent(\"NASA Protector\"); ssd.backward(100); }} 无论try块是怎样退出的,保护区后的finally子句中的代码块总是要被执行的 将子类引用转化为基类引用的动作，称之为upcasting向上转型 static强调只有一份，final说明它是一个常量 final参数final可以修饰数据，方法，类 java允许在参数列表中以声明的方式将参数指明为final，意味着你无法在方法中更改参数引用所指向的对象，你可以读参数，但却无法修改参数，这一特性主要用来向匿名内部类传递数据 final方法使用的原因： 锁定方法，防止继承类修改它的含义，禁止子类覆盖该方法 性能优化 类中的private方法都隐式的指定为是final的，因为子类无法取用private方法，所以也就无法覆盖它 override覆盖只在某方法是基类的接口的一部分时候才有效，如果基类的方法是private修饰，它就不是基类接口的一部分 final修饰类时，表示该类不可被继承。final类中的所有方法都被隐式指定为final的 类的代码在初次使用的时候才加载","link":"/2019/04/09/《Java编程思想》读书笔记(第七章)/"},{"title":"《Java编程思想》读书笔记(第三章)","text":"如果想通过“加号”连接字串（使用 Java 的早期版本），请务必保证第一个元素是字串（或加上引号的一系列字符，编译能将其识别成一个字串）。 十六进制（Base 16）——它适用于所有整数数据类型——用一个前置的 0x 或 0X 指示。并在后面跟随采用大写或小写形式的0-9 以及a-f。 八进制（Base 8）是用数字中的一个前置0 以及0-7 的数位指示的。 在 C，C++或者Java 中，对二进制数字没有相应的“字面”表示方法。 指数总是采用一种我们认为很不直观的记号方法：1.39e-47f。它真正的含义是“1.39×10 的-47 次方”。 注意如果编译器能够正确地识别类型，就不必使用尾随字符（long n3 = 200）。 编译器通常会将指数作为双精度数（double）处理，所以假如没有这个尾随的 f，就会收到一条出错提示，告诉我们须用一个“造型”将 double 转换成 float。 1float f4 = 1e-47f; //10 的幂数 运算符优先顺序： 一元运算符 &gt; 算术运算符和移位运算符 &gt; 关系运算符 &gt; 逻辑运算符和按位运算符 &gt; 条件运算符（三元） &gt; 赋值运算符（包括复合赋值，如*=） Java 使用了 C 的全部控制语句。 for 循环在第一次反复之前要进行初始化。随后，它会进行条件测试，而且在每一次反复的时候，进行某种形式的“步进”（Stepping）。for 循环的形式如下： 12for(初始表达式; 布尔表达式; 步进)语句 以于象 C 这样传统的程序化语言，要求所有变量都在一个块的开头定义。所以在编译器创建一个块的时候，它可以为那些变量分配空间。而在 Java 和C++中，则可在整个块的范围内分散变量声明，在真正需要的地方才加以定义。这样便可形成更自然的编码风格，也更易理解。 可在for 语句里定义多个变量，但它们必须具有同样的类型： 1234for(int i = 0, j = 1; i &lt; 10 &amp;&amp; j != 11; i++, j++) /* body of for loop */; 其中，for 语句内的 int 定义同时覆盖了i 和 j。只有 for 循环才具备在控制表达式里定义变量的能力。对于其他任何条件或循环语句，都不可采用这种方法。 无限循环的第二种形式是for(;;)。编译器将 while(true)与 for(;;)看作同一回事。所以具体选用哪个取决于自己的编程习惯。 在Java 里唯一需要用到标签的地方就是拥有嵌套循环，而且想中断或继续多个嵌套级别的时候。","link":"/2018/09/06/《Java编程思想》读书笔记(第三章)/"},{"title":"《Java编程思想》读书笔记(第九章)","text":"接口和内部类为我们提供了一种将接口与实现分离的更加结构化的方法 包含抽象方法的类叫做抽象类，抽象方法只有声明而没有方法体 如果从一个抽象类继承，并且想创建该新类的对象，那么就必须为基类中所有的抽象方法提供方法定义。如果不这么做，那么导出类也是抽象类，且编译器会强制我们用abstract来限定这个类","link":"/2019/04/16/《Java编程思想》读书笔记(第九章)/"},{"title":"《Java编程思想》读书笔记(第五章)","text":"java提供构造器，确保每个对象都会得到初始化 构造器采用与类相同的名称 创建对象时，先为对象分配足够的存储空间，再调用相应的构造器 由于构造器的名称必须与类完全相同，所以每个方法首字母小写的编码风格并不适用于构造器 不接受任何参数的构造器叫做默认构造器，javaDoc中经常使用术语“无参构造器” 如果一个类中只有一个构造器，那么编译器将不会允许你以其他方式创建这个类 构造器是一种特殊类型的方法，不仅没有返回值，也不会返回任何东西 每一个重载的方法都必须有一个独一无二的参数类型列表，参数顺序不同也足以区分两个方法 基本类型能从一个较小的类型自动提升至一个较大的类型 如果传入的实际参数大于重载方法声明的形式参数，就需要通过类型转换来执行窄化转换 不能通过返回值来区分重载方法 为了能用简便的面向对象的语法来编写代码，即“发送消息给对象”，编译器暗自把所操作对象的引用作为第一个参数传递给了方法 this关键字只能在方法内部使用，表示对“调用方法的那个对象”的引用。 如果在方法内部调用同一个类的另一个方法，就不必使用this，因为当前方法中this引用会自动应用于同一个类的其他方法 当方法需要返回当前对象的引用时，可以在return语句中写return this 在构造器中调用构造器，需要用到this参数，且必须将构造器调用置于最起始处 使用this.s来代表数据成员，与参数s区别开 static方法就是没有this的方法，在static方法内部不能调用非静态方法,可以在没有创建任何对象的前提下，仅仅通过类本身来调用static方法。 对象可能不被垃圾回收 垃圾回收并不等于析构 垃圾回收只与内存有关 System.gc()用于强制进行终结动作 在类的内部，变量定义的先后顺序决定了初始化的顺序，即使变量定义散布于方法定义之间，他们仍然会在任何方法（包括构造器）被调用前得到初始化 无论创建多少个对象，静态数据都只占用一份存储空间 数组只是相同类型的，用一个标识符名称封装到一起的一个对象序列或基本类型序列 定义一个数组，只要在类型名后面加上一对方括号 可以用特殊初始化表达式来定义数组：int[] a1={1,2,3,4,5} 一个数组赋值给另一个数组，其实只是复制了一个引用 所有数组都有一个固有成员length,通过它可以获知数组内包含多少个元素 java数组和C与C++类似从第0个元素开始，所以能使用的最大下标数为length-1 Array.toString()方法属于java.util标准类库，可产生一维数组的可打印版本 打印对象的默认行为就是打印类的名字和对象的地址 java提供可变参数列表，其写法为Object... arrays 可变参数列表使重载过程变得复杂，可以在参数中填加一个不可变参数来避免该问题 枚举类型的ordinal()方法输出特定enum常量的声明顺序，Static values()方法按照enum常量的声明顺序，产生这些常量构成的数组 enum可以在switch语句中使用","link":"/2019/04/09/《Java编程思想》读书笔记(第五章)/"},{"title":"《Java编程思想》读书笔记(第八章)","text":"把某个对象的引用视为对其基类类型的引用的做法被称作upcasting向上转型 将一个方法调用同一个方法主体关联起来被称作绑定，若在程序执行前进行绑定叫做前期绑定 java中除了static和final方法之外，其他所有的方法都是后期绑定 非private方法才能被覆盖 静态对象是与类，而非与单个对象相关联的 构造器的调用顺序： 调用基类构造器，这个步骤会不断的递归下去，首先是构造这种层次结构的根，然后是下一层导出类，等等，直到最底层的导出类 按声明顺序调用成员的初始化方法 调用导出类构造器的主体 协变返回类型标识在导出类的被覆盖方法可以返回基类方法的返回类型的某种导出类型 引用可以在运行时与另外一个不同的对象重新绑定起来","link":"/2019/04/15/《Java编程思想》读书笔记(第八章)/"},{"title":"《Java编程思想》读书笔记(第六章)","text":"重构即重写代码，使它更可读，更易理解，并因此更具可维护性 编写软件的程序员在重构代码时需要考虑如何把变动的事物与保持不变的事物区分开来 类库即library java访问权限控制等级从最大到最小依次为public,protected,包访问权限（没有关键词），private 使用类库的一种方式是用全名来指定，如java.util.ArrayList list = new java.util.ArrayList(); 还可以使用import关键字 123import java.util.ArrayList;ArrayList list = new ArrayList(); 要导入其他类，只需要使用* 文件起始处写package access表示你在声明该编译单元是名为access的类库的一部分 java包的命名规则全部使用小写字母 按照惯例，package名称的第一部分是类的创建者的反顺序Internet域名 package语句必须是文件中第一行非注释程序代码 通过构建自己的类库来减少代码重复量 使用public关键词，意味着public之后紧跟着的成员声明自己对每个人都时可用的 使用private关键词，除了该成员的类之外，其他任何类都无法访问这个成员 使用protect关键词，将基类中成员的访问权限，赋予子类。protect也提供包访问权限 访问权限的控制通常被称为具体实现的隐藏。把数据和方法包装进类中，以及具体实现的隐藏，常共同被称作是封装 类只有两种访问权限：包访问权限或public 如果不希望任何人对某个类具有访问权限，可以把它所有的构造器指定为private,除了一种情况，就是该类的static成员内部可以创建该类对象 方法名称前面的词告知了该方法返回的类型，经常是void，意思是不返回任何东西。但是也可以返回一个对象引用","link":"/2019/04/09/《Java编程思想》读书笔记(第六章)/"},{"title":"《Java编程思想》读书笔记(第十一章)","text":"数组是保存一组对象的最有效的方式，但是具有固定的尺寸 Java实用类库提供了容器来解决这个问题，其中基本的类型是 List Set Queue Map 这些对象类型也被叫做集合类。Java类库使用了Collection来指代该类库的一个特殊子集，Java编程思想称之为容器。 容器提供了完善的方法来保存对象 不同的容器有不同的特性：Set对于每一个值只保存一个对象，Map是允许你将某一些对象与其他一些对象关联起来的关联数组。 Java容器类可以自动调整自己的尺寸。 范型与类型安全的容器使用ArrayList的基本步骤： 创建一个实例 用add()插入对象 用get()访问对象 访问对象时需要使用索引，就像数组一样，但是不需要方括号 ArrayList还有一个size()方法，查看List中有多少个元素 注解以@符号开头，可以接受参数 @SuppressWarnings(&quot;unchecked&quot;)表示只有有关”不受检查的异常“的警告信息应该被抑制 如果一个类没有显式的声明继承自哪一个类，那么它将自动继承自Object 定义保存特定类型的ArrayList可以声明 ArrayList&lt;Type&gt;，其中尖括号括起来的就是类型参数，它指定了这个容器类可以保存的类型 通过使用范型，就可以在编译期防止将错误类型对象放置到容器中 将元素从指定了范型的容器中取出，不再需要downcasting向下转型，因为容器知道它保存的是什么类型 java对象的默认打印是由Object默认的toString()方法产生的，该方法将打印类名，后面跟随该对象的散列码的无符号十六进制表示（该散列码是通过hashCode()方法产生的） 基本概念java容器类类库的作用是保存对象，划分为两个概念： Collection，一个独立元素的序列 Map，一组成对的键值对对象 映射表允许我们使用另一个对象来查找某个对象，它也被称为关联数组 创建容器的实例应该创建一个具体类的对象，将其转型为对应的接口，在其余代码内都使用这个接口 添加一组元素Arrays.asList()接收一个数组或一个用逗号分隔的元素列表（使用可变参数），并将其转换为List对象 Collections.addAll()方法接收一个Collection对象，以及一个数组或逗号分割的列表，将元素添加到Collection中 可以在Arrays.asList()中插入一条线索，以告诉编译器对于由该方法产生的List类型，实际的目标类型应该是什么，这是显式类型参数说明 1List&lt;Snow&gt; snow4=Arrays.&lt;Snow&gt;asList(new Light(),new Heavy()); ListList接口在Collection的基础上添加了大量的方法，使得可以在List的中间插入和移除元素 List有两种类型： ArrayList擅长于随即访问元素，但是在LIst中间插入和移除元素时较慢 LinkedList可以已代价较低的在List中间进行插入和删除操作，提供了优化的顺序访问，但是在随机访问方面比较慢，但是他的特性集比ArrayList更大 page 223 迭代器java的Iterator只能单向移动，只能用来： 对Collection容器类使用方法iterator()返回一个Iterator，Iterator将准备号返回序列中的第一个元素 使用next()获得序列中的下一个元素 使用hasNext()检查序列中是否还有元素 使用remove()将迭代器新近返回的元素删除 Iterator也支持范型 Iterator能将遍历序列的操作与序列底层的结构分离 迭代器统一了对容器的访问方式 ListIterator通过调用listIterator()方法产生一个指向List开始处的ListIterator; listIterator(n)可以创建一个一开始就指向列表索引为n的元素处的ListIterator LinkedList 方法名 效果 类似方法 效果差别 getFirst()和element() 返回List的第一个元素，而并不移除它,如果List为空，则抛出NoSuchElementException peek() 如果List为空，则返回null removeFirst()和remove() 移除并返回列表的头，在列表为空时抛出NoSuchElementException poll() 在列表为空时返回null Stack栈通常是指后进先出的容器，最后一个压入栈的元素，第一个弹出栈 12345678public class Stack&lt;T&gt;{ private LinkedList&lt;T&gt; storage=new LinkedList&lt;T&gt;(); public void push(T v){storage.addFirst(v);} public T peek(){return storage.getFirst();} public T pop(){return storage.removeFirst();} public boolean isEmpty{return storage.isEmpty();} public String toString(){return storage.toString();}} 类名之后的告诉编译器这将是一个参数化类型，而其中的类型参数，即在类被使用的时候会被实际类型替换的参数，就是T。大体上就是在声明我们在定义一个可以持有T类型对象的Stack SetSet是基于对象的值来确定归属性的 出于速度原因的考虑，HashSet使用了散列 contains()可以测试Set的归属性 MapJava的自动包装机制会将随机生成的int转化为HashMap可以使用的Integer引用 如果key不在Map容器中，get()方法将返回null，否则get()方法将返回与该键相关联的值对象 Map与数组和其他Collection一样很容易扩展到多维，只需要将其值设置为Map keySet()方法产生Map中所有键组合成的Set Queue队列是典型的先进先出的容器(FIFO) offer()方法将一个元素插入队尾，或者返回false peek()和element()都在不移除元素的情况下返回队头 PriorityQueueFIFO先进先出声明的是下一个元素应该是等待时间最长的元素 优先级队列声明的是下一个弹出的元素应该是最需要的元(具有最高的优先级) 优先级队列在Java SE5中被添加 当我们对一个PriorityQueue调用offer()方法来插入一个对象时，这个对象会在队列中被排序，默认顺序是使用对象在队列中的自然顺序，通过提供自己的Comparator来修改这个顺序 优先级队列可以确保调用peek(),poll(),remove()是，获取的元素是队列中优先级最高的元素 Collection和IteratorCollection是描述所有序列容器的共性的根接口 通过针对接口而非具体类型来编写代码，我们的代码就可以应用于更多的对象类型 Collection和Iterator都可以将显示容器内容的实现与底层容器的特定实现解耦 foreach与迭代器foreach语法可以用于数组和任何Collection对象，实现了Iterable接口的类 适配其方法惯用法覆盖Collection对象，添加一个能够产生Iterable对象的方法","link":"/2019/04/16/《Java编程思想》读书笔记(第十一章)/"},{"title":"《Java编程思想》读书笔记(第十七章)","text":"Collections.nCopies(传入的对象个数，new Object())方法产生List传递给构造器 Collections.fill(需要填充的list对象，new Object())方法替换已经在list中存在的元素，而不能添加新的元素 一种Generator解决方案所有的Collection子类型都有一个能够接受另一个Collection对象的构造器","link":"/2019/05/07/《Java编程思想》读书笔记(第十七章)/"},{"title":"《Java编程思想》读书笔记(第十三章)","text":"字符串操作是计算机程序设计中最常见的行为 不可变String每当把String对象作为方法的参数时，都会复制一份引用 重载”+”与StringBuilderString对象具有只读特性，因此指向它的任何引用都不可能改变它的值 重载的意思是:一个操作符应用于特定的类时，被赋予了特殊的意义 反编译java代码 1javap -c Concatenation 无意识的递归如果想打印对象的内存地址，应该调用super.toString()方法 String上的操作 方法 构造器 length() charAt() getChars(),getBytes() toCharArray() equals(),equalsIgnoreCase() compareTo() contains() contentEquals() regionMather() startsWith() endWith() indexOf(),lastIndexOf() substring() concat() replace toLowCase(),toUpCase() trim() valueOf() intern() 格式化输出printf()%d,%f叫做格式修饰符，说明了插入数据的位置和数据类型 System.out.format()format方法可以用于PrintSteam或PrintWriter对象 可以用format也可以用printf 123456789101112pulblic class SimpleFormat{ public static void main(String[] args){ int x=5; double y= 2.333333; //the old way System.out.print(\"x = \"+x+\",y = \"+y); //the new format way System.out.format(\"x = %d,y = %f\"，x,y); //or System.out.printf(\"x = %d,y= %f\",x,y); }} Formatter类java中所有新的格式化功能都有java.util.Formatter类处理，可以将Formatter看作一个翻译器 当创建一个Formatter对象时，需要像其构造器传递一些信息 格式化说明符1%[argument_index$][flags][width][.precision]conversion Formatter转换 d 整数型(十进制) c unicode字符 b 布尔值 s String f 浮点数(十进制) e 浮点数(科学计数) x 整数(十六进制) h 散列码(十六进制) % 字符”%” String.format()String.format()是一个静态方法，接收和Formatter.format()一样的参数，但返回一个String对象 正则表达式正则表达式是一种强大而灵活的文本处理工具 match() split() 量词 贪婪型 勉强型 占有型","link":"/2019/04/25/《Java编程思想》读书笔记(第十三章)/"},{"title":"《Java编程思想》读书笔记(第十二章)","text":"Java的基本理念是结构不佳的代码不能运行 概念Java的异常处理机制建立在C++的基础之上 异常处理方式将“描述在正常执行过程中做什么事”的代码和“出了问题怎么办”的代码相分离 基本异常exception conidtion异常情形是指阻止当前方法或作用域继续执行的问题 普通问题 异常情形 在当前环境下能得到足够的信息，总能处理这个错误 在当前环境下无法获得必要的信息来解决问题 抛出异常后发生的事情： 使用new在堆上创建异常对象 当前执行路径被终止，并且从当前环境中弹出对异常对象的引用 异常处理机制接管程序，开始寻找恰当的地方来继续执行程序 异常使得我们可以将每件事都当作是一个事物来考虑 异常参数在使用new创建了异常对象之后，此对象的引用将传给throw 异常返回的地点和普通方法调用返回的地点完全不同 能够抛出任意类型的Throwable对象，它是异常类型的根类 通常异常对象中仅有的信息就是异常类型 捕获异常guarded region监视区域是指已端可能会产生异常的代码，并且在后面跟着处理这些异常的代码 try块如果在方法内部抛出了异常，这个方法将在抛出异常的过程中结束。要是不希望方法就此结束，可以在方法内设置一个特殊的块来捕获异常。 123try{ //Code that might generate exception} 异常处理程序异常处理程序将处理在try块中捕获到的异常，以关键字catch表示 12345try{ //Code that might generate exception}catch(Type1 id1){ //Handle exception of Type1} 创建自定义异常要自己定义异常类，必须从已有的异常类继承 1class SimpleException extends Exception{} 在异常处理程序中，调用了在Throwable类声明（Exception即从此类继承）的printStackTrace()方法，它将打印从方法调用处直到异常抛出处的方法调用序列 printStackTrace()方法默认将打印信息输出到标准错误流，如果参数为System.out，则输出到正常log控制台 异常与记录日志java标准类库中的java.util.logging工具将输出记录到日志中 静态的Logger.getLogger()方法创建了一个String参数相关联的Logger对象（通常与错误相关联的包名和类名） 对于异常类来说，getMessage()方法有点类似于toString()方法 异常说明java提供异常说明来告知客户端程序员某个方法可能会抛出的异常类型，它属于方法声明的一部分，紧跟在形式参数列表之后 异常说明使用了附加的关键字throws,后面接一个所有潜在异常类型的列表 1void func() throws TooBig,TooSmall,DivZero{ //...} 如果方法声明未包含异常声明，则表示该方法不会抛出任何异常（除了从RuntimeException继承的异常，它们可以在没有异常说明的情况下被抛出） 捕获所有的异常通过捕获异常类型的基类Exception可以捕获所有类型的异常 Exception可以调用它从其基类Throwable继承的方法： String getMessage() String getLocalizedMessage() String toString() void printStackTrace() Throwable fillInStackTrace() 栈轨迹printStackTrace()方法所提供的信息可以通过getStackTrace()方法来直接访问，getStackTrace()方法返回一个由栈轨迹中的元素所构成的数组 1234567try{ throw new Exception(\"My Exception\");}catch(Exception e){ for(StackTraceElement ste:e.getStackTrace()){ syso(ste.getMethodName()); }} 重新抛出异常在捕获到某个异常后可以将它重新抛出,重抛异常将会把异常交给上一级环境中的异常处理程序，同一个try块的后续catch字句将被忽略 1234catch(Exception e){ syso(\"An exception was thrown\"); throw e;} Java标准异常Throwable这个Java类被用来表示任何可以作为异常被抛出的类 Throwable对象的两种类型： Error用来表示编译时和系统错误 Exception表示可以被抛出的基本类型 如果对null引用进行调用，java会自动抛出NullPointException异常 对于RunTimeException异常类型，Java不需要异常说明，其输出被报告给了System.err 使用finally进行清理无论异常是否被抛出，finally字句总能被执行 在return中使用finally因为finally子句总会执行，所以在一个方法中，可以从多个点返回，并且可以保证重要的清理工作仍旧会执行 page 269","link":"/2019/04/18/《Java编程思想》读书笔记(第十二章)/"},{"title":"《Java编程思想》读书笔记(第十五章)","text":"范型实现了参数化类型的概念，使得代码可以应用于多种类型 范型这个术语的意思是适用于许多许多的类型 简单范型范型出现的一个重要原因是为了创造容器类，容器就是存放要使用的对象的地方 只持有一个对象的类 123456789101112131415class Automobile{}public class Holder1{ private Automobile a; public Holder1(Automobile a){ this.a=a; } Automobile get(){ return a; }} 在Java SE5之前，可以让这个类直接持有Object类型的对象 1234567891011121314151617181920public class Holder2{private Object o;public Holder2(Object o){this.o=o;}public void set(Object o){this.o=o;}public Object get(){return o;}public static void main(String[] args){ Holder2 h2=new Holder2(new Automobile()); Automobile a=(Automobile)h2.get(); h2.set(\"did you miss me?\"); String s=(String)h2.get(); h2.set(1); Integer x=(Integer)h2.get();}} 范型的主要目的之一就是要指定容器要持有什么类型的对象，而且由编译器来保证类型的正确性 因此，与其使用Object，不如暂时不指定类型，而是在稍后使用的时候再指定具体用什么类型。要达到这个目的，需要使用类型参数，用尖括号括住，放在类名后面。然后在使用这个类的时候，在用实际的类型替换此类型参数。 12345678910public class Holder3&lt;T&gt;{private T a;public Holder3(T a){this.a=a;}public void set(T a){this.a=a;}public T get(){return a;}public static void main(String[] args){ Holder3&lt;Automobile&gt; h3=new Holder3&lt;Automobile&gt;(new Automobile()); Automobile a=(Automobile)h3.get();//no cast need}} 一个元组类库元组将一组对象直接打包储存于其中的一个单一对象 123456789101112public class TwoTuple&lt;A,B&gt;{public final A first;public final B second;public TwoTuple(A a,B b){first=a;second=b;}public String toString(){ return \"(\"+first+\",\"+second+\")\";}} 我们可以通过继承机制实现长度更长的元组 1234567891011121314public class ThreeTuple&lt;A,B,C&gt; extends TwoTuple&lt;A,B&gt;{public final C third;public ThreeTuple(A a,B b,C c){super(a,b);third=c;}public String toString(){return \"(\"+first+\",\"+second+\",\"+third+\")\";}} 为了使用元组，只需定义一个长度合适的元组，将其作为方法的返回值，然后在return语句中创建该元组并返回即可 在对象被构造出来后，声明为final的元素便不能被赋予其他的值了 一个堆栈类123456789101112131415161718192021222324252627282930313233public class LinkedStack&lt;T&gt;{ private static class Node&lt;U&gt;{ U item; Node&lt;U&gt; next; Node(){item=null;next=null;} Node(U item,Node&lt;U&gt; next){this.item=item;this.next=next;} boolean end(){return item == null &amp;&amp; next == null;} } private Node&lt;T&gt; top=new Node&lt;T&gt;(); public void push(T item){ top=new Node&lt;T&gt;(item,top); } public T pop(){ T result=top.item; if(!top.end()){ top=top.next; } return result; } public static void main(String[] args){ LinkedStack&lt;String&gt; lss=new LinkedStack&lt;String&gt;(); for(String s:\"Are you ok\".split){ lss.push(s); } String s; while((s=lss.pop())!=null) System.out.println(s); }} 这个例子使用末端哨兵（end sentinel）来判读堆栈何时为空。这个末端哨兵是在构造LinkedStack时创建的 RandomList就是一个范型类里包含了一个ArrayList，随机选择一个对象 范型接口范型也可以应用于接口 1public interface Generator&lt;T&gt;{T next();} 基本类型无法作为类型参数 1234567891011121314151617public class Fibonacci implements Generator&lt;Integer&gt;{ private int count=0; public Integer next(){return fib(count++)} private int fib(int n){ if(n&lt;2) return 1; return fib(n-1)+fib(n-2); } public static void main(String[] args){ Fibonacci gen=new Fabonacci(); for(int i=0;i&lt;11;i++){ syso(gen.next()+\" \"); } }} 范型方法范型可以用于整个类之上，也可以在类中包含参数化方法 是否拥有范型方法，与其所在的类是否是范型没有关系 定义范型方法，只需将范型参数列表置于返回值之前 12345public class GenericMethod{ public &lt;T&gt; void f(T x){ System.out.println(x.getClass().getName()); }} 方法拥有的参数类型，是由该方法的返回值类型前面的类型参数决定的 当使用范型类是，必须在创建对象时指定类型参数的值，而在使用范型方法时通常不必指明参数类型，因为编译器辉为我们找到具体的类型，这叫做类型参数推断(type argument inference) 我们可以像调用普通方法一样调用范型方法，就好像该方法被无限次地重载过 如果调用范型方法时传入了基本类型，自动打包机制就会介入其中，将基本类型的值包装为对应的对象 杠杆利用类型参数推断类型推断支队赋值操作有效 显式的类型说明 在范型方法中可以显示的指明类型，要显式的指明类型，必须在点操作符和方法名之间插入尖括号，然后把类型置入尖括号内，如果是在定义该方法的类的内部，必须在点操作符之前使用this关键字，如果是static方法，必须在点操作符之前加上类名 123456public class ExplicitTypeSpcification{ static void f(Map&lt;Person,List&lt;Pet&gt;&gt; petPeople){} public static void main(String[] args){ f(New.&lt;Persom,List&lt;Pet&gt;&gt;map()); }} 只有编写非赋值语句时，我们才需要这样额外的说明 可变参数和范型方法范型方法和可变参数列表可以很好的共存 123456789public class GenericVarargs{ public static &lt;T&gt; List&lt;T&gt; makeList(T...args){ List&lt;T&gt; result=new ArrayList&lt;T&gt;(); for(T item:args) result.add(item); return result; }} makeList()方法展示了和标准类库中的java.util.Arrays.asList()方法相同的功能 一个set实用工具作为范型方法的示例，set可以表达数学中的关系式,表达元素的并，交等运算 12345678910111213141516171819202122232425public class Sets{ public static &lt;T&gt; Set&lt;T&gt; union(Set&lt;T&gt; a,Set&lt;T&gt; b){ Set&lt;T&gt; result=new HashSet&lt;T&gt;(a); result.addAll(b); return result; } public static &lt;T&gt; Set&lt;T&gt; intersection(Set&lt;T&gt; a,Set&lt;T&gt; b){ Set&lt;T&gt; result= new HashSet&lt;T&gt;(a); result.retainAll(b); return result; } public static &lt;T&gt; Set&lt;T&gt; difference(Set&lt;T&gt; a,Set&lt;T&gt; b){ Set&lt;T&gt; result=new HashSet&lt;T&gt;(a); result.removeAll(b); return result; } public static &lt;T&gt; Set&lt;T&gt; complement(Set&lt;T&gt; a,Set&lt;T&gt; b){ return difference(union(a,b),intersection(a,b)); }} EnumSet是Java SE5中的新工具，用来从enum直接创建Set，其静态方法EnumSet.range()可以传入某个范围内的第一个元素和最后一个元素，然后它将返回一个set，包含该范围内的所有元素 1234567public enum Watercolor{ZINC,LEMON_YELLOW,....}public class WatercolorSets{Set&lt;Watercolors&gt; sets1 =EnumSet.range(ZINC,LEMON_YELLOW);} 匿名内部类范型可以应用于内部类及匿名内部类 构建复杂模型范型的一个重要好处是能够简单而安全的创建复杂模型 擦除的神秘之处同一种类的不同范型对象，通过getClass()得到的Class对象是相同的 根据JDK文档的描述，Class.getTypeParameters()将返回一个类型参数对象数组，表明有范型声明的类型参数。 在范型代码内部，无法获得任何有关范型参数类型的信息 Java范型是使用范擦除来实现的，这意味着你在使用范型时，任何具体的类型信息都被擦除了，你唯一知道的是你在使用一个对象 C++的方式java的范型是受C++启发的 在C++中，Manipulator类存储了一个类型T的对象，其方法调用了f()，因为C++的范型语法和Java有区别，在实例化这个模板时，C++编译器将进行检查，因此在该类被实例化的这一刻，它会看到HasF有一个方法f() 123456789101112131415161718192021#include &lt;iostream&gt;using namespace std;template&lt;class T&gt; class Manipulator{ T obj; public: Manipulator(T x){obj=x;} void manipulate{obj.f();}};class HasF{ public: void f(){cout&lt;&lt;\"hasF::f()\"&lt;&lt;endl;}};int main(){ HasF hf; Manipulator&lt;HasF&gt; manipulator(hf); manipulator.manipulate();} 而在Java上由于范型的擦除机制，Java编译器将manipulate()必须能够在obj上调用f()的这一需求映射到HasF拥有f()这一事实上，为类调用f()，我们必须协助范型类，给定范型类的边界，以此告知编译器只能接受这个边界的类型，这里是重用了extends关键字 1234567891011//octopusheep/HasF.javapublic class HasF{ public void f(){System.out.println(\"HasF.f()\");}}//octopusheep/Manipulation.javaclass Manipulator&lt;T extends HasF&gt;{ private T obj; Manipulator(T X){obj=x;} public void manipulate(){obj.f();}} 边界声明了T必须具有类型HasF或HasF导出的类型，这样就可以安全的在obj上调用f()了 迁移兼容性擦除的核心动机是它使得泛化的客户端可以使用非泛化的类库，反之亦然，这经常被成为”迁移兼容性” 擦除的问题为了关闭警告，Java提供了一个注解，这个注解在Java SE5之前的版本中不支持 1@SuppressWarnings(\"unchecked\") 边界处的动作对于在范型中创建数组，使用Array.newInstance()是推荐方式 通配符通配符允许在两个类型之间建立某种类型的向上转型关系 问题基本类型不能被当作参数类型 一个类不能实现同一个范型接口的两种变体","link":"/2019/04/30/《Java编程思想》读书笔记(第十五章)/"},{"title":"《Java编程思想》读书笔记(第十六章)","text":"我突然意识到static和final的含义：static表示它所定义的域和方法对于这个类来说有且仅有一份;final表示它所定义的域对实例来说是不可改变的，final类型的域随实例的创建而被创建，不像static与整个类相关联。同时用static和final修饰域则表示常量，即其对于整个类来说只有一份且不可修改。 12345class BerylliumSphere{ private static long counter; private final long id=counter++; public String toString(){return \"Sphere \"+id;}} 数组为什么特殊数组是一种效率最高的存储和随机访问对象引用序列的方式 在范型出现之前，其他容器类在处理对象时，都将它们视为没有任何具体的类型 数组是第一级对象数组的只读成员length是唯一一个可以访问的字段或方法，表示该数组对象可以存储多少元素，”[]”语法是访问数组对象的唯一方式 length是数组的大小，而不是实际保存的元素的个数 基本类型数组的工作方式和对象数组一样，不过基本类型数组直接存储基本类型数据的值 返回一个数组该节主要展示了一个例子如何随机抽取元素不重复，用了do while循环 多维数组对于基本类型的多维数组，可以使用花括号将每个向量分隔开 1234567public class MutidimensionalPrimitiveArray{ public static void main(String[] args){ int[] a={{1,2,3},{4,5,6}}; System.out.println(Arrays.deepToString(a)); }} Java SE5的Arrays.deepToString()方法可以将多维数组转化为多个String 可以使用new来分配多维数组 1int[][][] a=new int[2][2][4]; 基本类型数组的值在不进行显式初始化的情况下会被自动初始化。对象数组会被初始化为null 数组中构成矩阵的每个向量都可以具有的长度，这被称为粗糙数组 12345678910111213public class RuggedArray{ public static void main(String[] args){ Random rand=new Random(47); int[][][] a=new int[rand.nextInt(7)][][]; for(int i=0;i&lt;a.length;i++){ a[i]=new int[rand.nextInt(5)][]; for(int j=0;j&lt;a[i].length;j++){ a[i][j]=new int[rand.nextInt(5)]; } } System.out.println(Arrays.deepToString(a)); }} 数组与范型不能实例化具有参数化类型的数组，但是可以参数化数组本身的类型 创建测试数据介绍一些用数值或对象来填充数组的工具 Arrays.fill()Arrays.fill(要填充的数组引用,填充的值); Arrays实用功能复制数组可以用System.arrayscopy(),它的参数为源数组引用，源数组开始位置偏移量，目标数组，目标数组开始位置偏移量，需要复制的元素个数 比较数组可以用Arrays.equals()","link":"/2019/05/07/《Java编程思想》读书笔记(第十六章)/"},{"title":"《Java编程思想》读书笔记(第十四章)","text":"运行时类型信息使得你可以在程序运行时发现和使用类型信息 为什么需要RTTI面向对象编程的基本的目的是：让代码只操纵对基类的引用 通常会创建一个具体对象，把它向上转型为基类 CLASS对象类是程序的一部分，每一个类都有一个class对象 每当编写并且编译了一个新类，就会产生一个class对象（被保存在了一个同名的.class文件中）。为了生成这个类的对象，运行这个类的JVM将使用被称为“类加载器”的子系统 类字面常量java提供类字面常量来生成对Class对象的引用 1FancyToy.class 类字面常量不仅可以应用普通类，也可以应用于接口，数组以及基本数据类型 对于基本数据类型的包装类，还有一个标准字段TYPE 泛化的Class引用为了在使用泛化的Class引用时放松限制，须使用通配符 新的转型语法Java SE5添加了用于Class引用的转型方法，即cast()方法 12House h = houseType.cast(b);h = (House)b; 类型转换前先做检查我们已知的RTTI形式包括： 传统的类型转换 代表对象的类型的Class对象 RTTI在java中的第三种形式是关键字instanceof,它返回一个布尔值，告诉我们对象是不是某个特定类型的实例 123if(x instanceof Dog){ ((Dog)x).bark();} 在进行向下转型前，如果没有其他信息可以告诉你这个对象是什么类型，那么使用instanceof是非常重要的，否则会得到一个ClassCastException异常 反射提供在跨网络的远程平台上创建和运行对象的能力，被成为远程方法调用 Class类和java.lang.reflect类库一起对反射的概念进行了支持 动态代理通过调用静态方法Proxy.newProxyInstance()可以创建动态代理","link":"/2019/04/29/《Java编程思想》读书笔记(第十四章)/"},{"title":"《Java编程思想》读书笔记(第十章)","text":"可以将一个类的定义方在另一个类的定义内部，这就是内部类 内部类和组合是完全不同的概念 如果想从外部类的非静态方法之外的任意位置创建某个内部类的对象，那么必须具体的指明这个对象的类型：OuterClassName.InnerClassName 内部类可以实现迭代器设计模式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546interface Selector{ boolean end(); Object current(); void next();}public class Sequence{ private Object[] items; private int next=0; public Sequence(int size){ items=new Object[size]; } public void add(Object x){ if(next &lt; items.length){ items[next ++]=x; } } private class SequenceSelector implements Selector{ private int i = 0; public boolean end(){ return i==items.length; } public Object current(){ return items[i]; } public void next(){ if(i&lt;items.length) i++; } } public Selector selector(){ return new SequenceSelector(); } private static void main(String[] args){ Sequence sequence = new Sequence(10); for(int i=0;i&lt;10;i++){ sequence.add(Integer.toSting(i)); } Selector selector= sequence.selector(); while(!selector.end()){ System.out.print(selector.current()+\" \"); selector.next(); } }} 但某个外部类的对象创建了一个内部类对象时，此内部类对象一定会秘密地捕获一个指向那个外部类对象的引用，在内部类中访问外部类的成员，就是用那个引用来选择外围类的成员 如果你需要生成对外部类对象的引用，可以使用外部类对象的名字后面紧跟dot和this。 1OuterClassName.this .new语法新建内部类 1OuterClassName.InnerClassName oi=o.new InnerClassName(); 在拥有外部类对象之前是不可能创建内部类对象的。内部类对象会暗自连接到创建它的外部类对象上。但是如果创建的是嵌套类（静态内部类），那么它就不需要对外部类对象的引用 anonymous inner class在匿名类定义字段时，还能够对其执行初始化操作 如果定义一个匿名内部类，并且希望它使用一个在其外部定义的对象，那么编译器要求其参数引用是final的 如果不想内部类与其外围类对象之间有联系，可以将内部类声明为static 一个内部类被嵌套多少层都能够透明的访问所有它所嵌套的外围类的所有成员 每个内部类都能独立的继承自一个接口的实现,所以无论外围类是否已经继承了某个接口的实现，对于内部类都没有影响 闭包与回调closure闭包是一个可调用的对象，它记录了一些信息，这些信息来自于创建它的作用域 继承内部类必须初始化指向内部类的外部类引用 12345class InheritanceInnerClass extends OutClass.InnerClass{ InheritanceInnerClass(OutClass outclass){ outclass.super(); }}","link":"/2019/04/16/《Java编程思想》读书笔记(第十章)/"},{"title":"《Java编程思想》读书笔记(第四章)","text":"所有方法首字母小写的编码规则并不适用于构建器。这是由于构建器的名字必须与类名完全相同！ 不能根据返回值类型来区分过载的方法。 this 关键字（注意只能在方法内部使用）可为已调用了其方法的那个对象生成相应的句柄。可象对待其他任何对象句柄一样对待这个句柄。但要注意，假若准备从自己某个类的另一个方法内部调用一个类方法，就不必使用this。只需简单地调用那个方法即可。 有可能发出这类调用的一种情况是我们将一个对象句柄传到static 方法内部。随后，通过句柄（此时实际是this），我们可调用非 static 方法，并访问非static 字段。 垃圾收集器只知道释放那些由new 分配的内存，所以不知道如何释放对象的“特殊”内存。为解决这个问题，Java 提供了一个名为finalize()的方法，可为我们的类定义它。 垃圾收集器存在的唯一原因是为了回收程序不再使用的内存。 “固有方法”是从Java 里调用非 Java 方法的一种方式。 在这里有必要总结一下对象的创建过程。请考虑一个名为 Dog 的类：(1) 类型为 Dog 的一个对象首次创建时，或者 Dog 类的static 方法／static 字段首次访问时，Java 解释器必须找到Dog.class（在事先设好的类路径里搜索）。(2) 找到Dog.class 后（它会创建一个 Class 对象，这将在后面学到），它的所有 static 初始化模块都会运行。因此，static 初始化仅发生一次——在 Class 对象首次载入的时候。(3) 创建一个new Dog()时，Dog 对象的构建进程首先会在内存堆（Heap）里为一个 Dog 对象分配足够多的存储空间。(4) 这种存储空间会清为零，将Dog 中的所有基本类型设为它们的默认值（零用于数字，以及 boolean 和char 的等价设定）。(5) 进行字段定义时发生的所有初始化都会执行。(6) 执行构建器。正如第6 章将要讲到的那样，这实际可能要求进行相当多的操作，特别是在涉及继承的时候。","link":"/2018/09/07/《Java编程思想》读书笔记(第四章)/"},{"title":"在vultr服务器上部署shadowsocks","text":"首先得有一台vultr服务器，或者其他国外运营商的云服务器 SSH登陆云服务器在Terminals中使用ssh命令登陆服务器 安装依赖包12apt-get install python-pip python-gevent python-m2cryptopip install --upgrade setuptools 安装shadowsocks1pip install shadowsocks 配置shadowsocks在/etc目录下新建文件夹shadowsocks,然后在shadowsocks文件夹下新建文件config.json: 12mkdir /etc/shadowsocksvim /etc/shadowsocks/config.json 配置内容如下： server填写tulvr服务器的ipv4地址 serverport和password随意设置 12345678{ &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8888, &quot;password&quot;:&quot;your_password&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;: false} 启动shadowsocks1ssserver -c /etc/shadowsocks/config.json -d start 停止shadowsocks1ssserver -c /etc/shadowsocks/config.json -d stop 解决undefined symbol: EVP_CIPHER_CTX_cleanup错误由于Ubuntu18.04中openssl升级到1.1.0版本了，所以启动Shadowsocks的时候应该会报undefined symbol: EVP_CIPHER_CTX_cleanup错误，没有的话请忽略该步骤 修改openssl.py文件 1vim /usr/local/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py 将上述文件中libcrypto.EVP_CIPHER_CTX_cleanup.argtypes 替换为libcrypto.EVP_CIPHER_CTX_reset.argtypes，修改后保存文件 重新运行shadowsocks 1ssserver -c /etc/shadowsocks/config.json -d start 设置Shadowsocks开机自启动创建shadowsocks.servic文件 1vim /etc/systemd/system/shadowsocks.service 文件内容如下： 123456789101112131415161718[Unit]Description=ShadowsocksAfter=network.target[Service]Type=forkingPIDFile=/run/shadowsocks/server.pidPermissionsStartOnly=trueExecStartPre=/bin/mkdir -p /run/shadowsocksExecStartPre=/bin/chown root:root /run/shadowsocksExecStart=/usr/local/bin/ssserver --pid-file /var/run/shadowsocks/server.pid -c /etc/shadowsocks/config.json -d startRestart=on-abortUser=rootGroup=rootUMask=0027[Install]WantedBy=multi-user.target 设置shadowsocks.servic文件权限 1chmod 755 /etc/systemd/system/shadowsocks.service 启动服务 12systemctl start shadowsockssystemctl enable shadowsocks 使用shadowsocks搭建完毕，现在只要去下载shadowsocks的客户端填上Config.json中的ip地址、端口号、以及密码就可以了。 shadowsocks下载链接 Windows 12345678910https://github.com/shadowsocks/shadowsocks-windows/releases``` - Mac OS X ``` https://github.com/shadowsocks/ShadowsocksX-NG/releases``` - linux https://github.com/shadowsocks/shadowsocks-qt5/wiki/Installation 123``` https://github.com/shadowsocks/shadowsocks-qt5/releases iOS 1https://itunes.apple.com/app/apple-store/id1070901416?pt=2305194&amp;ct=shadowsocks.org&amp;mt=8 1https://github.com/shadowsocks/shadowsocks-iOS/releases Android 1https://play.google.com/store/apps/details?id=com.github.shadowsocks 1https://github.com/shadowsocks/shadowsocks-android/releases","link":"/2020/10/19/在vultr服务器上部署shadowsocks/"},{"title":"外网VPN无法访问Jira的解决方法","text":"🈶️🈚️发现连了外网VPN后无法登陆jira系统嫩 查看VPN的网关1netstat -rn | grep utun 执行后出现如下内容 1234567891011120/1 192.168.250.129 UGSc 51 0 utun210.200/16 192.168.250.129 UGSc 0 0 utun2128.0/1 192.168.250.129 UGSc 14 0 utun2192.168.1 192.168.250.129 UGSc 0 0 utun2192.168.1.11/32 192.168.250.129 UGSc 1 0 utun2192.168.1.168/29 192.168.250.129 UGSc 0 0 utun2192.168.10 192.168.250.129 UGSc 0 0 utun2192.168.16/20 192.168.250.129 UGSc 0 0 utun2192.168.32 192.168.250.129 UGSc 0 0 utun2192.168.128/18 192.168.250.129 UGSc 0 0 utun2192.168.250.1/32 192.168.250.129 UGSc 0 0 utun2192.168.250.129 192.168.250.130 UHr 31 0 utun2 挑选出第二列第一行的ip并复制，如192.168.250.129 添加Jira的数据包通过VPN网关1sudo route -nv add 192.168.8.100/32 192.168.250.129 该命令中192.168.8.100/32参数为jira的ip地址，正常无需修改，除非jira系统的ip地址变更。而192.168.250.129为步骤1中获取的VPN网关，需修改成实际VPN网关地址","link":"/2019/11/12/外网VPN无法访问Jira的解决方法/"},{"title":"廖雪峰Git教程全指令","text":"安装gitsudo apt-get install git 设置姓名和emailgit config --global user.name &quot;your name&quot;git config --global user.email &quot;your email&quot; 创建文件夹mkdir yourdirname 进入文件夹cd yourdirname 显示当前目录pwd 初始化git仓库git init 查看文件夹内全部内容ls -ah 在youdirname文件夹内创建文件gedit readme.txt 把文件添加至仓库git add readme.txt 把文件提交至仓库git commit -as 查看仓库当前状态git status 查看仓库内文件具体改变git diff 查看仓库提交历史记录git log 查看仓库提交历史记录（一行显示一次提交）git log --pretty=oneline 回退提交版本（HEAD仅仅是一个指针,标识当前版本，上一个版本是HEAD^,上上个版本是HEAD^^）git reset --hard HEAD^ 查看每一次git操作记录git reflog 查看工作区和版本库里最新版本的区别git diff HEAD -- yourfilename 将工作区里的修改撤销git checkout -- yourfilename 将暂存区stage中的修改撤销git reset HEAD yourfilename 删除文件rm yourfilename 从版本库中删除文件git rm yourfilename 创建SSH Keyssh-keygen -t rsa -C &quot;youremail@example.com&quot; 添加远程仓库(本地仓库和远程仓库建立连接)git remote add origin git@github.com:yourgithubname/demo.git 向远程仓库推送本地库内容git push -u origin master 克隆一个本地库git clone git@github.com:yourgithubname/demo.git 创建分支并切换到新的分支git checkout -b newbranchname 创建分支git branch newbranchname 切换分支git checkout newbranchname 显示当前所有分支git branch 合并指定分支到当前分支git merge devbranchname 删除分支git branch -d devbranchname 不以fast-forward策略的合并分支git merge --no-f -m &quot;merge information&quot; devbranchname 查看提交历史记录，显示分支图，简短提交记录，提交记录单行显示git log --graph --pretty=oneline --abbrev-commit 藏匿工作区现场git stash 恢复stash内容git stash apply 删除stash内容git stash drop 恢复stash内容同时删除stash内容git stash pop 强行删除分支git branch -D devbranchname 查看远程库信息(-v查看更详细信息)git remote 推送本地分支提交到远程库git push origin master 将最新的与远程库代码抓下来git pull 建立本地分支和远程分支的关联git branch --set-upstream-to=origin/dev dev 常用命令设置别名git config --global alias.co checkout 设置lggit config --global alias.lg &quot;log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit&quot;","link":"/2019/04/04/廖雪峰Git教程全指令/"},{"title":"数据结构学习笔记","text":"绪论非数值计算程序设计需要考虑待处理对象的特性以及各处理对象之间的关系 什么是数据结构需求数学模型的实质是分析问题，从中提取出操作的对象，并找出这些对象之间所含有的关系，用数学的语言加以描述 非数值计算问题的例子 树木检索系统自动化问题（线性的数据结构） 计算机和人对弈的问题（数） 多岔路口交通灯的管理问题 数据结构是一门研究非数值计算问题的程序设计中计算机所操纵的想象以及它们之间的关系和操作等的学科 10:16pm 6/15/19-11:00pm 6/15/19 基本概念和术语数据是对客观事物的符号表示 数据元素是数据的基本单位 一个数据元素可由若干个数据项组成 数据项是数据的不可分割的最小单位 数据对象是性质相同的数据元素的集合 数据结构是相互之间存在一种或多种特定关系的数据元素的集合 结构是数据元素之间的相互关系 数据元素之间的关系有四种基本结构： 集合 线性结构 树状结构 图状结构或网状结构 数据结构的形式定义为：数据结构是一个二元组 Data_Structure=(D,S) D是数据元素的有限集，S是D上关系的有限集 数据的逻辑结构是指数据元素之间的逻辑关系 数据的物理结构或存储结构是指数据结构在计算机中的表示 计算机中表示信息的最小单位为二进制数的一位，叫做位（bit） 用一个有若干位组合起来形成的位串来表示数据元素，通常称这个位串为元素或节点 当数据元素由若干个数据项组成时，位串中对应于各个数据项的子串称为数据域 数据元素之间的关系在计算机中的两种不同表示方法： 顺序映像 非顺序映像 数据元素的两种存储结构： 顺序存储结构 链式存储结构 数据类型是一个值的集合和定义在这个值集上的一组操作的总称 数据类型分为两类： 原子类型 结构类型 原子类型的值是不可分解的 抽象数据类型（ADT）是指一个数学模型和定义在该模型上的一组操作 抽象数据类型的种类： 原子类型 固定聚合类型 可变聚合类型 抽象数据类型的形式定义：（D,S,P）D是数据对象，S是D上的关系集，P是对D的基本操作集 抽象数据类型的表示与实现for（赋初值表达式序列;条件;修改表达式序列） 算法和算法分析算法的五个重要特性： 有穷性 确定性 可行性 输入 输出 算法设计的要求 正确性 可读性 健壮性 效率和低存储量需求 冒泡排序的时间复杂度为T(n)=O(n的二次方) 2:30pm 6/1619-4:30pm 6/16/19","link":"/2019/06/16/数据结构学习笔记/"},{"title":"FSM有限状态机学习笔记","text":"该文章总结自wikipedia的有限状态机 A finite-state machine (FSM) or finite-state automaton (FSA, plural: automata), finite automaton, or simply a state machine, is a mathematical model of computation. It is an abstract machine that can be in exactly one of a finite number of states at any given time. 概念有限状态机FSM是一种数学计算模型，它是一种抽象机器，其状态在任意时间内都可以被精确描述为有限数量的状态集中的一种。对于测试来说，很重要的一环就是状态机的状态转化表，它描述了每一种可能的状态和他们之间的转化，以及由每一种输入导致的输出 举个栗子：turnstile旋转门 旋转门在锁定状态下无法被推动旋转，只有在被投币后进入解锁状态后才能被推动，随后又进入锁定状态 current state input next state output locked coin unlocked unlocks the turnstile so that customer can put through locked push locked none unlocked coin unlocked none unlocked push locked when the customer has pushed through, locks the turnstile 常用的表示方法 状态/事件表：将状态和输入作为横纵坐标，将当前状态和输入结合以展示下一个阶段的状态 current state &amp; input State A State B State C Input X … … … Input Y … State C … Input Z … … … 状态图：每个状态用节点表示，节点间的箭头表示在执行输入后状态之间的转变，如果一个输入无法造成状态转变，就用一个重新指向原状态的环形箭头表示，从黑点指向Locked节点的箭头表示它是初始状态","link":"/2019/06/11/状态机学习笔记/"},{"title":"等价类划分学习笔记","text":"概念等价类划分，指的是一种典型的、重要的黑盒测试方法。其就是解决如何选择适当的数据子集来代表整个数据集的问题，通过降低测试的数目去实现“合理的”覆盖，以此来发现更多的软件缺陷. 等价类类别 有效等价类：对于程序来说，有意义的合理的输入数据集合，用来测试功能是否正确实现 无效等价类：对于对程序来说，无意义的、不合理的输入数据集合—用来测试程序是否有强大的异常处理能力（健壮性） 两个步骤 划分等价类型 设计测试用例 举个例子：加法器 被测对象：两个输入框，分别代表两个输入接口 测试思路：先测第一个数,此时第二个数填写正确数据配合,第一个数测试完成后，测第二个数，此时第一个数填写正确数据配合 分析需求，根据需求划分等价类：要求-99—99之间的整数，不能为空 有效等价类 无效等价类 -99—99之间的整数 &lt;-99的整数,&gt;99的整数,非整数（需要细化）,为空（不填） 编写测试用例：从每个等价类范围中至少挑选一个代表数据进行测试","link":"/2019/06/11/等价类划分学习笔记/"},{"title":"读研目标学校分析","text":"为挑选目标高校，特此将其往年专业报考人数和录取人数做统计，方便横向对比 厦门大学招生简章厦门大学2019年硕士研究生招生简章 报考人数与录取人数根据厦门大学2019年硕士研究生招生考试各专业报考人数 报考院系代码 报考院系名称 报考专业代码 报考专业名称 人数 131 计算机科学系 081200 计算机科学与技术 130 135 智能科学与技术系 081200 计算机科学与技术 104 根据厦门大学各院系专业2014—2018年硕士生报考录取数据统计表 年份 非推免生录取率 2018 4.6% 2017 9.7% 2016 12.1% 2015 10.7% 2014 8.3% 初试内容大纲根据厦门大学2019年硕士研究生招生考试初试科目业务课考试内容范围说明 计算机科学系： 875数据结构与操作系统： 数据结构（100分）：绪论、线性表、栈、队列、串、数据和广义表、树与二叉树、图、查找、内部排序等 操作系统基础（50分）： 1、操作系统概述 2、进程管理 3、内存管理 4、文件管理 5、输入输出（I/O）管理 6、分布式操作系统基础 903数据结构B 智能科学与技术系： 864人工智能导论 合肥工业大学招生简章合肥工业大学2019年硕士研究生招生简章 报考人数与录取人数根据合肥工业大学2019年硕士研究生招生目录 初试内容大纲根据合肥工业大学2019年硕士研究生招生考试初试部分科目考试大纲","link":"/2019/06/13/读研目标学校分析/"},{"title":"购买vultr服务器指南","text":"注册vultr账号使用优惠链接注册vultr账号,或者直接点击官网链接注册 测试各服务器与本地网络的延迟下表给出所有vultr服务器的IP地址，使用terminals执行ping指令找出延迟最低的服务器 123456789101112131415ping fra-de-ping.vultr.com ping par-fr-ping.vultr.com ping ams-nl-ping.vultr.com ping lon-gb-ping.vultr.com ping sgp-ping.vultr.com ping nj-us-ping.vultr.com ping hnd-jp-ping.vultr.com ping il-us-ping.vultr.com ping ga-us-ping.vultr.com ping fl-us-ping.vultr.com ping wa-us-ping.vultr.com ping tx-us-ping.vultr.com ping sjo-ca-us-ping.vultr.com ping lax-ca-us-ping.vultr.com ping syd-au-ping.vultr.com 经我测试，与vultr洛杉矶服务器延迟最低，为180ms左右，丢包率在5%左右 123456789101112131415161718192021222324Last login: Sun Oct 18 18:21:44 on ttys000zhangyuyang@zhangyuyangs-MacBook-Pro ~ % ping lax-ca-us-ping.vultr.com PING lax-ca-us-ping.vultr.com (108.61.219.200): 56 data bytes64 bytes from 108.61.219.200: icmp_seq=0 ttl=49 time=181.622 ms64 bytes from 108.61.219.200: icmp_seq=1 ttl=49 time=188.388 ms64 bytes from 108.61.219.200: icmp_seq=2 ttl=49 time=188.166 msRequest timeout for icmp_seq 364 bytes from 108.61.219.200: icmp_seq=4 ttl=49 time=187.782 ms64 bytes from 108.61.219.200: icmp_seq=5 ttl=49 time=187.956 ms64 bytes from 108.61.219.200: icmp_seq=6 ttl=49 time=190.814 ms64 bytes from 108.61.219.200: icmp_seq=7 ttl=49 time=195.892 ms64 bytes from 108.61.219.200: icmp_seq=8 ttl=49 time=188.061 ms64 bytes from 108.61.219.200: icmp_seq=9 ttl=49 time=188.018 ms64 bytes from 108.61.219.200: icmp_seq=10 ttl=49 time=188.119 ms64 bytes from 108.61.219.200: icmp_seq=11 ttl=49 time=187.754 ms64 bytes from 108.61.219.200: icmp_seq=12 ttl=49 time=188.198 ms64 bytes from 108.61.219.200: icmp_seq=13 ttl=49 time=185.565 ms64 bytes from 108.61.219.200: icmp_seq=14 ttl=49 time=188.167 ms64 bytes from 108.61.219.200: icmp_seq=15 ttl=49 time=187.975 ms64 bytes from 108.61.219.200: icmp_seq=16 ttl=49 time=187.885 ms^C--- lax-ca-us-ping.vultr.com ping statistics ---17 packets transmitted, 16 packets received, 5.9% packet lossround-trip min/avg/max/stddev = 181.622/188.148/195.892/2.702 ms 购买并配置服务器 Server Location: Los Angeles/United States Server Type: Ubuntu 20.04 x64 Server Size: $5/mo Additional Features: Enable IPv6 SSH Keys: 如需配置ssh免密登陆，可以设置SSH Keys选项 最后付钱就完事啦，vultr支持支付宝哦","link":"/2020/10/19/购买vultr服务器指南/"},{"title":"集群健康检查操作指南","text":"Comprisal集群健康检查主要由三个文件组成： 保存集群和节点信息的文件/etc/ansible/hosts 输出健康检查信息的shell脚本/root/cluster/check_cluster.sh 发送邮件的python文件/root/cluster/send_mail.py 以上路径均为绝对路径 Step登陆131.29节点1ssh root@192.168.131.29 该节点为QA组执行常用操作的节点,密码为caicloud2018 添加需要检查的集群和节点信息1vi /etc/ansible/hosts 打开后向下翻阅找到与集群节点相关的记录 123456789101112131415161718192021222324252627282930313233...[cluster-30]192.168.129.30172.16.100.123192.168.132.10192.168.129.31#192.168.129.32#192.168.132.33192.168.129.34192.168.129.35#192.168.129.45#172.16.60.71#192.168.131.1192.168.129.37[test]192.168.131.29[cluster-40]192.168.129.40192.168.129.41192.168.129.44192.168.129.46192.168.129.48192.168.130.6192.168.131.11#192.168.129.45#172.16.60.102#192.168.133.11... 此处我们可以看到[cluster-30]标签下监控的ip有： 192.168.129.30 172.16.100.123 192.168.132.10 192.168.129.31 192.168.129.34 192.168.129.35 192.168.129.37 假设我们监控的是cluster-30集群，就要在[cluster-30]标签下添加我们需要监控的ip，按需添加即可 修改shell脚本1vi /root/cluster/check_cluster.sh 打开后可发现如下内容 12345678910#!/bin/bashcluster='cluster-30' //填写需要做健康检查的集群node='node-30' //填写需要做健康检查的节点log='/root/cluster/check_cluster.log'rm -rf /root/.ssh/known_hostsrm -rf /root/cluster/check_cluster.log.... 在check_cluster.sh中填写需要做检查的集群和节点，如cluster可以填写cluster-30或cluster-40等，集群相关信息被保存在了/etc/ansible/hosts文件中 运行shell脚本1bash /root/cluster/check_cluster.sh 执行后即输出集群健康检查日志如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586[INFO]Date 2019年 08月 01日 星期四 10:13:28 CST[INFO]Start checking the cluster environment[INFO]Start checking for cluster memory leaks[DEPRECATION WARNING]: The TRANSFORM_INVALID_GROUP_CHARS settings is set to allow bad characters in group names by default, this will change, but still be user configurableon deprecation. This feature will be removed in version 2.10. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg. [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details172.16.100.123 | CHANGED | rc=0 &gt;&gt;The above is the oom component informationWarning: Permanently added &apos;172.16.100.123&apos; (ECDSA) to the list of known hosts.Shared connection to 172.16.100.123 closed.192.168.129.31 | CHANGED | rc=0 &gt;&gt;The above is the oom component informationWarning: Permanently added &apos;192.168.129.31&apos; (ECDSA) to the list of known hosts.Shared connection to 192.168.129.31 closed.192.168.132.10 | CHANGED | rc=0 &gt;&gt;The above is the oom component informationWarning: Permanently added &apos;192.168.132.10&apos; (ECDSA) to the list of known hosts.Shared connection to 192.168.132.10 closed.192.168.129.30 | CHANGED | rc=0 &gt;&gt;The above is the oom component informationWarning: Permanently added &apos;192.168.129.30&apos; (ECDSA) to the list of known hosts.Shared connection to 192.168.129.30 closed.192.168.129.34 | CHANGED | rc=0 &gt;&gt;The above is the oom component informationWarning: Permanently added &apos;192.168.129.34&apos; (ECDSA) to the list of known hosts.Shared connection to 192.168.129.34 closed.192.168.129.35 | CHANGED | rc=0 &gt;&gt;The above is the oom component informationWarning: Permanently added &apos;192.168.129.35&apos; (ECDSA) to the list of known hosts.Shared connection to 192.168.129.35 closed.192.168.129.37 | CHANGED | rc=0 &gt;&gt;The above is the oom component informationWarning: Permanently added &apos;192.168.129.37&apos; (ECDSA) to the list of known hosts.Shared connection to 192.168.129.37 closed.[SUCCESS]Cluster check succeeded[INFO]Start checking for cluster pod status[DEPRECATION WARNING]: The TRANSFORM_INVALID_GROUP_CHARS settings is set to allow bad characters in group names by default, this will change, but still be user configurableon deprecation. This feature will be removed in version 2.10. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg. [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details172.16.100.123 | CHANGED | rc=0 &gt;&gt;kube-system mlneuron-controller-controller-v1-0-84949558d-zsqj7 0/1 CreateContainerConfigError 0 13hThe above is the non Running Completed component informationShared connection to 172.16.100.123 closed.192.168.129.30 | CHANGED | rc=0 &gt;&gt;The above is the non Running Completed component informationShared connection to 192.168.129.30 closed.192.168.129.34 | CHANGED | rc=0 &gt;&gt;kube-system lb-137661599-provider-ipvsdr-lxuqc-5dc55557f8-ld69l 0/1 Pending 0 37hkube-system lb-137661599-proxy-nginx-l18nn-768fbb948c-m8f6l 0/2 Pending 0 37hkube-system mlneuron-controller-controller-v1-0-84949558d-njkvv 0/1 CreateContainerConfigError 0 39hThe above is the non Running Completed component informationShared connection to 192.168.129.34 closed.192.168.129.31 | CHANGED | rc=0 &gt;&gt;kube-system mlneuron-controller-controller-v1-0-84949558d-smqd4 0/1 CreateContainerConfigError 0 39hkube-system sparkoperator-init-init-v1-0-6xmwt 0/1 Error 0 39hThe above is the non Running Completed component informationShared connection to 192.168.129.31 closed.192.168.132.10 | CHANGED | rc=0 &gt;&gt;kube-system clever-spark-operator-operator-v1-0-56dbcc95cc-wwpdx 0/1 ContainerCreating 0 39hkube-system mlneuron-controller-controller-v1-0-84949558d-5d9mh 0/1 CreateContainerConfigError 0 39hkube-system sparkoperator-init-init-v1-0-ptkf6 0/1 ContainerCreating 0 39hThe above is the non Running Completed component informationShared connection to 192.168.132.10 closed.192.168.129.35 | CHANGED | rc=0 &gt;&gt;kube-system mlneuron-controller-controller-v1-0-84949558d-8lw6v 0/1 CreateContainerConfigError 0 39hThe above is the non Running Completed component informationShared connection to 192.168.129.35 closed.192.168.129.37 | CHANGED | rc=0 &gt;&gt;kube-system mlneuron-controller-controller-v1-0-84949558d-kzj5z 0/1 CreateContainerConfigError 0 39hThe above is the non Running Completed component informationShared connection to 192.168.129.37 closed.[SUCCESS]Cluster check succeeded 发送邮件至相关通知人1python /root/cluster/send_mail.py 执行后提示，即发送成功 12Thu, 01 Aug 2019 10:15:40 +0800邮件已发送至对应账号！！ Gotcha其实整个健康检查就一个shell脚本和一个发送邮件的python文件，诸如更改日志保存路径和更改邮箱收件人自己看看代码就明白了","link":"/2019/08/01/集群健康检查操作指南/"}],"tags":[{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/tags/Elasticsearch/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"Logstash","slug":"Logstash","link":"/tags/Logstash/"},{"name":"Flutter","slug":"Flutter","link":"/tags/Flutter/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"LDAP","slug":"LDAP","link":"/tags/LDAP/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"RxJava","slug":"RxJava","link":"/tags/RxJava/"},{"name":"Sublime","slug":"Sublime","link":"/tags/Sublime/"},{"name":"Hanoi","slug":"Hanoi","link":"/tags/Hanoi/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"VI","slug":"VI","link":"/tags/VI/"},{"name":"Sshpass","slug":"Sshpass","link":"/tags/Sshpass/"},{"name":"Scraping","slug":"Scraping","link":"/tags/Scraping/"},{"name":"iTerm2","slug":"iTerm2","link":"/tags/iTerm2/"},{"name":"Vultr","slug":"Vultr","link":"/tags/Vultr/"},{"name":"Shadowsocks","slug":"Shadowsocks","link":"/tags/Shadowsocks/"},{"name":"Jira","slug":"Jira","link":"/tags/Jira/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"FSM","slug":"FSM","link":"/tags/FSM/"},{"name":"VPS","slug":"VPS","link":"/tags/VPS/"}],"categories":[{"name":"Programming","slug":"Programming","link":"/categories/Programming/"},{"name":"Java","slug":"Programming/Java","link":"/categories/Programming/Java/"},{"name":"Kubernetes","slug":"Programming/Kubernetes","link":"/categories/Programming/Kubernetes/"},{"name":"Elasticsearch","slug":"Programming/Elasticsearch","link":"/categories/Programming/Elasticsearch/"},{"name":"Flutter","slug":"Programming/Flutter","link":"/categories/Programming/Flutter/"},{"name":"Go","slug":"Programming/Go","link":"/categories/Programming/Go/"},{"name":"Kafka","slug":"Programming/Kafka","link":"/categories/Programming/Kafka/"},{"name":"Python","slug":"Programming/Python","link":"/categories/Programming/Python/"},{"name":"Docker","slug":"Programming/Docker","link":"/categories/Programming/Docker/"},{"name":"Studying","slug":"Studying","link":"/categories/Studying/"},{"name":"Testing","slug":"Testing","link":"/categories/Testing/"}]}